{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-26T14:05:18.058470179Z",
     "start_time": "2023-10-26T14:05:17.622603802Z"
    }
   },
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-26T14:05:18.118252034Z",
     "start_time": "2023-10-26T14:05:18.059645269Z"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "from helpers import *\n",
    "\n",
    "height, weight, gender = load_data(sub_sample=False, add_outlier=False)\n",
    "x, mean_x, std_x = standardize(height)\n",
    "y, tx = build_model_data(x, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-26T14:05:18.138851396Z",
     "start_time": "2023-10-26T14:05:18.119161139Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "((10000,), (10000, 2))"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape, tx.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NB: throughout this laboratory the data has the following format: \n",
    "  * there are **N = 10000** data entries\n",
    "  * **y** represents the column vector containing weight information -- that which we wish to predict/the output (see also the first page of $\\texttt{exercise02.pdf}$). Its **shape** is **(N,)**.\n",
    "  * **tx** represents the matrix $\\tilde{X}$ formed by laterally concatenating a column vector of 1s to the column vector of height information -- the input data (see also the first page of $\\texttt{exercise02.pdf}$). Its **shape** is **(N,2)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Computing the Cost Function\n",
    "Fill in the `compute_loss` function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-26T14:05:18.169995230Z",
     "start_time": "2023-10-26T14:05:18.136291463Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_loss(y, tx, w):\n",
    "    \"\"\"Calculate the loss using either MSE or MAE.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        w: numpy array of shape=(2,). The vector of model parameters.\n",
    "\n",
    "    Returns:\n",
    "        the value of the loss (a scalar), corresponding to the input parameters w.\n",
    "    \"\"\"\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    nb_sample = y.shape[0]\n",
    "    e = y - tx @ w\n",
    "    return 1/(2*nb_sample) * e.T @ e\n",
    "    # ***************************************************x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def compute_loss_MAE(y, tx, w):\n",
    "    nb_sample = y.shape[0]\n",
    "    e = y - tx @ w\n",
    "    return 1/nb_sample * np.sum(np.abs(e))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-26T14:05:18.200531362Z",
     "start_time": "2023-10-26T14:05:18.151804195Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in the function `grid_search()` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-26T14:05:18.200821153Z",
     "start_time": "2023-10-26T14:05:18.194589199Z"
    }
   },
   "outputs": [],
   "source": [
    "# from costs import *\n",
    "\n",
    "\n",
    "def grid_search(y, tx, grid_w0, grid_w1):\n",
    "    \"\"\"Algorithm for grid search.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        grid_w0: numpy array of shape=(num_grid_pts_w0, ). A 1D array containing num_grid_pts_w0 values of parameter w0 to be tested in the grid search.\n",
    "        grid_w1: numpy array of shape=(num_grid_pts_w1, ). A 1D array containing num_grid_pts_w1 values of parameter w1 to be tested in the grid search.\n",
    "\n",
    "    Returns:\n",
    "        losses: numpy array of shape=(num_grid_pts_w0, num_grid_pts_w1). A 2D array containing the loss value for each combination of w0 and w1\n",
    "    \"\"\"\n",
    "\n",
    "    losses = np.zeros((len(grid_w0), len(grid_w1)))\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    w = np.hstack((grid_w0[:, np.newaxis], grid_w1[:, np.newaxis]))\n",
    "    for i in range(len(grid_w0)):\n",
    "        for j in range(len(grid_w1)):\n",
    "            w = np.array([grid_w0[i], grid_w1[j]])\n",
    "            losses[i, j] = compute_loss(y, tx, w)\n",
    "            \n",
    "    # ***************************************************\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-26T14:05:18.255701187Z",
     "start_time": "2023-10-26T14:05:18.195285249Z"
    }
   },
   "outputs": [],
   "source": [
    "# This function is a bit more efficient as it doesn't contain any for loop, but it is not possible to use the function compute_loss as\n",
    "# we implemented it, because it expects to treat each (w0, w1) separately\n",
    "\n",
    "# This one uses indices\n",
    "def grid_search_v2(y, tx, grid_w0, grid_w1):\n",
    "    row, col = np.indices((len(grid_w0), len(grid_w1)))\n",
    "    big_w0, big_w1 = grid_w0[row.ravel()], grid_w1[col.ravel()]\n",
    "    w = np.column_stack((big_w0, big_w1))\n",
    "    e = (y[:, np.newaxis] - tx @ w.T)**2\n",
    "    nb_sample = y.shape[0]\n",
    "    losses = 1/(2*nb_sample) * np.sum(e, axis=0)\n",
    "    return losses.reshape((len(grid_w0), len(grid_w1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-26T14:05:18.256205758Z",
     "start_time": "2023-10-26T14:05:18.239631529Z"
    }
   },
   "outputs": [],
   "source": [
    "# This one uses broadcasting, the broadcasting must be explicit, as we have to stack the arrays\n",
    "def grid_search_v3(y, tx, grid_w0, grid_w1):\n",
    "    w0_size, w1_size = grid_w0.shape[0], grid_w1.shape[0]\n",
    "    w0 = np.broadcast_to(grid_w0[:, np.newaxis], (w0_size, w1_size))\n",
    "    w1 = np.broadcast_to(grid_w1[np.newaxis, :], (w0_size, w1_size))\n",
    "    w = np.column_stack((w0.ravel(), w1.ravel()))\n",
    "    e = (y[:, np.newaxis] - tx @ w.T)**2\n",
    "    nb_sample = y.shape[0]\n",
    "    losses = 1/(2*nb_sample) * np.sum(e, axis=0)\n",
    "    return losses.reshape((len(grid_w0), len(grid_w1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us play with the grid search demo now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-26T14:05:40.039147042Z",
     "start_time": "2023-10-26T14:05:18.240287628Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.39 s ± 1.46 s per loop (mean ± std. dev. of 3 runs, 3 loops each)\n",
      "6.95 s ± 153 ms per loop (mean ± std. dev. of 3 runs, 3 loops each)\n",
      "7.22 s ± 116 ms per loop (mean ± std. dev. of 3 runs, 3 loops each)\n"
     ]
    }
   ],
   "source": [
    "from grid_search import generate_w\n",
    "grid_w0_t, grid_w1_t = generate_w(num_intervals=100)\n",
    "%timeit -r 3 -n 3 -c grid_search(y, tx, grid_w0_t, grid_w1_t)\n",
    "%timeit -r 3 -n 3 -c grid_search_v2(y, tx, grid_w0_t, grid_w1_t)\n",
    "%timeit -r 3 -n 3 -c grid_search_v3(y, tx, grid_w0_t, grid_w1_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-26T14:05:41.402802221Z",
     "start_time": "2023-10-26T14:05:40.043366661Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search: loss*=15.558703368609557, w0*=72.72727272727272, w1*=13.636363636363626, execution time=0.790 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 1000x600 with 3 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from grid_search import generate_w, get_best_parameters\n",
    "from plots import grid_visualization\n",
    "\n",
    "from grid_search import grid_search_v2\n",
    "\n",
    "# Generate the grid of parameters to be swept\n",
    "grid_w0, grid_w1 = generate_w(num_intervals=100)\n",
    "\n",
    "# Start the grid search\n",
    "start_time = datetime.datetime.now()\n",
    "grid_losses = grid_search_v2(y, tx, grid_w0, grid_w1)\n",
    "\n",
    "# Select the best combinaison\n",
    "loss_star, w0_star, w1_star = get_best_parameters(grid_w0, grid_w1, grid_losses)\n",
    "end_time = datetime.datetime.now()\n",
    "execution_time = (end_time - start_time).total_seconds()\n",
    "\n",
    "# Print the results\n",
    "print(\n",
    "    \"Grid Search: loss*={l}, w0*={w0}, w1*={w1}, execution time={t:.3f} seconds\".format(\n",
    "        l=loss_star, w0=w0_star, w1=w1_star, t=execution_time\n",
    "    )\n",
    ")\n",
    "\n",
    "# Plot the results\n",
    "fig = grid_visualization(grid_losses, grid_w0, grid_w1, mean_x, std_x, height, weight)\n",
    "fig.set_size_inches(10.0, 6.0)\n",
    "fig.savefig(\"grid_plot\")  # Optional saving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, please fill in the functions `compute_gradient` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-26T14:05:41.526526248Z",
     "start_time": "2023-10-26T14:05:41.403498637Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_gradient(y, tx, w):\n",
    "    \"\"\"Computes the gradient at w.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        w: numpy array of shape=(2, ). The vector of model parameters.\n",
    "\n",
    "    Returns:\n",
    "        An numpy array of shape (2, ) (same shape as w), containing the gradient of the loss at w.\n",
    "    \"\"\"\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    nb_sample = y.shape[0]\n",
    "    e = y - tx @ w\n",
    "    return -1/nb_sample * tx.T @ e\n",
    "    # ***************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please fill in the functions `gradient_descent` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-26T14:05:41.527025209Z",
     "start_time": "2023-10-26T14:05:41.450248989Z"
    }
   },
   "outputs": [],
   "source": [
    "def gradient_descent(y, tx, initial_w, max_iters, gamma):\n",
    "    \"\"\"The Gradient Descent (GD) algorithm.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        initial_w: numpy array of shape=(2, ). The initial guess (or the initialization) for the model parameters\n",
    "        max_iters: a scalar denoting the total number of iterations of GD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "\n",
    "    Returns:\n",
    "        losses: a list of length max_iters containing the loss value (scalar) for each iteration of GD\n",
    "        ws: a list of length max_iters containing the model parameters as numpy arrays of shape (2, ), for each iteration of GD\n",
    "    \"\"\"\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        # ***************************************************\n",
    "        # INSERT YOUR CODE HERE\n",
    "        # TODO: compute gradient and loss\n",
    "        # ***************************************************\n",
    "        loss = compute_loss(y, tx, w)\n",
    "        gradient = compute_gradient(y, tx, w)\n",
    "        # ***************************************************\n",
    "        # INSERT YOUR CODE HERE\n",
    "        w = w - gamma*gradient\n",
    "        # ***************************************************\n",
    "\n",
    "        # store w and loss\n",
    "        ws.append(w)\n",
    "        losses.append(loss)\n",
    "        print(\n",
    "            \"GD iter. {bi}/{ti}: loss={l}, w0={w0}, w1={w1}\".format(\n",
    "                bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your gradient descent function through gradient descent demo shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-26T14:05:41.529233916Z",
     "start_time": "2023-10-26T14:05:41.450782615Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GD iter. 0/49: loss=2792.2367127591674, w0=51.30574540147361, w1=9.43579870449228\n",
      "GD iter. 1/49: loss=265.3024621089606, w0=66.69746902191571, w1=12.266538315839998\n",
      "GD iter. 2/49: loss=37.87837955044126, w0=71.31498610804834, w1=13.115760199244328\n",
      "GD iter. 3/49: loss=17.41021212017447, w0=72.70024123388814, w1=13.37052676426563\n",
      "GD iter. 4/49: loss=15.568077051450452, w0=73.11581777164007, w1=13.446956733772023\n",
      "GD iter. 5/49: loss=15.402284895265302, w0=73.24049073296565, w1=13.469885724623941\n",
      "GD iter. 6/49: loss=15.387363601208634, w0=73.27789262136334, w1=13.476764421879516\n",
      "GD iter. 7/49: loss=15.386020684743531, w0=73.28911318788263, w1=13.478828031056189\n",
      "GD iter. 8/49: loss=15.385899822261674, w0=73.29247935783842, w1=13.47944711380919\n",
      "GD iter. 9/49: loss=15.385888944638305, w0=73.29348920882516, w1=13.47963283863509\n",
      "GD iter. 10/49: loss=15.385887965652199, w0=73.29379216412119, w1=13.479688556082861\n",
      "GD iter. 11/49: loss=15.38588787754345, w0=73.29388305071, w1=13.479705271317192\n",
      "GD iter. 12/49: loss=15.385887869613665, w0=73.29391031668663, w1=13.479710285887492\n",
      "GD iter. 13/49: loss=15.385887868899985, w0=73.29391849647962, w1=13.479711790258582\n",
      "GD iter. 14/49: loss=15.385887868835756, w0=73.29392095041752, w1=13.479712241569908\n",
      "GD iter. 15/49: loss=15.385887868829968, w0=73.29392168659889, w1=13.479712376963306\n",
      "GD iter. 16/49: loss=15.385887868829451, w0=73.2939219074533, w1=13.479712417581325\n",
      "GD iter. 17/49: loss=15.3858878688294, w0=73.29392197370962, w1=13.479712429766732\n",
      "GD iter. 18/49: loss=15.385887868829407, w0=73.29392199358652, w1=13.479712433422353\n",
      "GD iter. 19/49: loss=15.385887868829403, w0=73.2939219995496, w1=13.47971243451904\n",
      "GD iter. 20/49: loss=15.3858878688294, w0=73.29392200133852, w1=13.479712434848047\n",
      "GD iter. 21/49: loss=15.385887868829398, w0=73.29392200187519, w1=13.479712434946748\n",
      "GD iter. 22/49: loss=15.385887868829403, w0=73.29392200203618, w1=13.479712434976358\n",
      "GD iter. 23/49: loss=15.3858878688294, w0=73.29392200208449, w1=13.479712434985242\n",
      "GD iter. 24/49: loss=15.3858878688294, w0=73.29392200209898, w1=13.479712434987906\n",
      "GD iter. 25/49: loss=15.385887868829402, w0=73.29392200210333, w1=13.479712434988706\n",
      "GD iter. 26/49: loss=15.385887868829403, w0=73.29392200210464, w1=13.479712434988945\n",
      "GD iter. 27/49: loss=15.385887868829398, w0=73.29392200210502, w1=13.479712434989018\n",
      "GD iter. 28/49: loss=15.385887868829396, w0=73.29392200210513, w1=13.47971243498904\n",
      "GD iter. 29/49: loss=15.385887868829403, w0=73.29392200210518, w1=13.479712434989047\n",
      "GD iter. 30/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 31/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 32/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 33/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 34/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 35/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 36/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 37/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 38/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 39/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 40/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 41/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 42/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 43/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 44/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 45/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 46/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 47/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 48/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 49/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD: execution time=0.023 seconds\n"
     ]
    }
   ],
   "source": [
    "# from gradient_descent import *\n",
    "from plots import gradient_descent_visualization\n",
    "\n",
    "# Define the parameters of the algorithm.\n",
    "max_iters = 50\n",
    "gamma = 0.7\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start gradient descent.\n",
    "start_time = datetime.datetime.now()\n",
    "gd_losses, gd_ws = gradient_descent(y, tx, w_initial, max_iters, gamma)\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"GD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-26T14:05:41.926659783Z",
     "start_time": "2023-10-26T14:05:41.497997068Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "interactive(children=(IntSlider(value=1, description='n_iter', max=51, min=1), Output()), _dom_classes=('widge…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6cf512276f094ddf93fc8cff10f8552c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<function __main__.plot_figure(n_iter)>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time Visualization\n",
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        gd_losses,\n",
    "        gd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "    \n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(gd_ws)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 4. Stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-26T14:05:41.929513574Z",
     "start_time": "2023-10-26T14:05:41.925862162Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_stoch_gradient(y, tx, w):\n",
    "    \"\"\"Compute a stochastic gradient at w from a data sample batch of size B, where B < N, and their corresponding labels.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(B, )\n",
    "        tx: numpy array of shape=(B,2)\n",
    "        w: numpy array of shape=(2, ). The vector of model parameters.\n",
    "\n",
    "    Returns:\n",
    "        A numpy array of shape (2, ) (same shape as w), containing the stochastic gradient of the loss at w.\n",
    "    \"\"\"\n",
    "\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    nb_sample = y.shape[0]\n",
    "    e = y - tx @ w\n",
    "    return -1/nb_sample * tx.T @ e\n",
    "    # ***************************************************\n",
    "\n",
    "\n",
    "def stochastic_gradient_descent(y, tx, initial_w, batch_size, max_iters, gamma):\n",
    "    \"\"\"The Stochastic Gradient Descent algorithm (SGD).\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        initial_w: numpy array of shape=(2, ). The initial guess (or the initialization) for the model parameters\n",
    "        batch_size: a scalar denoting the number of data points in a mini-batch used for computing the stochastic gradient\n",
    "        max_iters: a scalar denoting the total number of iterations of SGD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "\n",
    "    Returns:\n",
    "        losses: a list of length max_iters containing the loss value (scalar) for each iteration of SGD\n",
    "        ws: a list of length max_iters containing the model parameters as numpy arrays of shape (2, ), for each iteration of SGD\n",
    "    \"\"\"\n",
    "\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "\n",
    "    for n_iter in range(max_iters):\n",
    "        # ***************************************************\n",
    "        # INSERT YOUR CODE HERE\n",
    "        # TODO: implement stochastic gradient descent.\n",
    "        # ***************************************************\n",
    "        loss = compute_loss(y, tx, w)\n",
    "        gradient = np.zeros(tx.shape[1]) # init the gradient for the upcoming batch\n",
    "        for y_batch, tx_batch in batch_iter(y,tx, batch_size):\n",
    "            gradient += compute_stoch_gradient(y_batch, tx_batch, w)\n",
    "\n",
    "        w = w - gamma * gradient/batch_size\n",
    "        # store w and loss\n",
    "        ws.append(w)\n",
    "        losses.append(loss)\n",
    "        # ***************************************************\n",
    "        print(\n",
    "            \"SGD iter. {bi}/{ti}: loss={l}, w0={w0}, w1={w1}\".format(\n",
    "                bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]\n",
    "            )\n",
    "        )\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-26T14:05:41.933428705Z",
     "start_time": "2023-10-26T14:05:41.926300668Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD iter. 0/49: loss=2341.1583977948767, w0=6.806380114971931, w1=-1.717385763640734\n",
      "SGD iter. 0/49: loss=2045.4274226704606, w0=12.141781479709636, w1=-4.422767257289685\n",
      "SGD iter. 0/49: loss=1855.5668569439877, w0=17.06098748007426, w1=-9.284711853608735\n",
      "SGD iter. 0/49: loss=1711.9144493117901, w0=20.734597708501123, w1=-11.631531116171168\n",
      "SGD iter. 0/49: loss=1562.5188059336863, w0=24.95127440046024, w1=-14.038540761623707\n",
      "SGD iter. 0/49: loss=1488.5128998298876, w0=27.620360116801372, w1=-15.84910903181116\n",
      "SGD iter. 0/49: loss=1417.5612562409078, w0=30.533110795464417, w1=-17.759105751590674\n",
      "SGD iter. 0/49: loss=1417.7249170448126, w0=30.55445702210362, w1=-17.793537980904553\n",
      "SGD iter. 0/49: loss=1351.232199193019, w0=27.51924814844768, w1=-10.528033320072275\n",
      "SGD iter. 0/49: loss=1006.9114773639624, w0=33.427106243534055, w1=-6.361864625880174\n",
      "SGD iter. 0/49: loss=976.969671872074, w0=35.089634660734994, w1=-8.051659949151068\n",
      "SGD iter. 0/49: loss=916.6806899193801, w0=38.10498732080975, w1=-10.275886486036416\n",
      "SGD iter. 0/49: loss=810.2166049188813, w0=41.31087976861593, w1=-10.326724585089119\n",
      "SGD iter. 0/49: loss=476.8627676211269, w0=46.88678095106713, w1=-1.5408288673467823\n",
      "SGD iter. 0/49: loss=364.2979375926547, w0=50.79808990649845, w1=-0.36809019842253354\n",
      "SGD iter. 0/49: loss=296.2855848203907, w0=53.64179785322258, w1=0.22854605840059783\n",
      "SGD iter. 0/49: loss=197.51335575935832, w0=57.28750493655581, w1=3.085023959390182\n",
      "SGD iter. 0/49: loss=194.62510547449278, w0=57.5132987220066, w1=3.0178596304931986\n",
      "SGD iter. 0/49: loss=123.52221852178944, w0=60.44516210820927, w1=6.325550674521795\n",
      "SGD iter. 0/49: loss=85.68035255355547, w0=62.78504866102187, w1=7.98858227166925\n",
      "SGD iter. 0/49: loss=62.923895532212384, w0=64.58299109388211, w1=9.09842289434808\n",
      "SGD iter. 0/49: loss=66.47278428079352, w0=64.10114692571693, w1=9.276537537502245\n",
      "SGD iter. 0/49: loss=57.60753978329569, w0=65.09950038664991, w1=9.321015738054788\n",
      "SGD iter. 0/49: loss=55.475993292939876, w0=66.01741560927482, w1=8.261219782573045\n",
      "SGD iter. 0/49: loss=55.96929268941102, w0=65.9260097420894, w1=8.29505443567295\n",
      "SGD iter. 0/49: loss=53.431020259936034, w0=66.48045686659256, w1=8.032974178989663\n",
      "SGD iter. 0/49: loss=55.88877292518377, w0=66.0407852634409, w1=8.150755917719733\n",
      "SGD iter. 0/49: loss=55.70574739588144, w0=66.0857945369735, w1=8.124096924095994\n",
      "SGD iter. 0/49: loss=42.43263042950929, w0=67.31505524267608, w1=9.196414944228753\n",
      "SGD iter. 0/49: loss=43.72619146165832, w0=66.71292169355624, w1=9.823068875037315\n",
      "SGD iter. 0/49: loss=43.68075885980784, w0=66.72767034791208, w1=9.809006617879325\n",
      "SGD iter. 0/49: loss=27.351976198232382, w0=68.46885939649225, w1=12.672899252944001\n",
      "SGD iter. 0/49: loss=23.19573165716335, w0=69.48134270939555, w1=12.438594423681224\n",
      "SGD iter. 0/49: loss=23.33095108882005, w0=69.4240651172559, w1=12.52350423027319\n",
      "SGD iter. 0/49: loss=21.13695182178576, w0=69.98973360409548, w1=12.715208061966413\n",
      "SGD iter. 0/49: loss=20.93055272884365, w0=70.03600289399373, w1=12.790297607014837\n",
      "SGD iter. 0/49: loss=20.01042777957043, w0=70.36372636538695, w1=12.665443835545677\n",
      "SGD iter. 0/49: loss=18.849820732026448, w0=70.95839656137083, w1=12.26596343207424\n",
      "SGD iter. 0/49: loss=19.830658587174792, w0=70.5877489470435, w1=12.228245762340977\n",
      "SGD iter. 0/49: loss=17.817015741788335, w0=71.17789824510061, w1=12.859471186997522\n",
      "SGD iter. 0/49: loss=16.91699028495835, w0=71.61611273723928, w1=12.982559638569262\n",
      "SGD iter. 0/49: loss=16.712483616064297, w0=71.71220798981156, w1=13.090646530823989\n",
      "SGD iter. 0/49: loss=16.300929882574874, w0=71.9683309617333, w1=13.209726470211782\n",
      "SGD iter. 0/49: loss=15.803738123218386, w0=72.38314678148276, w1=13.55838267255158\n",
      "SGD iter. 0/49: loss=16.082730900727537, w0=72.15234565659149, w1=13.178897689406547\n",
      "SGD iter. 0/49: loss=16.690870261016343, w0=71.6784316177576, w1=13.492186506271079\n",
      "SGD iter. 0/49: loss=16.551407487047115, w0=71.76735487931727, w1=13.454571709891468\n",
      "SGD iter. 0/49: loss=16.71044500373319, w0=71.66880656132535, w1=13.389634280331354\n",
      "SGD iter. 0/49: loss=15.809331282050238, w0=72.42376976713075, w1=13.779248600436002\n",
      "SGD iter. 0/49: loss=15.586193457333128, w0=72.66262160243103, w1=13.434204387583103\n",
      "SGD: execution time=0.008 seconds\n"
     ]
    }
   ],
   "source": [
    "# from stochastic_gradient_descent import *\n",
    "\n",
    "# Define the parameters of the algorithm.\n",
    "max_iters = 50\n",
    "gamma = 0.1\n",
    "batch_size = 1\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start SGD.\n",
    "start_time = datetime.datetime.now()\n",
    "sgd_losses, sgd_ws = stochastic_gradient_descent(\n",
    "    y, tx, w_initial, batch_size, max_iters, gamma\n",
    ")\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"SGD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-26T14:05:42.318596172Z",
     "start_time": "2023-10-26T14:05:41.930004879Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "interactive(children=(IntSlider(value=1, description='n_iter', max=51, min=1), Output()), _dom_classes=('widge…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bb44005f351b4b609706d5d0a5ed476f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<function __main__.plot_figure(n_iter)>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time Visualization\n",
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        sgd_losses,\n",
    "        sgd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(sgd_ws)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Effect of Outliers and MAE Cost Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-26T14:05:42.375742694Z",
     "start_time": "2023-10-26T14:05:42.317734306Z"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "from helpers import *\n",
    "\n",
    "# ***************************************************\n",
    "# INSERT YOUR CODE HERE\n",
    "# TODO: reload the data by subsampling first, then by subsampling and adding outliers\n",
    "height, weight, gender = load_data(sub_sample=True, add_outlier=True)\n",
    "x, mean_x, std_x = standardize(height)\n",
    "y, tx = build_model_data(x, weight)\n",
    "# ***************************************************\n",
    "\n",
    "x, mean_x, std_x = standardize(height)\n",
    "y, tx = build_model_data(x, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-26T14:05:42.390616532Z",
     "start_time": "2023-10-26T14:05:42.377072531Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "((202,), (202, 2))"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape, tx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-26T14:05:42.416912796Z",
     "start_time": "2023-10-26T14:05:42.391720177Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GD iter. 0/49: loss=2869.835114535854, w0=51.84746409844846, w1=7.724426406192428\n",
      "GD iter. 1/49: loss=318.2821247015954, w0=67.40170332798299, w1=10.041754328050121\n",
      "GD iter. 2/49: loss=88.6423556165127, w0=72.06797509684336, w1=10.736952704607413\n",
      "GD iter. 3/49: loss=67.9747763988552, w0=73.46785662750146, w1=10.945512217574597\n",
      "GD iter. 4/49: loss=66.11469426926604, w0=73.88782108669889, w1=11.00808007146475\n",
      "GD iter. 5/49: loss=65.94728687760302, w0=74.01381042445813, w1=11.026850427631794\n",
      "GD iter. 6/49: loss=65.93222021235334, w0=74.0516072257859, w1=11.03248153448191\n",
      "GD iter. 7/49: loss=65.93086421248088, w0=74.06294626618423, w1=11.034170866536943\n",
      "GD iter. 8/49: loss=65.93074217249236, w0=74.06634797830372, w1=11.034677666153454\n",
      "GD iter. 9/49: loss=65.93073118889338, w0=74.06736849193958, w1=11.034829706038408\n",
      "GD iter. 10/49: loss=65.93073020036948, w0=74.06767464603033, w1=11.034875318003893\n",
      "GD iter. 11/49: loss=65.93073011140234, w0=74.06776649225755, w1=11.03488900159354\n",
      "GD iter. 12/49: loss=65.93073010339528, w0=74.06779404612573, w1=11.034893106670433\n",
      "GD iter. 13/49: loss=65.93073010267466, w0=74.06780231228618, w1=11.034894338193501\n",
      "GD iter. 14/49: loss=65.93073010260979, w0=74.06780479213431, w1=11.034894707650421\n",
      "GD iter. 15/49: loss=65.93073010260395, w0=74.06780553608876, w1=11.034894818487498\n",
      "GD iter. 16/49: loss=65.93073010260343, w0=74.06780575927509, w1=11.03489485173862\n",
      "GD iter. 17/49: loss=65.93073010260338, w0=74.06780582623098, w1=11.034894861713957\n",
      "GD iter. 18/49: loss=65.93073010260338, w0=74.06780584631775, w1=11.034894864706558\n",
      "GD iter. 19/49: loss=65.93073010260338, w0=74.06780585234378, w1=11.034894865604338\n",
      "GD iter. 20/49: loss=65.93073010260338, w0=74.06780585415159, w1=11.034894865873673\n",
      "GD iter. 21/49: loss=65.93073010260339, w0=74.06780585469393, w1=11.034894865954472\n",
      "GD iter. 22/49: loss=65.93073010260338, w0=74.06780585485663, w1=11.034894865978712\n",
      "GD iter. 23/49: loss=65.93073010260338, w0=74.06780585490544, w1=11.034894865985985\n",
      "GD iter. 24/49: loss=65.93073010260338, w0=74.0678058549201, w1=11.034894865988166\n",
      "GD iter. 25/49: loss=65.93073010260338, w0=74.06780585492449, w1=11.034894865988822\n",
      "GD iter. 26/49: loss=65.93073010260338, w0=74.06780585492581, w1=11.034894865989017\n",
      "GD iter. 27/49: loss=65.93073010260338, w0=74.06780585492619, w1=11.034894865989076\n",
      "GD iter. 28/49: loss=65.93073010260338, w0=74.06780585492632, w1=11.034894865989093\n",
      "GD iter. 29/49: loss=65.93073010260338, w0=74.06780585492635, w1=11.0348948659891\n",
      "GD iter. 30/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 31/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 32/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 33/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 34/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 35/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 36/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 37/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 38/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 39/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 40/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 41/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 42/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 43/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 44/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 45/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 46/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 47/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 48/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 49/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD: execution time=0.002 seconds\n"
     ]
    }
   ],
   "source": [
    "from plots import gradient_descent_visualization\n",
    "\n",
    "# Define the parameters of the algorithm.\n",
    "max_iters = 50\n",
    "gamma = 0.7\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start gradient descent.\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "# ***************************************************\n",
    "# INSERT YOUR CODE HERE\n",
    "# TODO: fit the model to the subsampled data / subsampled data with outliers and visualize the cloud of points\n",
    "gd_losses, gd_ws = gradient_descent(y, tx, w_initial, max_iters, gamma)\n",
    "#       and the model fit\n",
    "# ***************************************************\n",
    "\n",
    "\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"GD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-26T14:05:42.742759081Z",
     "start_time": "2023-10-26T14:05:42.407960751Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "interactive(children=(IntSlider(value=1, description='n_iter', max=51, min=1), Output()), _dom_classes=('widge…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a1b2515e0dc347fbbcbf57bb3e388a64"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<function __main__.plot_figure(n_iter)>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time Visualization\n",
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        gd_losses,\n",
    "        gd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(gd_ws)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 6. Subgradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-26T14:05:42.744436317Z",
     "start_time": "2023-10-26T14:05:42.741863785Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_subgradient_mae(y, tx, w):\n",
    "    \"\"\"Compute a subgradient of the MAE at w.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        w: numpy array of shape=(2, ). The vector of model parameters.\n",
    "\n",
    "    Returns:\n",
    "        A numpy array of shape (2, ) (same shape as w), containing the subgradient of the MAE at w.\n",
    "    \"\"\"\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # TODO: compute subgradient gradient vector for MAE\n",
    "\n",
    "    #return -1/nb_sample * tx.T @ e\n",
    "    nb_sample = y.shape[0]\n",
    "    e = y - tx @ w\n",
    "    return -1/nb_sample * tx.T @ np.sign(e)\n",
    "    \n",
    "    # ***************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-26T14:05:42.745523494Z",
     "start_time": "2023-10-26T14:05:42.742202790Z"
    }
   },
   "outputs": [],
   "source": [
    "def subgradient_descent(y, tx, initial_w, max_iters, gamma):\n",
    "    \"\"\"The SubGradient Descent (SubGD) algorithm.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        initial_w: numpy array of shape=(2, ). The initial guess (or the initialization) for the model parameters\n",
    "        max_iters: a scalar denoting the total number of iterations of GD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "\n",
    "    Returns:\n",
    "        losses: a list of length max_iters containing the loss value (scalar) for each iteration of SubGD\n",
    "        ws: a list of length max_iters containing the model parameters as numpy arrays of shape (2, ), for each iteration of SubGD\n",
    "    \"\"\"\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        # ***************************************************\n",
    "        # INSERT YOUR CODE HERE\n",
    "        # TODO: compute subgradient and loss\n",
    "        # ***************************************************\n",
    "        loss = compute_loss_MAE(y, tx, w)\n",
    "        subgradient = compute_subgradient_mae(y, tx, w)\n",
    "        # ***************************************************\n",
    "        # INSERT YOUR CODE HERE\n",
    "        # TODO: update w by subgradient\n",
    "        w = w - gamma*subgradient\n",
    "        # ***************************************************\n",
    "\n",
    "        ws.append(w)\n",
    "        losses.append(loss)\n",
    "        print(\n",
    "            \"SubGD iter. {bi}/{ti}: loss={l}, w0={w0}, w1={w1}\".format(\n",
    "                bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-26T14:05:42.758287351Z",
     "start_time": "2023-10-26T14:05:42.742477367Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SubGD iter. 0/499: loss=74.06780585492638, w0=0.7000000000000004, w1=7.625844400394043e-16\n",
      "SubGD iter. 1/499: loss=73.36780585492637, w0=1.4000000000000008, w1=1.5251688800788087e-15\n",
      "SubGD iter. 2/499: loss=72.66780585492637, w0=2.1000000000000014, w1=2.287753320118213e-15\n",
      "SubGD iter. 3/499: loss=71.96780585492637, w0=2.8000000000000016, w1=3.0503377601576174e-15\n",
      "SubGD iter. 4/499: loss=71.26780585492638, w0=3.5000000000000018, w1=3.812922200197022e-15\n",
      "SubGD iter. 5/499: loss=70.56780585492639, w0=4.200000000000002, w1=4.575506640236426e-15\n",
      "SubGD iter. 6/499: loss=69.86780585492637, w0=4.900000000000002, w1=5.3380910802758305e-15\n",
      "SubGD iter. 7/499: loss=69.16780585492637, w0=5.600000000000002, w1=6.100675520315235e-15\n",
      "SubGD iter. 8/499: loss=68.46780585492637, w0=6.3000000000000025, w1=6.863259960354639e-15\n",
      "SubGD iter. 9/499: loss=67.76780585492638, w0=7.000000000000003, w1=7.625844400394044e-15\n",
      "SubGD iter. 10/499: loss=67.06780585492638, w0=7.700000000000003, w1=8.388428840433449e-15\n",
      "SubGD iter. 11/499: loss=66.36780585492637, w0=8.400000000000004, w1=9.151013280472854e-15\n",
      "SubGD iter. 12/499: loss=65.66780585492639, w0=9.100000000000005, w1=9.913597720512259e-15\n",
      "SubGD iter. 13/499: loss=64.96780585492637, w0=9.800000000000006, w1=1.0676182160551664e-14\n",
      "SubGD iter. 14/499: loss=64.26780585492638, w0=10.500000000000007, w1=1.1438766600591069e-14\n",
      "SubGD iter. 15/499: loss=63.56780585492637, w0=11.200000000000008, w1=1.2201351040630474e-14\n",
      "SubGD iter. 16/499: loss=62.867805854926374, w0=11.90000000000001, w1=1.2963935480669879e-14\n",
      "SubGD iter. 17/499: loss=62.16780585492637, w0=12.60000000000001, w1=1.3726519920709284e-14\n",
      "SubGD iter. 18/499: loss=61.46780585492636, w0=13.300000000000011, w1=1.448910436074869e-14\n",
      "SubGD iter. 19/499: loss=60.76780585492637, w0=14.000000000000012, w1=1.5251688800788094e-14\n",
      "SubGD iter. 20/499: loss=60.06780585492637, w0=14.700000000000014, w1=1.60142732408275e-14\n",
      "SubGD iter. 21/499: loss=59.36780585492637, w0=15.400000000000015, w1=1.6776857680866904e-14\n",
      "SubGD iter. 22/499: loss=58.667805854926364, w0=16.100000000000016, w1=1.753944212090631e-14\n",
      "SubGD iter. 23/499: loss=57.96780585492636, w0=16.800000000000015, w1=1.8302026560945714e-14\n",
      "SubGD iter. 24/499: loss=57.267805854926365, w0=17.500000000000014, w1=1.906461100098512e-14\n",
      "SubGD iter. 25/499: loss=56.56780585492637, w0=18.200000000000014, w1=1.9827195441024524e-14\n",
      "SubGD iter. 26/499: loss=55.86780585492637, w0=18.900000000000013, w1=2.058977988106393e-14\n",
      "SubGD iter. 27/499: loss=55.16780585492637, w0=19.600000000000012, w1=2.1352364321103335e-14\n",
      "SubGD iter. 28/499: loss=54.46780585492636, w0=20.30000000000001, w1=2.211494876114274e-14\n",
      "SubGD iter. 29/499: loss=53.767805854926365, w0=21.00000000000001, w1=2.2877533201182145e-14\n",
      "SubGD iter. 30/499: loss=53.06780585492637, w0=21.70000000000001, w1=2.364011764122155e-14\n",
      "SubGD iter. 31/499: loss=52.36780585492637, w0=22.40000000000001, w1=2.4402702081260955e-14\n",
      "SubGD iter. 32/499: loss=51.66780585492637, w0=23.10000000000001, w1=2.516528652130036e-14\n",
      "SubGD iter. 33/499: loss=50.96780585492636, w0=23.800000000000008, w1=2.5927870961339765e-14\n",
      "SubGD iter. 34/499: loss=50.26780585492637, w0=24.500000000000007, w1=2.669045540137917e-14\n",
      "SubGD iter. 35/499: loss=49.56780585492638, w0=25.200000000000006, w1=2.7453039841418575e-14\n",
      "SubGD iter. 36/499: loss=48.86780585492637, w0=25.900000000000006, w1=2.821562428145798e-14\n",
      "SubGD iter. 37/499: loss=48.16780585492637, w0=26.600000000000005, w1=2.8978208721497385e-14\n",
      "SubGD iter. 38/499: loss=47.46780585492637, w0=27.300000000000004, w1=2.9740793161536787e-14\n",
      "SubGD iter. 39/499: loss=46.76780585492637, w0=28.000000000000004, w1=3.050337760157619e-14\n",
      "SubGD iter. 40/499: loss=46.06780585492638, w0=28.700000000000003, w1=3.126596204161559e-14\n",
      "SubGD iter. 41/499: loss=45.367805854926374, w0=29.400000000000002, w1=3.202854648165499e-14\n",
      "SubGD iter. 42/499: loss=44.66780585492637, w0=30.1, w1=3.2791130921694394e-14\n",
      "SubGD iter. 43/499: loss=43.96780585492637, w0=30.8, w1=3.3553715361733796e-14\n",
      "SubGD iter. 44/499: loss=43.26780585492637, w0=31.5, w1=3.43162998017732e-14\n",
      "SubGD iter. 45/499: loss=42.567805854926384, w0=32.2, w1=3.50788842418126e-14\n",
      "SubGD iter. 46/499: loss=41.867805854926374, w0=32.900000000000006, w1=3.5841468681852e-14\n",
      "SubGD iter. 47/499: loss=41.16780585492638, w0=33.60000000000001, w1=3.6604053121891404e-14\n",
      "SubGD iter. 48/499: loss=40.46780585492637, w0=34.30000000000001, w1=3.7366637561930805e-14\n",
      "SubGD iter. 49/499: loss=39.767805854926365, w0=35.000000000000014, w1=3.812922200197021e-14\n",
      "SubGD iter. 50/499: loss=39.06780585492637, w0=35.70000000000002, w1=3.889180644200961e-14\n",
      "SubGD iter. 51/499: loss=38.36780585492637, w0=36.40000000000002, w1=3.965439088204901e-14\n",
      "SubGD iter. 52/499: loss=37.667805854926364, w0=37.10000000000002, w1=4.041697532208841e-14\n",
      "SubGD iter. 53/499: loss=36.967805854926354, w0=37.800000000000026, w1=4.1179559762127815e-14\n",
      "SubGD iter. 54/499: loss=36.26780585492636, w0=38.50000000000003, w1=4.1942144202167217e-14\n",
      "SubGD iter. 55/499: loss=35.56780585492635, w0=39.20000000000003, w1=4.270472864220662e-14\n",
      "SubGD iter. 56/499: loss=34.86780585492634, w0=39.900000000000034, w1=4.346731308224602e-14\n",
      "SubGD iter. 57/499: loss=34.16780585492634, w0=40.60000000000004, w1=4.422989752228542e-14\n",
      "SubGD iter. 58/499: loss=33.46780585492633, w0=41.30000000000004, w1=4.4992481962324824e-14\n",
      "SubGD iter. 59/499: loss=32.76780585492634, w0=42.00000000000004, w1=4.5755066402364226e-14\n",
      "SubGD iter. 60/499: loss=32.067805854926334, w0=42.700000000000045, w1=4.651765084240363e-14\n",
      "SubGD iter. 61/499: loss=31.36780585492633, w0=43.40000000000005, w1=4.728023528244303e-14\n",
      "SubGD iter. 62/499: loss=30.667805854926332, w0=44.10000000000005, w1=4.804281972248243e-14\n",
      "SubGD iter. 63/499: loss=29.967805854926326, w0=44.800000000000054, w1=4.8805404162521834e-14\n",
      "SubGD iter. 64/499: loss=29.267805854926323, w0=45.50000000000006, w1=4.9567988602561235e-14\n",
      "SubGD iter. 65/499: loss=28.56780585492632, w0=46.20000000000006, w1=5.033057304260064e-14\n",
      "SubGD iter. 66/499: loss=27.867805854926317, w0=46.90000000000006, w1=5.109315748264004e-14\n",
      "SubGD iter. 67/499: loss=27.173270209668893, w0=47.59306930693076, w1=0.011147845678281268\n",
      "SubGD iter. 68/499: loss=26.490451563751183, w0=48.279207920792146, w1=0.03308574108990965\n",
      "SubGD iter. 69/499: loss=25.817212322770157, w0=48.965346534653534, w1=0.055023636501538034\n",
      "SubGD iter. 70/499: loss=25.155039434656434, w0=49.630693069307, w1=0.10538326388308852\n",
      "SubGD iter. 71/499: loss=24.524103413894757, w0=50.28910891089116, w1=0.16746568532794484\n",
      "SubGD iter. 72/499: loss=23.89929534603557, w0=50.94752475247532, w1=0.22954810677280116\n",
      "SubGD iter. 73/499: loss=23.284392925657123, w0=51.59207920792086, w1=0.31242512932748595\n",
      "SubGD iter. 74/499: loss=22.686876444181824, w0=52.22277227722779, w1=0.4119501328840099\n",
      "SubGD iter. 75/499: loss=22.10626756964053, w0=52.84653465346541, w1=0.5208167847923866\n",
      "SubGD iter. 76/499: loss=21.53781882800841, w0=53.45643564356442, w1=0.6457900912636104\n",
      "SubGD iter. 77/499: loss=20.986339874628445, w0=54.059405940594125, w1=0.7796904498577328\n",
      "SubGD iter. 78/499: loss=20.44556093662042, w0=54.655445544554524, w1=0.9197570104995809\n",
      "SubGD iter. 79/499: loss=19.91191015895782, w0=55.244554455445616, w1=1.0670920297850033\n",
      "SubGD iter. 80/499: loss=19.389644090563205, w0=55.81980198019809, w1=1.2261255948210887\n",
      "SubGD iter. 81/499: loss=18.88798906439586, w0=56.36732673267334, w1=1.4107093426222252\n",
      "SubGD iter. 82/499: loss=18.41596050185421, w0=56.900990099009974, w1=1.6058537322202813\n",
      "SubGD iter. 83/499: loss=17.95489854304036, w0=57.4277227722773, w1=1.8087628022939741\n",
      "SubGD iter. 84/499: loss=17.505757656579803, w0=57.9336633663367, w1=2.0285064197514817\n",
      "SubGD iter. 85/499: loss=17.074957426931594, w0=58.4326732673268, w1=2.24943708486729\n",
      "SubGD iter. 86/499: loss=16.65296729750988, w0=58.91089108910898, w1=2.4837982986028466\n",
      "SubGD iter. 87/499: loss=16.248540731496703, w0=59.38217821782185, w1=2.7260245553531632\n",
      "SubGD iter. 88/499: loss=15.849105212654136, w0=59.83960396039611, w1=2.9787423334691487\n",
      "SubGD iter. 89/499: loss=15.466919791231307, w0=60.26237623762383, w1=3.251528669355451\n",
      "SubGD iter. 90/499: loss=15.108294621512195, w0=60.67821782178225, w1=3.5270865794242927\n",
      "SubGD iter. 91/499: loss=14.754896345922813, w0=61.087128712871355, w1=3.8064591839518287\n",
      "SubGD iter. 92/499: loss=14.404528961620256, w0=61.49603960396046, w1=4.085831788479364\n",
      "SubGD iter. 93/499: loss=14.055787028127256, w0=61.891089108910954, w1=4.373839384328622\n",
      "SubGD iter. 94/499: loss=13.714620911605614, w0=62.27920792079214, w1=4.666037469532062\n",
      "SubGD iter. 95/499: loss=13.381236307284132, w0=62.653465346534716, w1=4.959829093241784\n",
      "SubGD iter. 96/499: loss=13.058821615166217, w0=63.020792079207986, w1=5.257057192056655\n",
      "SubGD iter. 97/499: loss=12.740251724339217, w0=63.38118811881195, w1=5.560434316352422\n",
      "SubGD iter. 98/499: loss=12.42321888875609, w0=63.74158415841591, w1=5.86381144064819\n",
      "SubGD iter. 99/499: loss=12.10756173190115, w0=64.08811881188126, w1=6.172402175278565\n",
      "SubGD iter. 100/499: loss=11.800622097398117, w0=64.42772277227729, w1=6.486369310516515\n",
      "SubGD iter. 101/499: loss=11.495041794646406, w0=64.76732673267333, w1=6.800336445754466\n",
      "SubGD iter. 102/499: loss=11.189461491894695, w0=65.10693069306936, w1=7.114303580992416\n",
      "SubGD iter. 103/499: loss=10.883881189142983, w0=65.44653465346539, w1=7.428270716230367\n",
      "SubGD iter. 104/499: loss=10.584593408313182, w0=65.76534653465352, w1=7.747893210218644\n",
      "SubGD iter. 105/499: loss=10.295816534318924, w0=66.07029702970303, w1=8.073669686866923\n",
      "SubGD iter. 106/499: loss=10.011352081221341, w0=66.37524752475254, w1=8.399446163515202\n",
      "SubGD iter. 107/499: loss=9.72808432666811, w0=66.66633663366343, w1=8.732970280417408\n",
      "SubGD iter. 108/499: loss=9.448125461122489, w0=66.95742574257433, w1=9.066494397319614\n",
      "SubGD iter. 109/499: loss=9.171041104096652, w0=67.23465346534661, w1=9.398630319470307\n",
      "SubGD iter. 110/499: loss=8.903656131158945, w0=67.51188118811889, w1=9.730766241621\n",
      "SubGD iter. 111/499: loss=8.636271158221236, w0=67.78910891089117, w1=10.062902163771692\n",
      "SubGD iter. 112/499: loss=8.376151920302355, w0=68.06633663366345, w1=10.36399928997944\n",
      "SubGD iter. 113/499: loss=8.140540838751479, w0=68.32970297029712, w1=10.66046690927363\n",
      "SubGD iter. 114/499: loss=7.918544501597256, w0=68.59306930693079, w1=10.943174379960832\n",
      "SubGD iter. 115/499: loss=7.705279728376982, w0=68.85643564356445, w1=11.225881850648033\n",
      "SubGD iter. 116/499: loss=7.4936958311786235, w0=69.11287128712881, w1=11.504395843582225\n",
      "SubGD iter. 117/499: loss=7.289992405743398, w0=69.35544554455456, w1=11.78820189306777\n",
      "SubGD iter. 118/499: loss=7.0972340357815265, w0=69.58415841584169, w1=12.06091146519099\n",
      "SubGD iter. 119/499: loss=6.919905294668907, w0=69.8059405940595, w1=12.324245668386068\n",
      "SubGD iter. 120/499: loss=6.750573527315438, w0=70.02772277227733, w1=12.587579871581145\n",
      "SubGD iter. 121/499: loss=6.584744810805648, w0=70.25643564356446, w1=12.824765405096503\n",
      "SubGD iter. 122/499: loss=6.43034327634779, w0=70.47821782178228, w1=13.065616959310168\n",
      "SubGD iter. 123/499: loss=6.278071481890337, w0=70.6930693069308, w1=13.302953389983932\n",
      "SubGD iter. 124/499: loss=6.1336633292633085, w0=70.8940594059407, w1=13.525403099312937\n",
      "SubGD iter. 125/499: loss=6.005840798343017, w0=71.08811881188129, w1=13.742945617944232\n",
      "SubGD iter. 126/499: loss=5.885021825223205, w0=71.27524752475257, w1=13.953548196006865\n",
      "SubGD iter. 127/499: loss=5.771635252269645, w0=71.46237623762386, w1=14.1641507740695\n",
      "SubGD iter. 128/499: loss=5.667162061790244, w0=71.62178217821791, w1=14.349779559473198\n",
      "SubGD iter. 129/499: loss=5.586726765993134, w0=71.75346534653474, w1=14.516890107612335\n",
      "SubGD iter. 130/499: loss=5.523847812160379, w0=71.87128712871295, w1=14.67079118532421\n",
      "SubGD iter. 131/499: loss=5.4800937085918635, w0=71.95445544554464, w1=14.780276456654546\n",
      "SubGD iter. 132/499: loss=5.4530880035020175, w0=72.03762376237633, w1=14.889761727984881\n",
      "SubGD iter. 133/499: loss=5.427392630862901, w0=72.1069306930694, w1=14.985916181776751\n",
      "SubGD iter. 134/499: loss=5.407322445682746, w0=72.17623762376247, w1=15.082070635568622\n",
      "SubGD iter. 135/499: loss=5.387252260502593, w0=72.24554455445555, w1=15.178225089360492\n",
      "SubGD iter. 136/499: loss=5.370460780338691, w0=72.30099009901001, w1=15.259723489715935\n",
      "SubGD iter. 137/499: loss=5.3574065233347365, w0=72.34950495049516, w1=15.335091856448162\n",
      "SubGD iter. 138/499: loss=5.345929264022579, w0=72.39801980198031, w1=15.41046022318039\n",
      "SubGD iter. 139/499: loss=5.33571465951747, w0=72.43267326732685, w1=15.46996178675575\n",
      "SubGD iter. 140/499: loss=5.330043910465358, w0=72.46039603960408, w1=15.518645285832834\n",
      "SubGD iter. 141/499: loss=5.325676428273224, w0=72.48811881188131, w1=15.561592159086512\n",
      "SubGD iter. 142/499: loss=5.322176726526589, w0=72.50198019801992, w1=15.59782833203255\n",
      "SubGD iter. 143/499: loss=5.32011130964311, w0=72.52277227722784, w1=15.624722856626738\n",
      "SubGD iter. 144/499: loss=5.318478284898437, w0=72.55049504950507, w1=15.642690329098025\n",
      "SubGD iter. 145/499: loss=5.317240048565144, w0=72.56435643564369, w1=15.664356578291116\n",
      "SubGD iter. 146/499: loss=5.316406547951545, w0=72.58514851485161, w1=15.677095775361309\n",
      "SubGD iter. 147/499: loss=5.315557122666142, w0=72.60594059405953, w1=15.689834972431502\n",
      "SubGD iter. 148/499: loss=5.314707697380738, w0=72.62673267326745, w1=15.702574169501695\n",
      "SubGD iter. 149/499: loss=5.313876880922166, w0=72.64059405940607, w1=15.724240418694786\n",
      "SubGD iter. 150/499: loss=5.313052246871382, w0=72.66138613861399, w1=15.736979615764978\n",
      "SubGD iter. 151/499: loss=5.312377839024388, w0=72.6683168316833, w1=15.748110294231305\n",
      "SubGD iter. 152/499: loss=5.312132229725042, w0=72.6752475247526, w1=15.759240972697631\n",
      "SubGD iter. 153/499: loss=5.311886620425697, w0=72.68217821782191, w1=15.770371651163957\n",
      "SubGD iter. 154/499: loss=5.311683566098434, w0=72.68217821782191, w1=15.774323911906711\n",
      "SubGD iter. 155/499: loss=5.311661251291322, w0=72.68217821782191, w1=15.778276172649464\n",
      "SubGD iter. 156/499: loss=5.311638936484209, w0=72.68217821782191, w1=15.782228433392218\n",
      "SubGD iter. 157/499: loss=5.311616621677096, w0=72.68217821782191, w1=15.786180694134972\n",
      "SubGD iter. 158/499: loss=5.311594306869985, w0=72.68217821782191, w1=15.790132954877725\n",
      "SubGD iter. 159/499: loss=5.311571992062872, w0=72.68217821782191, w1=15.794085215620479\n",
      "SubGD iter. 160/499: loss=5.311549677255759, w0=72.68217821782191, w1=15.798037476363232\n",
      "SubGD iter. 161/499: loss=5.311527362448647, w0=72.68217821782191, w1=15.801989737105986\n",
      "SubGD iter. 162/499: loss=5.3115050476415355, w0=72.68217821782191, w1=15.80594199784874\n",
      "SubGD iter. 163/499: loss=5.311482732834422, w0=72.68217821782191, w1=15.809894258591493\n",
      "SubGD iter. 164/499: loss=5.311460418027309, w0=72.68217821782191, w1=15.813846519334247\n",
      "SubGD iter. 165/499: loss=5.311438103220198, w0=72.68217821782191, w1=15.817798780077\n",
      "SubGD iter. 166/499: loss=5.311415788413084, w0=72.68217821782191, w1=15.821751040819754\n",
      "SubGD iter. 167/499: loss=5.311393473605972, w0=72.68217821782191, w1=15.825703301562507\n",
      "SubGD iter. 168/499: loss=5.311371158798861, w0=72.68217821782191, w1=15.82965556230526\n",
      "SubGD iter. 169/499: loss=5.311348843991747, w0=72.68217821782191, w1=15.833607823048014\n",
      "SubGD iter. 170/499: loss=5.311326529184636, w0=72.68217821782191, w1=15.837560083790768\n",
      "SubGD iter. 171/499: loss=5.3113042143775235, w0=72.68217821782191, w1=15.841512344533522\n",
      "SubGD iter. 172/499: loss=5.311281899570409, w0=72.68217821782191, w1=15.845464605276275\n",
      "SubGD iter. 173/499: loss=5.311259584763298, w0=72.68217821782191, w1=15.849416866019029\n",
      "SubGD iter. 174/499: loss=5.311237269956186, w0=72.68217821782191, w1=15.853369126761782\n",
      "SubGD iter. 175/499: loss=5.3112149551490715, w0=72.68217821782191, w1=15.857321387504536\n",
      "SubGD iter. 176/499: loss=5.31119264034196, w0=72.68217821782191, w1=15.86127364824729\n",
      "SubGD iter. 177/499: loss=5.311170325534848, w0=72.68217821782191, w1=15.865225908990043\n",
      "SubGD iter. 178/499: loss=5.311148010727736, w0=72.68217821782191, w1=15.869178169732796\n",
      "SubGD iter. 179/499: loss=5.311125695920623, w0=72.68217821782191, w1=15.87313043047555\n",
      "SubGD iter. 180/499: loss=5.3111033811135115, w0=72.68217821782191, w1=15.877082691218304\n",
      "SubGD iter. 181/499: loss=5.311081066306398, w0=72.68217821782191, w1=15.881034951961057\n",
      "SubGD iter. 182/499: loss=5.311058751499286, w0=72.68217821782191, w1=15.88498721270381\n",
      "SubGD iter. 183/499: loss=5.311036436692174, w0=72.68217821782191, w1=15.888939473446564\n",
      "SubGD iter. 184/499: loss=5.31101412188506, w0=72.68217821782191, w1=15.892891734189318\n",
      "SubGD iter. 185/499: loss=5.310991807077948, w0=72.68217821782191, w1=15.896843994932071\n",
      "SubGD iter. 186/499: loss=5.310969492270836, w0=72.68217821782191, w1=15.900796255674825\n",
      "SubGD iter. 187/499: loss=5.3109471774637225, w0=72.68217821782191, w1=15.904748516417579\n",
      "SubGD iter. 188/499: loss=5.310924862656612, w0=72.68217821782191, w1=15.908700777160332\n",
      "SubGD iter. 189/499: loss=5.310902547849499, w0=72.68217821782191, w1=15.912653037903086\n",
      "SubGD iter. 190/499: loss=5.310913706061381, w0=72.6752475247526, w1=15.910526938117348\n",
      "SubGD iter. 191/499: loss=5.31089223718627, w0=72.6752475247526, w1=15.914479198860102\n",
      "SubGD iter. 192/499: loss=5.3108699223791564, w0=72.6752475247526, w1=15.918431459602855\n",
      "SubGD iter. 193/499: loss=5.310862636053835, w0=72.6683168316833, w1=15.916305359817118\n",
      "SubGD iter. 194/499: loss=5.310859611715927, w0=72.6683168316833, w1=15.920257620559871\n",
      "SubGD iter. 195/499: loss=5.310837296908815, w0=72.6683168316833, w1=15.924209881302625\n",
      "SubGD iter. 196/499: loss=5.310814982101703, w0=72.6683168316833, w1=15.928162142045379\n",
      "SubGD iter. 197/499: loss=5.310823570190171, w0=72.66138613861399, w1=15.926036042259641\n",
      "SubGD iter. 198/499: loss=5.310804671438475, w0=72.66138613861399, w1=15.929988303002395\n",
      "SubGD iter. 199/499: loss=5.3107823566313614, w0=72.66138613861399, w1=15.933940563745148\n",
      "SubGD iter. 200/499: loss=5.310772500182622, w0=72.65445544554468, w1=15.93181446395941\n",
      "SubGD iter. 201/499: loss=5.3107720459681325, w0=72.65445544554468, w1=15.935766724702164\n",
      "SubGD iter. 202/499: loss=5.310749731161019, w0=72.65445544554468, w1=15.939718985444918\n",
      "SubGD iter. 203/499: loss=5.310727416353908, w0=72.65445544554468, w1=15.943671246187671\n",
      "SubGD iter. 204/499: loss=5.31073343431896, w0=72.64752475247538, w1=15.941545146401934\n",
      "SubGD iter. 205/499: loss=5.310717105690678, w0=72.64752475247538, w1=15.945497407144687\n",
      "SubGD iter. 206/499: loss=5.3106947908835656, w0=72.64752475247538, w1=15.949449667887441\n",
      "SubGD iter. 207/499: loss=5.310682364311412, w0=72.64059405940607, w1=15.947323568101703\n",
      "SubGD iter. 208/499: loss=5.3106844802203375, w0=72.64059405940607, w1=15.951275828844457\n",
      "SubGD iter. 209/499: loss=5.310662165413224, w0=72.64059405940607, w1=15.95522808958721\n",
      "SubGD iter. 210/499: loss=5.310639850606112, w0=72.64059405940607, w1=15.959180350329964\n",
      "SubGD iter. 211/499: loss=5.310643298447748, w0=72.63366336633676, w1=15.957054250544227\n",
      "SubGD iter. 212/499: loss=5.310629539942882, w0=72.63366336633676, w1=15.96100651128698\n",
      "SubGD iter. 213/499: loss=5.3106072251357705, w0=72.63366336633676, w1=15.964958772029734\n",
      "SubGD iter. 214/499: loss=5.3105922284402, w0=72.62673267326745, w1=15.962832672243996\n",
      "SubGD iter. 215/499: loss=5.310633183099026, w0=72.63366336633676, w1=15.9673013720514\n",
      "SubGD iter. 216/499: loss=5.3105993435850625, w0=72.62673267326745, w1=15.965175272265663\n",
      "SubGD iter. 217/499: loss=5.31061822827579, w0=72.63366336633676, w1=15.969643972073067\n",
      "SubGD iter. 218/499: loss=5.310606458729926, w0=72.62673267326745, w1=15.96751787228733\n",
      "SubGD iter. 219/499: loss=5.310603273452553, w0=72.63366336633676, w1=15.971986572094734\n",
      "SubGD iter. 220/499: loss=5.31061357387479, w0=72.62673267326745, w1=15.969860472308996\n",
      "SubGD iter. 221/499: loss=5.310588318629315, w0=72.63366336633676, w1=15.9743291721164\n",
      "SubGD iter. 222/499: loss=5.310620689019653, w0=72.62673267326745, w1=15.972203072330663\n",
      "SubGD iter. 223/499: loss=5.3105749661498844, w0=72.62673267326745, w1=15.970593411609576\n",
      "SubGD iter. 224/499: loss=5.310583639649727, w0=72.63366336633676, w1=15.97506211141698\n",
      "SubGD iter. 225/499: loss=5.310622915165494, w0=72.62673267326745, w1=15.972936011631242\n",
      "SubGD iter. 226/499: loss=5.310576651555033, w0=72.62673267326745, w1=15.971326350910156\n",
      "SubGD iter. 227/499: loss=5.31057896067014, w0=72.63366336633676, w1=15.97579505071756\n",
      "SubGD iter. 228/499: loss=5.310625141311338, w0=72.62673267326745, w1=15.973668950931822\n",
      "SubGD iter. 229/499: loss=5.31057833696018, w0=72.62673267326745, w1=15.972059290210735\n",
      "SubGD iter. 230/499: loss=5.310574635520699, w0=72.62673267326745, w1=15.970449629489648\n",
      "SubGD iter. 231/499: loss=5.310584557534202, w0=72.63366336633676, w1=15.974918329297052\n",
      "SubGD iter. 232/499: loss=5.31062247845816, w0=72.62673267326745, w1=15.972792229511315\n",
      "SubGD iter. 233/499: loss=5.310576320925845, w0=72.62673267326745, w1=15.971182568790228\n",
      "SubGD iter. 234/499: loss=5.3105798785546146, w0=72.63366336633676, w1=15.975651268597632\n",
      "SubGD iter. 235/499: loss=5.310624704604003, w0=72.62673267326745, w1=15.973525168811895\n",
      "SubGD iter. 236/499: loss=5.310578006330994, w0=72.62673267326745, w1=15.971915508090808\n",
      "SubGD iter. 237/499: loss=5.310575199575027, w0=72.63366336633676, w1=15.976384207898212\n",
      "SubGD iter. 238/499: loss=5.310626930749845, w0=72.62673267326745, w1=15.974258108112474\n",
      "SubGD iter. 239/499: loss=5.310579691736141, w0=72.62673267326745, w1=15.972648447391387\n",
      "SubGD iter. 240/499: loss=5.310575990296659, w0=72.62673267326745, w1=15.9710387866703\n",
      "SubGD iter. 241/499: loss=5.310580796439088, w0=72.63366336633676, w1=15.975507486477705\n",
      "SubGD iter. 242/499: loss=5.310624267896666, w0=72.62673267326745, w1=15.973381386691967\n",
      "SubGD iter. 243/499: loss=5.310577675701806, w0=72.62673267326745, w1=15.97177172597088\n",
      "SubGD iter. 244/499: loss=5.3105761174595, w0=72.63366336633676, w1=15.976240425778284\n",
      "SubGD iter. 245/499: loss=5.31062649404251, w0=72.62673267326745, w1=15.974114325992547\n",
      "SubGD iter. 246/499: loss=5.310579361106954, w0=72.62673267326745, w1=15.97250466527146\n",
      "SubGD iter. 247/499: loss=5.310575659667473, w0=72.62673267326745, w1=15.970895004550373\n",
      "SubGD iter. 248/499: loss=5.310581714323562, w0=72.63366336633676, w1=15.975363704357777\n",
      "SubGD iter. 249/499: loss=5.310623831189333, w0=72.62673267326745, w1=15.97323760457204\n",
      "SubGD iter. 250/499: loss=5.310577345072619, w0=72.62673267326745, w1=15.971627943850953\n",
      "SubGD iter. 251/499: loss=5.310577035343974, w0=72.63366336633676, w1=15.976096643658357\n",
      "SubGD iter. 252/499: loss=5.310626057335176, w0=72.62673267326745, w1=15.97397054387262\n",
      "SubGD iter. 253/499: loss=5.310579030477768, w0=72.62673267326745, w1=15.972360883151532\n",
      "SubGD iter. 254/499: loss=5.3105753290382856, w0=72.62673267326745, w1=15.970751222430446\n",
      "SubGD iter. 255/499: loss=5.310582632208036, w0=72.63366336633676, w1=15.97521992223785\n",
      "SubGD iter. 256/499: loss=5.310623394481998, w0=72.62673267326745, w1=15.973093822452112\n",
      "SubGD iter. 257/499: loss=5.3105770144434326, w0=72.62673267326745, w1=15.971484161731025\n",
      "SubGD iter. 258/499: loss=5.3105779532284485, w0=72.63366336633676, w1=15.97595286153843\n",
      "SubGD iter. 259/499: loss=5.3106256206278415, w0=72.62673267326745, w1=15.973826761752692\n",
      "SubGD iter. 260/499: loss=5.310578699848579, w0=72.62673267326745, w1=15.972217101031605\n",
      "SubGD iter. 261/499: loss=5.310574998409099, w0=72.62673267326745, w1=15.970607440310518\n",
      "SubGD iter. 262/499: loss=5.3105835500925105, w0=72.63366336633676, w1=15.975076140117922\n",
      "SubGD iter. 263/499: loss=5.3106229577746635, w0=72.62673267326745, w1=15.972950040332185\n",
      "SubGD iter. 264/499: loss=5.310576683814246, w0=72.62673267326745, w1=15.971340379611098\n",
      "SubGD iter. 265/499: loss=5.310578871112921, w0=72.63366336633676, w1=15.975809079418502\n",
      "SubGD iter. 266/499: loss=5.310625183920507, w0=72.62673267326745, w1=15.973682979632764\n",
      "SubGD iter. 267/499: loss=5.310578369219392, w0=72.62673267326745, w1=15.972073318911677\n",
      "SubGD iter. 268/499: loss=5.310574667779911, w0=72.62673267326745, w1=15.97046365819059\n",
      "SubGD iter. 269/499: loss=5.310584467976983, w0=72.63366336633676, w1=15.974932357997995\n",
      "SubGD iter. 270/499: loss=5.310622521067329, w0=72.62673267326745, w1=15.972806258212257\n",
      "SubGD iter. 271/499: loss=5.310576353185058, w0=72.62673267326745, w1=15.97119659749117\n",
      "SubGD iter. 272/499: loss=5.310579788997397, w0=72.63366336633676, w1=15.975665297298574\n",
      "SubGD iter. 273/499: loss=5.310624747213173, w0=72.62673267326745, w1=15.973539197512837\n",
      "SubGD iter. 274/499: loss=5.310578038590206, w0=72.62673267326745, w1=15.97192953679175\n",
      "SubGD iter. 275/499: loss=5.310575110017809, w0=72.63366336633676, w1=15.976398236599154\n",
      "SubGD iter. 276/499: loss=5.310626973359014, w0=72.62673267326745, w1=15.974272136813417\n",
      "SubGD iter. 277/499: loss=5.310579723995353, w0=72.62673267326745, w1=15.97266247609233\n",
      "SubGD iter. 278/499: loss=5.310576022555871, w0=72.62673267326745, w1=15.971052815371243\n",
      "SubGD iter. 279/499: loss=5.310580706881869, w0=72.63366336633676, w1=15.975521515178647\n",
      "SubGD iter. 280/499: loss=5.310624310505837, w0=72.62673267326745, w1=15.97339541539291\n",
      "SubGD iter. 281/499: loss=5.310577707961018, w0=72.62673267326745, w1=15.971785754671822\n",
      "SubGD iter. 282/499: loss=5.310576027902282, w0=72.63366336633676, w1=15.976254454479227\n",
      "SubGD iter. 283/499: loss=5.31062653665168, w0=72.62673267326745, w1=15.97412835469349\n",
      "SubGD iter. 284/499: loss=5.310579393366166, w0=72.62673267326745, w1=15.972518693972402\n",
      "SubGD iter. 285/499: loss=5.310575691926685, w0=72.62673267326745, w1=15.970909033251315\n",
      "SubGD iter. 286/499: loss=5.310581624766343, w0=72.63366336633676, w1=15.97537773305872\n",
      "SubGD iter. 287/499: loss=5.310623873798502, w0=72.62673267326745, w1=15.973251633272982\n",
      "SubGD iter. 288/499: loss=5.310577377331833, w0=72.62673267326745, w1=15.971641972551895\n",
      "SubGD iter. 289/499: loss=5.310576945786757, w0=72.63366336633676, w1=15.9761106723593\n",
      "SubGD iter. 290/499: loss=5.310626099944345, w0=72.62673267326745, w1=15.973984572573562\n",
      "SubGD iter. 291/499: loss=5.310579062736979, w0=72.62673267326745, w1=15.972374911852475\n",
      "SubGD iter. 292/499: loss=5.310575361297499, w0=72.62673267326745, w1=15.970765251131388\n",
      "SubGD iter. 293/499: loss=5.310582542650818, w0=72.63366336633676, w1=15.975233950938792\n",
      "SubGD iter. 294/499: loss=5.310623437091167, w0=72.62673267326745, w1=15.973107851153054\n",
      "SubGD iter. 295/499: loss=5.310577046702646, w0=72.62673267326745, w1=15.971498190431968\n",
      "SubGD iter. 296/499: loss=5.310577863671229, w0=72.63366336633676, w1=15.975966890239372\n",
      "SubGD iter. 297/499: loss=5.310625663237011, w0=72.62673267326745, w1=15.973840790453634\n",
      "SubGD iter. 298/499: loss=5.310578732107793, w0=72.62673267326745, w1=15.972231129732547\n",
      "SubGD iter. 299/499: loss=5.310575030668311, w0=72.62673267326745, w1=15.97062146901146\n",
      "SubGD iter. 300/499: loss=5.310583460535291, w0=72.63366336633676, w1=15.975090168818864\n",
      "SubGD iter. 301/499: loss=5.310623000383833, w0=72.62673267326745, w1=15.972964069033127\n",
      "SubGD iter. 302/499: loss=5.3105767160734585, w0=72.62673267326745, w1=15.97135440831204\n",
      "SubGD iter. 303/499: loss=5.310578781555704, w0=72.63366336633676, w1=15.975823108119444\n",
      "SubGD iter. 304/499: loss=5.310625226529674, w0=72.62673267326745, w1=15.973697008333707\n",
      "SubGD iter. 305/499: loss=5.3105784014786055, w0=72.62673267326745, w1=15.97208734761262\n",
      "SubGD iter. 306/499: loss=5.3105747000391235, w0=72.62673267326745, w1=15.970477686891533\n",
      "SubGD iter. 307/499: loss=5.3105843784197635, w0=72.63366336633676, w1=15.974946386698937\n",
      "SubGD iter. 308/499: loss=5.310622563676499, w0=72.62673267326745, w1=15.9728202869132\n",
      "SubGD iter. 309/499: loss=5.310576385444271, w0=72.62673267326745, w1=15.971210626192113\n",
      "SubGD iter. 310/499: loss=5.310579699440177, w0=72.63366336633676, w1=15.975679325999517\n",
      "SubGD iter. 311/499: loss=5.310624789822341, w0=72.62673267326745, w1=15.97355322621378\n",
      "SubGD iter. 312/499: loss=5.3105780708494175, w0=72.62673267326745, w1=15.971943565492692\n",
      "SubGD iter. 313/499: loss=5.310575020460588, w0=72.63366336633676, w1=15.976412265300096\n",
      "SubGD iter. 314/499: loss=5.310627015968183, w0=72.62673267326745, w1=15.974286165514359\n",
      "SubGD iter. 315/499: loss=5.310579756254565, w0=72.62673267326745, w1=15.972676504793272\n",
      "SubGD iter. 316/499: loss=5.310576054815085, w0=72.62673267326745, w1=15.971066844072185\n",
      "SubGD iter. 317/499: loss=5.310580617324651, w0=72.63366336633676, w1=15.97553554387959\n",
      "SubGD iter. 318/499: loss=5.3106243531150055, w0=72.62673267326745, w1=15.973409444093852\n",
      "SubGD iter. 319/499: loss=5.310577740220231, w0=72.62673267326745, w1=15.971799783372765\n",
      "SubGD iter. 320/499: loss=5.310575938345063, w0=72.63366336633676, w1=15.976268483180169\n",
      "SubGD iter. 321/499: loss=5.310626579260849, w0=72.62673267326745, w1=15.974142383394431\n",
      "SubGD iter. 322/499: loss=5.310579425625379, w0=72.62673267326745, w1=15.972532722673344\n",
      "SubGD iter. 323/499: loss=5.310575724185898, w0=72.62673267326745, w1=15.970923061952258\n",
      "SubGD iter. 324/499: loss=5.310581535209124, w0=72.63366336633676, w1=15.975391761759662\n",
      "SubGD iter. 325/499: loss=5.310623916407671, w0=72.62673267326745, w1=15.973265661973924\n",
      "SubGD iter. 326/499: loss=5.310577409591045, w0=72.62673267326745, w1=15.971656001252837\n",
      "SubGD iter. 327/499: loss=5.310576856229537, w0=72.63366336633676, w1=15.976124701060241\n",
      "SubGD iter. 328/499: loss=5.310626142553515, w0=72.62673267326745, w1=15.973998601274504\n",
      "SubGD iter. 329/499: loss=5.310579094996193, w0=72.62673267326745, w1=15.972388940553417\n",
      "SubGD iter. 330/499: loss=5.310575393556711, w0=72.62673267326745, w1=15.97077927983233\n",
      "SubGD iter. 331/499: loss=5.310582453093599, w0=72.63366336633676, w1=15.975247979639734\n",
      "SubGD iter. 332/499: loss=5.310623479700335, w0=72.62673267326745, w1=15.973121879853997\n",
      "SubGD iter. 333/499: loss=5.310577078961858, w0=72.62673267326745, w1=15.97151221913291\n",
      "SubGD iter. 334/499: loss=5.3105777741140106, w0=72.63366336633676, w1=15.975980918940314\n",
      "SubGD iter. 335/499: loss=5.310625705846178, w0=72.62673267326745, w1=15.973854819154576\n",
      "SubGD iter. 336/499: loss=5.310578764367006, w0=72.62673267326745, w1=15.97224515843349\n",
      "SubGD iter. 337/499: loss=5.310575062927523, w0=72.62673267326745, w1=15.970635497712403\n",
      "SubGD iter. 338/499: loss=5.3105833709780725, w0=72.63366336633676, w1=15.975104197519807\n",
      "SubGD iter. 339/499: loss=5.310623042993001, w0=72.62673267326745, w1=15.97297809773407\n",
      "SubGD iter. 340/499: loss=5.31057674833267, w0=72.62673267326745, w1=15.971368437012982\n",
      "SubGD iter. 341/499: loss=5.310578691998485, w0=72.63366336633676, w1=15.975837136820386\n",
      "SubGD iter. 342/499: loss=5.310625269138844, w0=72.62673267326745, w1=15.973711037034649\n",
      "SubGD iter. 343/499: loss=5.310578433737818, w0=72.62673267326745, w1=15.972101376313562\n",
      "SubGD iter. 344/499: loss=5.310574732298337, w0=72.62673267326745, w1=15.970491715592475\n",
      "SubGD iter. 345/499: loss=5.310584288862548, w0=72.63366336633676, w1=15.97496041539988\n",
      "SubGD iter. 346/499: loss=5.310622606285666, w0=72.62673267326745, w1=15.972834315614142\n",
      "SubGD iter. 347/499: loss=5.3105764177034835, w0=72.62673267326745, w1=15.971224654893055\n",
      "SubGD iter. 348/499: loss=5.310579609882959, w0=72.63366336633676, w1=15.975693354700459\n",
      "SubGD iter. 349/499: loss=5.310624832431509, w0=72.62673267326745, w1=15.973567254914721\n",
      "SubGD iter. 350/499: loss=5.310578103108631, w0=72.62673267326745, w1=15.971957594193634\n",
      "SubGD iter. 351/499: loss=5.310574930903369, w0=72.63366336633676, w1=15.976426294001039\n",
      "SubGD iter. 352/499: loss=5.310627058577351, w0=72.62673267326745, w1=15.974300194215301\n",
      "SubGD iter. 353/499: loss=5.310579788513779, w0=72.62673267326745, w1=15.972690533494214\n",
      "SubGD iter. 354/499: loss=5.310576087074297, w0=72.62673267326745, w1=15.971080872773127\n",
      "SubGD iter. 355/499: loss=5.310580527767432, w0=72.63366336633676, w1=15.975549572580531\n",
      "SubGD iter. 356/499: loss=5.310624395724174, w0=72.62673267326745, w1=15.973423472794794\n",
      "SubGD iter. 357/499: loss=5.310577772479444, w0=72.62673267326745, w1=15.971813812073707\n",
      "SubGD iter. 358/499: loss=5.3105758487878445, w0=72.63366336633676, w1=15.976282511881111\n",
      "SubGD iter. 359/499: loss=5.310626621870017, w0=72.62673267326745, w1=15.974156412095374\n",
      "SubGD iter. 360/499: loss=5.310579457884592, w0=72.62673267326745, w1=15.972546751374287\n",
      "SubGD iter. 361/499: loss=5.310575756445111, w0=72.62673267326745, w1=15.9709370906532\n",
      "SubGD iter. 362/499: loss=5.310581445651906, w0=72.63366336633676, w1=15.975405790460604\n",
      "SubGD iter. 363/499: loss=5.310623959016838, w0=72.62673267326745, w1=15.973279690674866\n",
      "SubGD iter. 364/499: loss=5.310577441850257, w0=72.62673267326745, w1=15.97167002995378\n",
      "SubGD iter. 365/499: loss=5.310576766672318, w0=72.63366336633676, w1=15.976138729761184\n",
      "SubGD iter. 366/499: loss=5.310626185162682, w0=72.62673267326745, w1=15.974012629975446\n",
      "SubGD iter. 367/499: loss=5.310579127255404, w0=72.62673267326745, w1=15.97240296925436\n",
      "SubGD iter. 368/499: loss=5.310575425815922, w0=72.62673267326745, w1=15.970793308533272\n",
      "SubGD iter. 369/499: loss=5.310582363536379, w0=72.63366336633676, w1=15.975262008340676\n",
      "SubGD iter. 370/499: loss=5.310623522309504, w0=72.62673267326745, w1=15.973135908554939\n",
      "SubGD iter. 371/499: loss=5.31057711122107, w0=72.62673267326745, w1=15.971526247833852\n",
      "SubGD iter. 372/499: loss=5.310577684556793, w0=72.63366336633676, w1=15.975994947641256\n",
      "SubGD iter. 373/499: loss=5.310625748455347, w0=72.62673267326745, w1=15.973868847855519\n",
      "SubGD iter. 374/499: loss=5.310578796626218, w0=72.62673267326745, w1=15.972259187134432\n",
      "SubGD iter. 375/499: loss=5.310575095186736, w0=72.62673267326745, w1=15.970649526413345\n",
      "SubGD iter. 376/499: loss=5.310583281420853, w0=72.63366336633676, w1=15.975118226220749\n",
      "SubGD iter. 377/499: loss=5.3106230856021694, w0=72.62673267326745, w1=15.972992126435011\n",
      "SubGD iter. 378/499: loss=5.310576780591883, w0=72.62673267326745, w1=15.971382465713925\n",
      "SubGD iter. 379/499: loss=5.310578602441265, w0=72.63366336633676, w1=15.975851165521329\n",
      "SubGD iter. 380/499: loss=5.310625311748013, w0=72.62673267326745, w1=15.973725065735591\n",
      "SubGD iter. 381/499: loss=5.310578465997032, w0=72.62673267326745, w1=15.972115405014504\n",
      "SubGD iter. 382/499: loss=5.310574764557549, w0=72.62673267326745, w1=15.970505744293417\n",
      "SubGD iter. 383/499: loss=5.310584199305326, w0=72.63366336633676, w1=15.974974444100821\n",
      "SubGD iter. 384/499: loss=5.310622648894835, w0=72.62673267326745, w1=15.972848344315084\n",
      "SubGD iter. 385/499: loss=5.310576449962697, w0=72.62673267326745, w1=15.971238683593997\n",
      "SubGD iter. 386/499: loss=5.310579520325739, w0=72.63366336633676, w1=15.975707383401401\n",
      "SubGD iter. 387/499: loss=5.310624875040678, w0=72.62673267326745, w1=15.973581283615664\n",
      "SubGD iter. 388/499: loss=5.3105781353678445, w0=72.62673267326745, w1=15.971971622894577\n",
      "SubGD iter. 389/499: loss=5.310574841346151, w0=72.63366336633676, w1=15.976440322701981\n",
      "SubGD iter. 390/499: loss=5.31062710118652, w0=72.62673267326745, w1=15.974314222916243\n",
      "SubGD iter. 391/499: loss=5.3105798207729915, w0=72.62673267326745, w1=15.972704562195156\n",
      "SubGD iter. 392/499: loss=5.3105761193335095, w0=72.62673267326745, w1=15.97109490147407\n",
      "SubGD iter. 393/499: loss=5.310580438210213, w0=72.63366336633676, w1=15.975563601281474\n",
      "SubGD iter. 394/499: loss=5.310624438333342, w0=72.62673267326745, w1=15.973437501495736\n",
      "SubGD iter. 395/499: loss=5.3105778047386565, w0=72.62673267326745, w1=15.97182784077465\n",
      "SubGD iter. 396/499: loss=5.310575759230625, w0=72.63366336633676, w1=15.976296540582053\n",
      "SubGD iter. 397/499: loss=5.3106266644791855, w0=72.62673267326745, w1=15.974170440796316\n",
      "SubGD iter. 398/499: loss=5.310579490143805, w0=72.62673267326745, w1=15.972560780075229\n",
      "SubGD iter. 399/499: loss=5.310575788704322, w0=72.62673267326745, w1=15.970951119354142\n",
      "SubGD iter. 400/499: loss=5.310581356094687, w0=72.63366336633676, w1=15.975419819161546\n",
      "SubGD iter. 401/499: loss=5.310624001626008, w0=72.62673267326745, w1=15.973293719375809\n",
      "SubGD iter. 402/499: loss=5.31057747410947, w0=72.62673267326745, w1=15.971684058654722\n",
      "SubGD iter. 403/499: loss=5.310576677115099, w0=72.63366336633676, w1=15.976152758462126\n",
      "SubGD iter. 404/499: loss=5.310626227771851, w0=72.62673267326745, w1=15.974026658676388\n",
      "SubGD iter. 405/499: loss=5.310579159514617, w0=72.62673267326745, w1=15.972416997955301\n",
      "SubGD iter. 406/499: loss=5.310575458075135, w0=72.62673267326745, w1=15.970807337234215\n",
      "SubGD iter. 407/499: loss=5.31058227397916, w0=72.63366336633676, w1=15.975276037041619\n",
      "SubGD iter. 408/499: loss=5.310623564918673, w0=72.62673267326745, w1=15.973149937255881\n",
      "SubGD iter. 409/499: loss=5.310577143480284, w0=72.62673267326745, w1=15.971540276534794\n",
      "SubGD iter. 410/499: loss=5.3105775949995735, w0=72.63366336633676, w1=15.976008976342198\n",
      "SubGD iter. 411/499: loss=5.310625791064516, w0=72.62673267326745, w1=15.97388287655646\n",
      "SubGD iter. 412/499: loss=5.310578828885431, w0=72.62673267326745, w1=15.972273215835374\n",
      "SubGD iter. 413/499: loss=5.310575127445949, w0=72.62673267326745, w1=15.970663555114287\n",
      "SubGD iter. 414/499: loss=5.310583191863635, w0=72.63366336633676, w1=15.975132254921691\n",
      "SubGD iter. 415/499: loss=5.310623128211339, w0=72.62673267326745, w1=15.973006155135954\n",
      "SubGD iter. 416/499: loss=5.310576812851097, w0=72.62673267326745, w1=15.971396494414867\n",
      "SubGD iter. 417/499: loss=5.310578512884047, w0=72.63366336633676, w1=15.975865194222271\n",
      "SubGD iter. 418/499: loss=5.31062535435718, w0=72.62673267326745, w1=15.973739094436533\n",
      "SubGD iter. 419/499: loss=5.310578498256244, w0=72.62673267326745, w1=15.972129433715446\n",
      "SubGD iter. 420/499: loss=5.310574796816762, w0=72.62673267326745, w1=15.97051977299436\n",
      "SubGD iter. 421/499: loss=5.310584109748107, w0=72.63366336633676, w1=15.974988472801764\n",
      "SubGD iter. 422/499: loss=5.310622691504004, w0=72.62673267326745, w1=15.972862373016026\n",
      "SubGD iter. 423/499: loss=5.310576482221909, w0=72.62673267326745, w1=15.97125271229494\n",
      "SubGD iter. 424/499: loss=5.310579430768521, w0=72.63366336633676, w1=15.975721412102343\n",
      "SubGD iter. 425/499: loss=5.310624917649846, w0=72.62673267326745, w1=15.973595312316606\n",
      "SubGD iter. 426/499: loss=5.310578167627056, w0=72.62673267326745, w1=15.971985651595519\n",
      "SubGD iter. 427/499: loss=5.310574751788933, w0=72.63366336633676, w1=15.976454351402923\n",
      "SubGD iter. 428/499: loss=5.310627143795689, w0=72.62673267326745, w1=15.974328251617186\n",
      "SubGD iter. 429/499: loss=5.310579853032204, w0=72.62673267326745, w1=15.972718590896099\n",
      "SubGD iter. 430/499: loss=5.310576151592722, w0=72.62673267326745, w1=15.971108930175012\n",
      "SubGD iter. 431/499: loss=5.310580348652993, w0=72.63366336633676, w1=15.975577629982416\n",
      "SubGD iter. 432/499: loss=5.310624480942511, w0=72.62673267326745, w1=15.973451530196678\n",
      "SubGD iter. 433/499: loss=5.310577836997871, w0=72.62673267326745, w1=15.971841869475591\n",
      "SubGD iter. 434/499: loss=5.310575669673406, w0=72.63366336633676, w1=15.976310569282996\n",
      "SubGD iter. 435/499: loss=5.310626707088354, w0=72.62673267326745, w1=15.974184469497258\n",
      "SubGD iter. 436/499: loss=5.3105795224030174, w0=72.62673267326745, w1=15.972574808776171\n",
      "SubGD iter. 437/499: loss=5.310575820963535, w0=72.62673267326745, w1=15.970965148055084\n",
      "SubGD iter. 438/499: loss=5.310581266537468, w0=72.63366336633676, w1=15.975433847862488\n",
      "SubGD iter. 439/499: loss=5.310624044235177, w0=72.62673267326745, w1=15.973307748076751\n",
      "SubGD iter. 440/499: loss=5.310577506368683, w0=72.62673267326745, w1=15.971698087355664\n",
      "SubGD iter. 441/499: loss=5.310576587557881, w0=72.63366336633676, w1=15.976166787163068\n",
      "SubGD iter. 442/499: loss=5.31062627038102, w0=72.62673267326745, w1=15.97404068737733\n",
      "SubGD iter. 443/499: loss=5.310579191773829, w0=72.62673267326745, w1=15.972431026656244\n",
      "SubGD iter. 444/499: loss=5.310575490334348, w0=72.62673267326745, w1=15.970821365935157\n",
      "SubGD iter. 445/499: loss=5.310582184421942, w0=72.63366336633676, w1=15.975290065742561\n",
      "SubGD iter. 446/499: loss=5.310623607527843, w0=72.62673267326745, w1=15.973163965956823\n",
      "SubGD iter. 447/499: loss=5.310577175739496, w0=72.62673267326745, w1=15.971554305235736\n",
      "SubGD iter. 448/499: loss=5.310577505442354, w0=72.63366336633676, w1=15.97602300504314\n",
      "SubGD iter. 449/499: loss=5.310625833673684, w0=72.62673267326745, w1=15.973896905257403\n",
      "SubGD iter. 450/499: loss=5.310578861144643, w0=72.62673267326745, w1=15.972287244536316\n",
      "SubGD iter. 451/499: loss=5.310575159705161, w0=72.62673267326745, w1=15.97067758381523\n",
      "SubGD iter. 452/499: loss=5.310583102306416, w0=72.63366336633676, w1=15.975146283622633\n",
      "SubGD iter. 453/499: loss=5.310623170820507, w0=72.62673267326745, w1=15.973020183836896\n",
      "SubGD iter. 454/499: loss=5.310576845110308, w0=72.62673267326745, w1=15.971410523115809\n",
      "SubGD iter. 455/499: loss=5.310578423326828, w0=72.63366336633676, w1=15.975879222923213\n",
      "SubGD iter. 456/499: loss=5.3106253969663495, w0=72.62673267326745, w1=15.973753123137476\n",
      "SubGD iter. 457/499: loss=5.310578530515456, w0=72.62673267326745, w1=15.972143462416389\n",
      "SubGD iter. 458/499: loss=5.310574829075974, w0=72.62673267326745, w1=15.970533801695302\n",
      "SubGD iter. 459/499: loss=5.3105840201908885, w0=72.63366336633676, w1=15.975002501502706\n",
      "SubGD iter. 460/499: loss=5.310622734113172, w0=72.62673267326745, w1=15.972876401716968\n",
      "SubGD iter. 461/499: loss=5.310576514481122, w0=72.62673267326745, w1=15.971266740995882\n",
      "SubGD iter. 462/499: loss=5.3105793412113025, w0=72.63366336633676, w1=15.975735440803286\n",
      "SubGD iter. 463/499: loss=5.310624960259015, w0=72.62673267326745, w1=15.973609341017548\n",
      "SubGD iter. 464/499: loss=5.310578199886271, w0=72.62673267326745, w1=15.971999680296461\n",
      "SubGD iter. 465/499: loss=5.310574662231715, w0=72.63366336633676, w1=15.976468380103865\n",
      "SubGD iter. 466/499: loss=5.310627186404856, w0=72.62673267326745, w1=15.974342280318128\n",
      "SubGD iter. 467/499: loss=5.310579885291417, w0=72.62673267326745, w1=15.972732619597041\n",
      "SubGD iter. 468/499: loss=5.310576183851936, w0=72.62673267326745, w1=15.971122958875954\n",
      "SubGD iter. 469/499: loss=5.310580259095775, w0=72.63366336633676, w1=15.975591658683358\n",
      "SubGD iter. 470/499: loss=5.31062452355168, w0=72.62673267326745, w1=15.97346555889762\n",
      "SubGD iter. 471/499: loss=5.310577869257083, w0=72.62673267326745, w1=15.971855898176534\n",
      "SubGD iter. 472/499: loss=5.310575580116187, w0=72.63366336633676, w1=15.976324597983938\n",
      "SubGD iter. 473/499: loss=5.310626749697522, w0=72.62673267326745, w1=15.9741984981982\n",
      "SubGD iter. 474/499: loss=5.3105795546622305, w0=72.62673267326745, w1=15.972588837477113\n",
      "SubGD iter. 475/499: loss=5.310575853222749, w0=72.62673267326745, w1=15.970979176756027\n",
      "SubGD iter. 476/499: loss=5.310581176980248, w0=72.63366336633676, w1=15.97544787656343\n",
      "SubGD iter. 477/499: loss=5.310624086844346, w0=72.62673267326745, w1=15.973321776777693\n",
      "SubGD iter. 478/499: loss=5.3105775386278955, w0=72.62673267326745, w1=15.971712116056606\n",
      "SubGD iter. 479/499: loss=5.310576498000661, w0=72.63366336633676, w1=15.97618081586401\n",
      "SubGD iter. 480/499: loss=5.310626312990188, w0=72.62673267326745, w1=15.974054716078273\n",
      "SubGD iter. 481/499: loss=5.3105792240330425, w0=72.62673267326745, w1=15.972445055357186\n",
      "SubGD iter. 482/499: loss=5.310575522593562, w0=72.62673267326745, w1=15.970835394636099\n",
      "SubGD iter. 483/499: loss=5.310582094864723, w0=72.63366336633676, w1=15.975304094443503\n",
      "SubGD iter. 484/499: loss=5.3106236501370105, w0=72.62673267326745, w1=15.973177994657766\n",
      "SubGD iter. 485/499: loss=5.310577207998708, w0=72.62673267326745, w1=15.971568333936679\n",
      "SubGD iter. 486/499: loss=5.3105774158851355, w0=72.63366336633676, w1=15.976037033744083\n",
      "SubGD iter. 487/499: loss=5.310625876282853, w0=72.62673267326745, w1=15.973910933958345\n",
      "SubGD iter. 488/499: loss=5.310578893403856, w0=72.62673267326745, w1=15.972301273237258\n",
      "SubGD iter. 489/499: loss=5.310575191964373, w0=72.62673267326745, w1=15.970691612516172\n",
      "SubGD iter. 490/499: loss=5.310583012749197, w0=72.63366336633676, w1=15.975160312323576\n",
      "SubGD iter. 491/499: loss=5.310623213429675, w0=72.62673267326745, w1=15.973034212537838\n",
      "SubGD iter. 492/499: loss=5.310576877369523, w0=72.62673267326745, w1=15.971424551816751\n",
      "SubGD iter. 493/499: loss=5.310578333769609, w0=72.63366336633676, w1=15.975893251624155\n",
      "SubGD iter. 494/499: loss=5.310625439575519, w0=72.62673267326745, w1=15.973767151838418\n",
      "SubGD iter. 495/499: loss=5.310578562774669, w0=72.62673267326745, w1=15.972157491117331\n",
      "SubGD iter. 496/499: loss=5.310574861335188, w0=72.62673267326745, w1=15.970547830396244\n",
      "SubGD iter. 497/499: loss=5.310583930633669, w0=72.63366336633676, w1=15.975016530203648\n",
      "SubGD iter. 498/499: loss=5.310622776722341, w0=72.62673267326745, w1=15.97289043041791\n",
      "SubGD iter. 499/499: loss=5.310576546740334, w0=72.62673267326745, w1=15.971280769696824\n",
      "SubGD: execution time=0.014 seconds\n"
     ]
    }
   ],
   "source": [
    "# Define the parameters of the algorithm.\n",
    "max_iters = 500\n",
    "gamma = 0.7\n",
    "batch_size = 1\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start SubSGD.\n",
    "start_time = datetime.datetime.now()\n",
    "subgd_losses, subgd_ws = subgradient_descent(y, tx, w_initial, max_iters, gamma)\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"SubGD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-26T14:05:43.242387232Z",
     "start_time": "2023-10-26T14:05:42.759356870Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "interactive(children=(IntSlider(value=1, description='n_iter', max=501, min=1), Output()), _dom_classes=('widg…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2aa390c11b1f4d13b896d3c31c2e8115"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<function __main__.plot_figure(n_iter)>"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        subgd_losses,\n",
    "        subgd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(subgd_ws)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Subgradient Descent\n",
    "\n",
    "**NB** for the computation of the subgradient you can reuse the `compute_subgradient` method that you implemented above, just making sure that you pass in a minibatch as opposed to the full data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-26T14:05:43.242640158Z",
     "start_time": "2023-10-26T14:05:43.238055559Z"
    }
   },
   "outputs": [],
   "source": [
    "def stochastic_subgradient_descent(y, tx, initial_w, batch_size, max_iters, gamma):\n",
    "    \"\"\"Compute a stochastic subgradient at w from a data sample batch of size B, where B < N, and their corresponding labels.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(B, )\n",
    "        tx: numpy array of shape=(B,2)\n",
    "        initial_w: numpy array of shape=(2, ). The initial guess (or the initialization) for the model parameters\n",
    "        batch_size: a scalar denoting the number of data points in a mini-batch used for computing the stochastic subgradient\n",
    "        max_iters: a scalar denoting the total number of iterations of SubSGD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "\n",
    "    Returns:\n",
    "        losses: a list of length max_iters containing the loss value (scalar) for each iteration of SubSGD\n",
    "        ws: a list of length max_iters containing the model parameters as numpy arrays of shape (2, ), for each iteration of SubSGD\n",
    "    \"\"\"\n",
    "\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "\n",
    "    for n_iter in range(max_iters):\n",
    "        # ***************************************************\n",
    "        # INSERT YOUR CODE HERE\n",
    "        loss = compute_loss_MAE(y, tx, w)\n",
    "        gradient = np.zeros(tx.shape[1]) # init the gradient for the upcomming batch\n",
    "        for y_batch, tx_batch in batch_iter(y,tx, batch_size):\n",
    "            gradient += compute_subgradient_mae(y_batch, tx_batch, w)\n",
    "\n",
    "        w = w - gamma * gradient/batch_size    \n",
    "        # store w and loss\n",
    "        ws.append(w)\n",
    "        losses.append(loss)\n",
    "        # ***************************************************\n",
    "\n",
    "        print(\n",
    "            \"SubSGD iter. {bi}/{ti}: loss={l}, w0={w0}, w1={w1}\".format(\n",
    "                bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]\n",
    "            )\n",
    "        )\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-26T14:05:43.297735021Z",
     "start_time": "2023-10-26T14:05:43.238841408Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SubSGD iter. 0/499: loss=74.06780585492638, w0=0.7, w1=-0.24097991466664814\n",
      "SubSGD iter. 1/499: loss=73.36780585492637, w0=1.4, w1=-0.8978608824196117\n",
      "SubSGD iter. 2/499: loss=72.66780585492637, w0=2.0999999999999996, w1=-0.6991000166010872\n",
      "SubSGD iter. 3/499: loss=71.96780585492638, w0=2.8, w1=0.0351757268907118\n",
      "SubSGD iter. 4/499: loss=71.26780585492638, w0=3.5, w1=-0.24737209219551337\n",
      "SubSGD iter. 5/499: loss=70.56780585492638, w0=4.2, w1=-1.1012183626207825\n",
      "SubSGD iter. 6/499: loss=69.86780585492639, w0=4.9, w1=-1.8353326856217715\n",
      "SubSGD iter. 7/499: loss=69.16780585492639, w0=5.6000000000000005, w1=-2.120507180171066\n",
      "SubSGD iter. 8/499: loss=68.46780585492638, w0=6.300000000000001, w1=-1.036631783479764\n",
      "SubSGD iter. 9/499: loss=67.76780585492638, w0=7.000000000000001, w1=-0.42197080234937734\n",
      "SubSGD iter. 10/499: loss=67.06780585492638, w0=7.700000000000001, w1=-1.2218015364120869\n",
      "SubSGD iter. 11/499: loss=66.36780585492637, w0=8.4, w1=0.14094985897965984\n",
      "SubSGD iter. 12/499: loss=65.66780585492639, w0=9.1, w1=-0.2550263842421725\n",
      "SubSGD iter. 13/499: loss=64.9678058549264, w0=9.799999999999999, w1=-0.05868179072494448\n",
      "SubSGD iter. 14/499: loss=64.26780585492638, w0=10.499999999999998, w1=-0.2421475697753638\n",
      "SubSGD iter. 15/499: loss=63.567805854926384, w0=11.199999999999998, w1=-0.513627751757943\n",
      "SubSGD iter. 16/499: loss=62.86780585492639, w0=11.899999999999997, w1=0.5442875550696152\n",
      "SubSGD iter. 17/499: loss=62.167805854926385, w0=12.599999999999996, w1=1.907038950461362\n",
      "SubSGD iter. 18/499: loss=61.46780585492638, w0=13.299999999999995, w1=1.2859873768907686\n",
      "SubSGD iter. 19/499: loss=60.76780585492638, w0=13.999999999999995, w1=1.1758132600100282\n",
      "SubSGD iter. 20/499: loss=60.067805854926384, w0=14.699999999999994, w1=1.6157377028942101\n",
      "SubSGD iter. 21/499: loss=59.36780585492639, w0=15.399999999999993, w1=1.0119716329276964\n",
      "SubSGD iter. 22/499: loss=58.667805854926385, w0=16.099999999999994, w1=0.3991734619262841\n",
      "SubSGD iter. 23/499: loss=57.96780585492638, w0=16.799999999999994, w1=0.046057710358969495\n",
      "SubSGD iter. 24/499: loss=57.26780585492638, w0=17.499999999999993, w1=-0.6322892856155735\n",
      "SubSGD iter. 25/499: loss=56.567805854926384, w0=18.199999999999992, w1=-1.1794515878494438\n",
      "SubSGD iter. 26/499: loss=55.867805854926395, w0=18.89999999999999, w1=-0.08682707352364938\n",
      "SubSGD iter. 27/499: loss=55.167805854926385, w0=19.59999999999999, w1=-0.2067188870119806\n",
      "SubSGD iter. 28/499: loss=54.46780585492639, w0=20.29999999999999, w1=-2.97701858390097\n",
      "SubSGD iter. 29/499: loss=53.767805854926394, w0=20.99999999999999, w1=-2.961710917188834\n",
      "SubSGD iter. 30/499: loss=53.067805854926405, w0=21.69999999999999, w1=-2.7629500513703094\n",
      "SubSGD iter. 31/499: loss=52.367805854926395, w0=22.399999999999988, w1=-1.4001986559785626\n",
      "SubSGD iter. 32/499: loss=51.667805854926385, w0=23.099999999999987, w1=-2.022985062798855\n",
      "SubSGD iter. 33/499: loss=50.96780585492639, w0=23.799999999999986, w1=-2.4189613060206874\n",
      "SubSGD iter. 34/499: loss=50.267805854926394, w0=24.499999999999986, w1=-2.6024270850711066\n",
      "SubSGD iter. 35/499: loss=49.56780585492639, w0=25.199999999999985, w1=-3.1565341590676876\n",
      "SubSGD iter. 36/499: loss=48.867805854926395, w0=25.899999999999984, w1=-3.6462176924642757\n",
      "SubSGD iter. 37/499: loss=48.16780585492641, w0=26.599999999999984, w1=-2.1061553540770896\n",
      "SubSGD iter. 38/499: loss=47.4678058549264, w0=27.299999999999983, w1=-1.2649651858524464\n",
      "SubSGD iter. 39/499: loss=46.7678058549264, w0=27.999999999999982, w1=-1.5364453678350256\n",
      "SubSGD iter. 40/499: loss=46.067805854926405, w0=28.69999999999998, w1=-1.2868469051478473\n",
      "SubSGD iter. 41/499: loss=45.367805854926395, w0=29.39999999999998, w1=-0.047530604169846224\n",
      "SubSGD iter. 42/499: loss=44.66780585492641, w0=30.09999999999998, w1=-0.6174907287058321\n",
      "SubSGD iter. 43/499: loss=43.9678058549264, w0=30.79999999999998, w1=-1.1756144324548714\n",
      "SubSGD iter. 44/499: loss=43.2678058549264, w0=31.49999999999998, w1=-1.0101616405222456\n",
      "SubSGD iter. 45/499: loss=42.567805854926405, w0=32.19999999999998, w1=-0.6551341629924196\n",
      "SubSGD iter. 46/499: loss=41.867805854926395, w0=32.899999999999984, w1=0.4374903513333749\n",
      "SubSGD iter. 47/499: loss=41.167805854926385, w0=33.59999999999999, w1=1.3167383172295468\n",
      "SubSGD iter. 48/499: loss=40.46780585492639, w0=34.29999999999999, w1=1.1332725381791275\n",
      "SubSGD iter. 49/499: loss=39.76780585492639, w0=34.99999999999999, w1=0.36244947211094014\n",
      "SubSGD iter. 50/499: loss=39.067805854926384, w0=35.699999999999996, w1=1.5571883092153656\n",
      "SubSGD iter. 51/499: loss=38.36780585492639, w0=36.4, w1=1.0791401067892423\n",
      "SubSGD iter. 52/499: loss=37.66780585492638, w0=37.1, w1=0.3450257837882533\n",
      "SubSGD iter. 53/499: loss=36.967805854926375, w0=37.800000000000004, w1=-0.06604940075397259\n",
      "SubSGD iter. 54/499: loss=36.26780585492637, w0=38.50000000000001, w1=-0.601569083580178\n",
      "SubSGD iter. 55/499: loss=35.56780585492637, w0=39.20000000000001, w1=0.637747217397823\n",
      "SubSGD iter. 56/499: loss=34.86780585492637, w0=39.90000000000001, w1=0.35781822496135984\n",
      "SubSGD iter. 57/499: loss=34.167805854926364, w0=40.600000000000016, w1=1.152987950078707\n",
      "SubSGD iter. 58/499: loss=33.46780585492636, w0=41.30000000000002, w1=2.210903256906265\n",
      "SubSGD iter. 59/499: loss=32.76780585492636, w0=42.00000000000002, w1=1.930974264469802\n",
      "SubSGD iter. 60/499: loss=32.067805854926355, w0=42.700000000000024, w1=1.5553884261832323\n",
      "SubSGD iter. 61/499: loss=31.36780585492635, w0=43.40000000000003, w1=0.7472746851412994\n",
      "SubSGD iter. 62/499: loss=30.667805854926353, w0=44.10000000000003, w1=0.546525148092048\n",
      "SubSGD iter. 63/499: loss=29.967805854926343, w0=44.80000000000003, w1=-0.023434976443937883\n",
      "SubSGD iter. 64/499: loss=29.267805854926348, w0=45.500000000000036, w1=-0.7017819724184808\n",
      "SubSGD iter. 65/499: loss=28.57058504799929, w0=46.20000000000004, w1=-0.2531229336337706\n",
      "SubSGD iter. 66/499: loss=27.87037062431643, w0=46.90000000000004, w1=-0.21079637703027987\n",
      "SubSGD iter. 67/499: loss=27.176752424768758, w0=47.600000000000044, w1=0.9075138435812016\n",
      "SubSGD iter. 68/499: loss=26.467805854926336, w0=48.30000000000005, w1=1.1518265672903358\n",
      "SubSGD iter. 69/499: loss=25.768788188921473, w0=49.00000000000005, w1=2.0080486197948737\n",
      "SubSGD iter. 70/499: loss=25.067805854926327, w0=49.70000000000005, w1=2.5564431235526843\n",
      "SubSGD iter. 71/499: loss=24.367805854926324, w0=50.400000000000055, w1=3.6128443549315743\n",
      "SubSGD iter. 72/499: loss=23.667805854926325, w0=51.10000000000006, w1=3.7657381120461557\n",
      "SubSGD iter. 73/499: loss=22.96780585492631, w0=51.80000000000006, w1=2.788940633104237\n",
      "SubSGD iter. 74/499: loss=22.286028300013, w0=52.500000000000064, w1=2.1661542262839446\n",
      "SubSGD iter. 75/499: loss=21.644287005660193, w0=53.20000000000007, w1=2.368591116324944\n",
      "SubSGD iter. 76/499: loss=20.96611248481326, w0=53.90000000000007, w1=2.2480865648459014\n",
      "SubSGD iter. 77/499: loss=20.33225307371337, w0=54.60000000000007, w1=2.6982663110521954\n",
      "SubSGD iter. 78/499: loss=19.638333754823563, w0=55.300000000000075, w1=2.958978532434059\n",
      "SubSGD iter. 79/499: loss=18.96979332709591, w0=56.00000000000008, w1=3.3989029753182414\n",
      "SubSGD iter. 80/499: loss=18.278345144198504, w0=56.70000000000008, w1=2.967110397034821\n",
      "SubSGD iter. 81/499: loss=17.76299600197523, w0=57.400000000000084, w1=2.3941003140201973\n",
      "SubSGD iter. 82/499: loss=17.354527468972588, w0=58.10000000000009, w1=2.6642387643098675\n",
      "SubSGD iter. 83/499: loss=16.75573400291115, w0=58.80000000000009, w1=2.463489227260616\n",
      "SubSGD iter. 84/499: loss=16.33035628340219, w0=59.50000000000009, w1=3.0680213331147757\n",
      "SubSGD iter. 85/499: loss=15.65000184998179, w0=60.200000000000095, w1=3.124330948160079\n",
      "SubSGD iter. 86/499: loss=15.195421723919932, w0=60.9000000000001, w1=2.7712151965927645\n",
      "SubSGD iter. 87/499: loss=14.934343112841916, w0=61.6000000000001, w1=2.3757784046497585\n",
      "SubSGD iter. 88/499: loss=14.752195787239888, w0=62.300000000000104, w1=2.0932305855635334\n",
      "SubSGD iter. 89/499: loss=14.5537293936997, w0=63.00000000000011, w1=1.5685976608517938\n",
      "SubSGD iter. 90/499: loss=14.556721068278813, w0=63.70000000000011, w1=-1.8045460167378833\n",
      "SubSGD iter. 91/499: loss=16.237831166794603, w0=64.4000000000001, w1=-0.8576337549954529\n",
      "SubSGD iter. 92/499: loss=15.461851971116824, w0=65.10000000000011, w1=-0.6080352923082747\n",
      "SubSGD iter. 93/499: loss=15.112696444109114, w0=64.4000000000001, w1=-0.21259850036526873\n",
      "SubSGD iter. 94/499: loss=15.076791692383622, w0=65.10000000000011, w1=0.05218660882549947\n",
      "SubSGD iter. 95/499: loss=14.71051480268478, w0=65.80000000000011, w1=-0.28417634885057724\n",
      "SubSGD iter. 96/499: loss=14.73622661354055, w0=65.10000000000011, w1=0.06616058451781387\n",
      "SubSGD iter. 97/499: loss=14.70202445074295, w0=65.80000000000011, w1=0.7843239085490021\n",
      "SubSGD iter. 98/499: loss=14.076544440443957, w0=65.10000000000011, w1=1.2740074419455905\n",
      "SubSGD iter. 99/499: loss=13.998587837315434, w0=65.80000000000011, w1=1.0898466636272706\n",
      "SubSGD iter. 100/499: loss=13.890933992807813, w0=66.50000000000011, w1=1.071267204728394\n",
      "SubSGD iter. 101/499: loss=13.723446897395878, w0=67.20000000000012, w1=-2.301876472861283\n",
      "SubSGD iter. 102/499: loss=15.74320744506326, w0=67.90000000000012, w1=-1.4685388903017063\n",
      "SubSGD iter. 103/499: loss=15.075928135539636, w0=68.60000000000012, w1=-0.7342631468099072\n",
      "SubSGD iter. 104/499: loss=14.474332583386936, w0=67.90000000000012, w1=-0.7905727618552107\n",
      "SubSGD iter. 105/499: loss=14.632369169808113, w0=68.60000000000012, w1=-0.5881358718142117\n",
      "SubSGD iter. 106/499: loss=14.378057385210578, w0=69.30000000000013, w1=-0.13947683302950142\n",
      "SubSGD iter. 107/499: loss=13.964638919429765, w0=70.00000000000013, w1=-0.15805629192837803\n",
      "SubSGD iter. 108/499: loss=13.86336395227196, w0=70.70000000000013, w1=1.0479599978420688\n",
      "SubSGD iter. 109/499: loss=12.968131542157023, w0=71.40000000000013, w1=0.9209455526140438\n",
      "SubSGD iter. 110/499: loss=12.981372529205016, w0=72.10000000000014, w1=1.1321099471802476\n",
      "SubSGD iter. 111/499: loss=12.794657845788512, w0=71.40000000000013, w1=1.9264792916710278\n",
      "SubSGD iter. 112/499: loss=12.31020377700589, w0=72.10000000000014, w1=2.176760408133084\n",
      "SubSGD iter. 113/499: loss=12.081620768588776, w0=72.80000000000014, w1=3.382776697903531\n",
      "SubSGD iter. 114/499: loss=11.231335912908529, w0=72.10000000000014, w1=3.4830537971437407\n",
      "SubSGD iter. 115/499: loss=11.210461576235453, w0=72.80000000000014, w1=3.712175489430499\n",
      "SubSGD iter. 116/499: loss=11.010322802642523, w0=72.10000000000014, w1=4.255191950795598\n",
      "SubSGD iter. 117/499: loss=10.703809996942363, w0=71.40000000000013, w1=4.4370557943707665\n",
      "SubSGD iter. 118/499: loss=10.67387357553977, w0=70.70000000000013, w1=4.258703672990952\n",
      "SubSGD iter. 119/499: loss=10.89152643828056, w0=71.40000000000013, w1=4.547200937548368\n",
      "SubSGD iter. 120/499: loss=10.602954409942212, w0=72.10000000000014, w1=5.163587886385618\n",
      "SubSGD iter. 121/499: loss=10.122855638687321, w0=71.40000000000013, w1=4.558184734941634\n",
      "SubSGD iter. 122/499: loss=10.59588227109205, w0=72.10000000000014, w1=4.5396052760427565\n",
      "SubSGD iter. 123/499: loss=10.518305329974007, w0=72.80000000000014, w1=5.745621565813203\n",
      "SubSGD iter. 124/499: loss=9.702773470817885, w0=73.50000000000014, w1=5.721655726010113\n",
      "SubSGD iter. 125/499: loss=9.694115753772468, w0=74.20000000000014, w1=6.734334067362879\n",
      "SubSGD iter. 126/499: loss=9.064835617092859, w0=73.50000000000014, w1=7.505157133431067\n",
      "SubSGD iter. 127/499: loss=8.570509283690043, w0=72.80000000000014, w1=7.890441273759195\n",
      "SubSGD iter. 128/499: loss=8.383972250186556, w0=73.50000000000014, w1=8.98306578808499\n",
      "SubSGD iter. 129/499: loss=7.703519152024595, w0=72.80000000000014, w1=9.959863267026908\n",
      "SubSGD iter. 130/499: loss=7.208753430851963, w0=72.10000000000014, w1=10.563629336993422\n",
      "SubSGD iter. 131/499: loss=6.983038805102304, w0=72.80000000000014, w1=11.28179266102461\n",
      "SubSGD iter. 132/499: loss=6.557226579706547, w0=72.10000000000014, w1=11.721987915731582\n",
      "SubSGD iter. 133/499: loss=6.4316027185249895, w0=71.40000000000013, w1=11.064805212536596\n",
      "SubSGD iter. 134/499: loss=6.858584316237064, w0=72.10000000000014, w1=11.669337318390756\n",
      "SubSGD iter. 135/499: loss=6.456436739966038, w0=71.40000000000013, w1=11.886594322570506\n",
      "SubSGD iter. 136/499: loss=6.48204911246104, w0=72.10000000000014, w1=12.3367740687768\n",
      "SubSGD iter. 137/499: loss=6.154843218708176, w0=72.80000000000014, w1=13.429398583102595\n",
      "SubSGD iter. 138/499: loss=5.663673353392923, w0=73.50000000000014, w1=13.44470624981473\n",
      "SubSGD iter. 139/499: loss=5.648772562473401, w0=72.80000000000014, w1=14.534501272887951\n",
      "SubSGD iter. 140/499: loss=5.419068759758266, w0=73.50000000000014, w1=13.180544378854723\n",
      "SubSGD iter. 141/499: loss=5.729407865117358, w0=74.20000000000014, w1=13.708600194365372\n",
      "SubSGD iter. 142/499: loss=5.652767971037044, w0=73.50000000000014, w1=14.47942326043356\n",
      "SubSGD iter. 143/499: loss=5.436116361919841, w0=74.20000000000014, w1=13.625576990008291\n",
      "SubSGD iter. 144/499: loss=5.670522710715179, w0=73.50000000000014, w1=13.644156448907168\n",
      "SubSGD iter. 145/499: loss=5.590651387399138, w0=74.20000000000014, w1=14.376121042414804\n",
      "SubSGD iter. 146/499: loss=5.543471018018556, w0=73.50000000000014, w1=13.319719811035913\n",
      "SubSGD iter. 147/499: loss=5.6860035048803725, w0=72.80000000000014, w1=12.124980973931487\n",
      "SubSGD iter. 148/499: loss=6.169336378571058, w0=73.50000000000014, w1=11.600348049219749\n",
      "SubSGD iter. 149/499: loss=6.365081722846127, w0=72.80000000000014, w1=10.899414051784996\n",
      "SubSGD iter. 150/499: loss=6.738537481102677, w0=72.10000000000014, w1=11.602918970175859\n",
      "SubSGD iter. 151/499: loss=6.487764678621138, w0=72.80000000000014, w1=12.398088695293206\n",
      "SubSGD iter. 152/499: loss=6.050740680091692, w0=72.10000000000014, w1=13.010886866294618\n",
      "SubSGD iter. 153/499: loss=5.895787059147509, w0=72.80000000000014, w1=13.355355113165086\n",
      "SubSGD iter. 154/499: loss=5.6863989332470135, w0=72.10000000000014, w1=13.902517415398956\n",
      "SubSGD iter. 155/499: loss=5.616242668252763, w0=72.80000000000014, w1=14.521650811343623\n",
      "SubSGD iter. 156/499: loss=5.420902428978072, w0=73.50000000000014, w1=14.146064973057053\n",
      "SubSGD iter. 157/499: loss=5.482556259122339, w0=72.80000000000014, w1=14.716025097593038\n",
      "SubSGD iter. 158/499: loss=5.3946905825838645, w0=72.10000000000014, w1=14.220398837124206\n",
      "SubSGD iter. 159/499: loss=5.534982075264213, w0=71.40000000000013, w1=14.425232356999429\n",
      "SubSGD iter. 160/499: loss=5.61235834381624, w0=72.10000000000014, w1=14.636396751565632\n",
      "SubSGD iter. 161/499: loss=5.459111610125312, w0=71.40000000000013, w1=14.629968870687286\n",
      "SubSGD iter. 162/499: loss=5.5634725272832455, w0=72.10000000000014, w1=14.974437117557754\n",
      "SubSGD iter. 163/499: loss=5.4095854574173545, w0=72.80000000000014, w1=15.498617669009471\n",
      "SubSGD iter. 164/499: loss=5.328258240416353, w0=72.10000000000014, w1=14.405993154683676\n",
      "SubSGD iter. 165/499: loss=5.495893985660857, w0=72.80000000000014, w1=14.010016911461843\n",
      "SubSGD iter. 166/499: loss=5.51336306807912, w0=73.50000000000014, w1=13.769036996795196\n",
      "SubSGD iter. 167/499: loss=5.558531815396261, w0=72.80000000000014, w1=14.321008428732874\n",
      "SubSGD iter. 168/499: loss=5.454102723134501, w0=72.10000000000014, w1=13.264607197353984\n",
      "SubSGD iter. 169/499: loss=5.808769390420316, w0=72.80000000000014, w1=13.692124282571402\n",
      "SubSGD iter. 170/499: loss=5.588756984810386, w0=72.10000000000014, w1=13.639963937041692\n",
      "SubSGD iter. 171/499: loss=5.686226195081432, w0=71.40000000000013, w1=14.148465054781525\n",
      "SubSGD iter. 172/499: loss=5.685526153002728, w0=72.10000000000014, w1=14.763126035911911\n",
      "SubSGD iter. 173/499: loss=5.439807325168818, w0=72.80000000000014, w1=14.636111590683885\n",
      "SubSGD iter. 174/499: loss=5.40513487183323, w0=73.50000000000014, w1=15.279041289447681\n",
      "SubSGD iter. 175/499: loss=5.376603689553374, w0=74.20000000000014, w1=14.706031206433059\n",
      "SubSGD iter. 176/499: loss=5.50668385465409, w0=73.50000000000014, w1=14.086897810488392\n",
      "SubSGD iter. 177/499: loss=5.492526725350389, w0=72.80000000000014, w1=13.836616694026334\n",
      "SubSGD iter. 178/499: loss=5.553535342460536, w0=72.10000000000014, w1=13.571831584835566\n",
      "SubSGD iter. 179/499: loss=5.707467782678956, w0=71.40000000000013, w1=14.411859156295376\n",
      "SubSGD iter. 180/499: loss=5.615790352616598, w0=72.10000000000014, w1=13.827546618749485\n",
      "SubSGD iter. 181/499: loss=5.635642389757351, w0=71.40000000000013, w1=14.099026800732064\n",
      "SubSGD iter. 182/499: loss=5.698636385933701, w0=70.70000000000013, w1=14.940445310458008\n",
      "SubSGD iter. 183/499: loss=5.699367357834541, w0=71.40000000000013, w1=16.0330698247838\n",
      "SubSGD iter. 184/499: loss=5.434720905159254, w0=72.10000000000014, w1=16.562770798845918\n",
      "SubSGD iter. 185/499: loss=5.356731014228965, w0=72.80000000000014, w1=15.876076163339782\n",
      "SubSGD iter. 186/499: loss=5.312814555594056, w0=72.10000000000014, w1=14.783451649013987\n",
      "SubSGD iter. 187/499: loss=5.4367111865828415, w0=71.40000000000013, w1=14.19113368774581\n",
      "SubSGD iter. 188/499: loss=5.674211115128448, w0=72.10000000000014, w1=14.923098281253445\n",
      "SubSGD iter. 189/499: loss=5.4166375399361435, w0=72.80000000000014, w1=15.125535171294445\n",
      "SubSGD iter. 190/499: loss=5.350329469355032, w0=73.50000000000014, w1=14.695203582833708\n",
      "SubSGD iter. 191/499: loss=5.414215194024649, w0=72.80000000000014, w1=14.10288562156553\n",
      "SubSGD iter. 192/499: loss=5.493138625247218, w0=73.50000000000014, w1=14.83716136505733\n",
      "SubSGD iter. 193/499: loss=5.402236635411008, w0=74.20000000000014, w1=14.233395295090816\n",
      "SubSGD iter. 194/499: loss=5.561543292783544, w0=73.50000000000014, w1=15.052053664896444\n",
      "SubSGD iter. 195/499: loss=5.387416733737179, w0=72.80000000000014, w1=14.62851241184243\n",
      "SubSGD iter. 196/499: loss=5.406128045890378, w0=73.50000000000014, w1=15.346675735873617\n",
      "SubSGD iter. 197/499: loss=5.373481048817134, w0=72.80000000000014, w1=15.742112527816623\n",
      "SubSGD iter. 198/499: loss=5.315870597143347, w0=72.10000000000014, w1=14.862382397984145\n",
      "SubSGD iter. 199/499: loss=5.4249776864965, w0=71.40000000000013, w1=15.27345758252637\n",
      "SubSGD iter. 200/499: loss=5.4732968618351325, w0=72.10000000000014, w1=14.654316427111988\n",
      "SubSGD iter. 201/499: loss=5.456381960661424, w0=71.40000000000013, w1=15.132364629538111\n",
      "SubSGD iter. 202/499: loss=5.488127071834584, w0=72.10000000000014, w1=15.032087530297902\n",
      "SubSGD iter. 203/499: loss=5.401666394634634, w0=71.40000000000013, w1=13.974172223470344\n",
      "SubSGD iter. 204/499: loss=5.734194332079184, w0=70.70000000000013, w1=14.245652405452923\n",
      "SubSGD iter. 205/499: loss=5.847950293415831, w0=71.40000000000013, w1=14.90879672249597\n",
      "SubSGD iter. 206/499: loss=5.513955414852562, w0=72.10000000000014, w1=15.074602982063466\n",
      "SubSGD iter. 207/499: loss=5.395826323145729, w0=72.80000000000014, w1=14.520495908066884\n",
      "SubSGD iter. 208/499: loss=5.421067225439514, w0=73.50000000000014, w1=14.60902342155601\n",
      "SubSGD iter. 209/499: loss=5.422680516469389, w0=72.80000000000014, w1=14.113397161087178\n",
      "SubSGD iter. 210/499: loss=5.49118075211078, w0=72.10000000000014, w1=14.648916843913383\n",
      "SubSGD iter. 211/499: loss=5.457204462684141, w0=71.40000000000013, w1=15.305797811666347\n",
      "SubSGD iter. 212/499: loss=5.46989759646136, w0=72.10000000000014, w1=15.919712225043929\n",
      "SubSGD iter. 213/499: loss=5.33974253100502, w0=72.80000000000014, w1=16.347229310261348\n",
      "SubSGD iter. 214/499: loss=5.319023479323289, w0=73.50000000000014, w1=16.695196356651763\n",
      "SubSGD iter. 215/499: loss=5.411946741870501, w0=72.80000000000014, w1=17.35207732440473\n",
      "SubSGD iter. 216/499: loss=5.450148403503627, w0=72.10000000000014, w1=16.446902221217666\n",
      "SubSGD iter. 217/499: loss=5.3506524013660615, w0=72.80000000000014, w1=16.06477623666733\n",
      "SubSGD iter. 218/499: loss=5.313417330583643, w0=72.10000000000014, w1=16.504971491374302\n",
      "SubSGD iter. 219/499: loss=5.353698789090316, w0=72.80000000000014, w1=16.944895934258483\n",
      "SubSGD iter. 220/499: loss=5.388005745488081, w0=72.10000000000014, w1=16.415194960196366\n",
      "SubSGD iter. 221/499: loss=5.349131955755556, w0=71.40000000000013, w1=15.331319563505065\n",
      "SubSGD iter. 222/499: loss=5.467591018480246, w0=72.10000000000014, w1=16.187541616009604\n",
      "SubSGD iter. 223/499: loss=5.3402849941227135, w0=72.80000000000014, w1=16.46566858481129\n",
      "SubSGD iter. 224/499: loss=5.3263244696975285, w0=73.50000000000014, w1=15.281666384417399\n",
      "SubSGD iter. 225/499: loss=5.376482490535388, w0=74.20000000000014, w1=16.29410472228382\n",
      "SubSGD iter. 226/499: loss=5.494553249024615, w0=74.90000000000015, w1=17.150326774788358\n",
      "SubSGD iter. 227/499: loss=5.767986510898923, w0=74.20000000000014, w1=16.29410472228382\n",
      "SubSGD iter. 228/499: loss=5.494553249024615, w0=73.50000000000014, w1=16.237795107238515\n",
      "SubSGD iter. 229/499: loss=5.367599287309248, w0=74.20000000000014, w1=16.778752159209656\n",
      "SubSGD iter. 230/499: loss=5.53987698007492, w0=73.50000000000014, w1=17.722258642746777\n",
      "SubSGD iter. 231/499: loss=5.584085639051983, w0=72.80000000000014, w1=16.356889190083166\n",
      "SubSGD iter. 232/499: loss=5.319315118448825, w0=72.10000000000014, w1=15.622613446591366\n",
      "SubSGD iter. 233/499: loss=5.347388221155829, w0=71.40000000000013, w1=16.033688631133593\n",
      "SubSGD iter. 234/499: loss=5.434710164369454, w0=72.10000000000014, w1=16.015109172234716\n",
      "SubSGD iter. 235/499: loss=5.33805472450821, w0=72.80000000000014, w1=15.661993420667402\n",
      "SubSGD iter. 236/499: loss=5.319427481990452, w0=72.10000000000014, w1=16.19751310349361\n",
      "SubSGD iter. 237/499: loss=5.340518366009875, w0=71.40000000000013, w1=15.998752237675085\n",
      "SubSGD iter. 238/499: loss=5.435316564834873, w0=72.10000000000014, w1=15.39498616770857\n",
      "SubSGD iter. 239/499: loss=5.3616818549527006, w0=71.40000000000013, w1=14.84659166395076\n",
      "SubSGD iter. 240/499: loss=5.521491995045659, w0=72.10000000000014, w1=16.08590796492876\n",
      "SubSGD iter. 241/499: loss=5.33860460889669, w0=72.80000000000014, w1=15.902442185878343\n",
      "SubSGD iter. 242/499: loss=5.312853549696362, w0=72.10000000000014, w1=16.28772632620647\n",
      "SubSGD iter. 243/499: loss=5.343528538820798, w0=72.80000000000014, w1=16.565853295008157\n",
      "SubSGD iter. 244/499: loss=5.3372491840967085, w0=72.10000000000014, w1=16.747717138583326\n",
      "SubSGD iter. 245/499: loss=5.371517689580065, w0=72.80000000000014, w1=17.542886863700673\n",
      "SubSGD iter. 246/499: loss=5.483701359408065, w0=73.50000000000014, w1=17.99306660990697\n",
      "SubSGD iter. 247/499: loss=5.640408029895054, w0=74.20000000000014, w1=17.6174807716204\n",
      "SubSGD iter. 248/499: loss=5.681331700521598, w0=73.50000000000014, w1=17.83473777580015\n",
      "SubSGD iter. 249/499: loss=5.607126064976221, w0=72.80000000000014, w1=18.538242694191013\n",
      "SubSGD iter. 250/499: loss=5.72657102086458, w0=73.50000000000014, w1=18.188304762710697\n",
      "SubSGD iter. 251/499: loss=5.683779057311962, w0=72.80000000000014, w1=17.66024894720005\n",
      "SubSGD iter. 252/499: loss=5.505824626888652, w0=72.10000000000014, w1=17.78014076068838\n",
      "SubSGD iter. 253/499: loss=5.546747058017829, w0=72.80000000000014, w1=17.868668274177505\n",
      "SubSGD iter. 254/499: loss=5.551149488942585, w0=73.50000000000014, w1=18.07983266874371\n",
      "SubSGD iter. 255/499: loss=5.659316539841462, w0=74.20000000000014, w1=17.04231847493017\n",
      "SubSGD iter. 256/499: loss=5.57286652724168, w0=74.90000000000015, w1=16.80133856026352\n",
      "SubSGD iter. 257/499: loss=5.715630489508529, w0=74.20000000000014, w1=17.64136613172333\n",
      "SubSGD iter. 258/499: loss=5.686722329890688, w0=73.50000000000014, w1=17.217824878669315\n",
      "SubSGD iter. 259/499: loss=5.489252119100195, w0=72.80000000000014, w1=17.564908864289308\n",
      "SubSGD iter. 260/499: loss=5.4877564433771, w0=73.50000000000014, w1=16.825576064845364\n",
      "SubSGD iter. 261/499: loss=5.426554788189711, w0=74.20000000000014, w1=17.457850493327054\n",
      "SubSGD iter. 262/499: loss=5.647090889552428, w0=73.50000000000014, w1=16.928149519264938\n",
      "SubSGD iter. 263/499: loss=5.440058125919795, w0=74.20000000000014, w1=16.59178656158886\n",
      "SubSGD iter. 264/499: loss=5.5213790602602755, w0=74.90000000000015, w1=15.614989082646943\n",
      "SubSGD iter. 265/499: loss=5.622604631124772, w0=74.20000000000014, w1=15.412552192605943\n",
      "SubSGD iter. 266/499: loss=5.469878345995625, w0=74.90000000000015, w1=15.013094420219364\n",
      "SubSGD iter. 267/499: loss=5.643695005171246, w0=74.20000000000014, w1=15.026849616194854\n",
      "SubSGD iter. 268/499: loss=5.482487301684217, w0=73.50000000000014, w1=15.127126715435063\n",
      "SubSGD iter. 269/499: loss=5.383617491873172, w0=74.20000000000014, w1=13.915703827508883\n",
      "SubSGD iter. 270/499: loss=5.612532925322471, w0=73.50000000000014, w1=14.035595640997215\n",
      "SubSGD iter. 271/499: loss=5.501866732466408, w0=72.80000000000014, w1=13.983435295467505\n",
      "SubSGD iter. 272/499: loss=5.5195213300871995, w0=72.10000000000014, w1=14.330519281087495\n",
      "SubSGD iter. 273/499: loss=5.510727601034664, w0=71.40000000000013, w1=14.355817046476337\n",
      "SubSGD iter. 274/499: loss=5.630539726760805, w0=72.10000000000014, w1=14.960349152330497\n",
      "SubSGD iter. 275/499: loss=5.411520629705163, w0=71.40000000000013, w1=15.518472856079537\n",
      "SubSGD iter. 276/499: loss=5.452400161785868, w0=70.70000000000013, w1=16.199072033735618\n",
      "SubSGD iter. 277/499: loss=5.610950760537617, w0=71.40000000000013, w1=17.43838833471362\n",
      "SubSGD iter. 278/499: loss=5.5574873541841745, w0=70.70000000000013, w1=16.677031384094548\n",
      "SubSGD iter. 279/499: loss=5.631311983384632, w0=70.00000000000013, w1=16.95696037653101\n",
      "SubSGD iter. 280/499: loss=5.9327996750686305, w0=70.70000000000013, w1=16.157129642468302\n",
      "SubSGD iter. 281/499: loss=5.61097498141287, w0=71.40000000000013, w1=16.605788681253014\n",
      "SubSGD iter. 282/499: loss=5.450939017012661, w0=70.70000000000013, w1=16.40702781543449\n",
      "SubSGD iter. 283/499: loss=5.61295362091276, w0=71.40000000000013, w1=15.053070921401261\n",
      "SubSGD iter. 284/499: loss=5.49715569338252, w0=70.70000000000013, w1=14.792358700019397\n",
      "SubSGD iter. 285/499: loss=5.727471942999879, w0=71.40000000000013, w1=15.438505933406617\n",
      "SubSGD iter. 286/499: loss=5.458599181731877, w0=70.70000000000013, w1=15.72368042795591\n",
      "SubSGD iter. 287/499: loss=5.6199112463688055, w0=71.40000000000013, w1=14.78017394441879\n",
      "SubSGD iter. 288/499: loss=5.532040837574452, w0=72.10000000000014, w1=15.685349047605854\n",
      "SubSGD iter. 289/499: loss=5.345267171724547, w0=72.80000000000014, w1=14.658416850013321\n",
      "SubSGD iter. 290/499: loss=5.4022196877895166, w0=72.10000000000014, w1=14.162790589544489\n",
      "SubSGD iter. 291/499: loss=5.548893416021311, w0=72.80000000000014, w1=15.40210689052249\n",
      "SubSGD iter. 292/499: loss=5.333532539605883, w0=72.10000000000014, w1=15.772374981051286\n",
      "SubSGD iter. 293/499: loss=5.343215710309733, w0=72.80000000000014, w1=15.342043392590549\n",
      "SubSGD iter. 294/499: loss=5.336815000522987, w0=72.10000000000014, w1=14.17371259207308\n",
      "SubSGD iter. 295/499: loss=5.546085977656739, w0=72.80000000000014, w1=13.837349634397004\n",
      "SubSGD iter. 296/499: loss=5.55336553943427, w0=73.50000000000014, w1=13.455223649846669\n",
      "SubSGD iter. 297/499: loss=5.645639747210806, w0=74.20000000000014, w1=14.107280547289124\n",
      "SubSGD iter. 298/499: loss=5.580789965457096, w0=74.90000000000015, w1=13.420585911782988\n",
      "SubSGD iter. 299/499: loss=5.857958155238954, w0=75.60000000000015, w1=12.836273374237097\n",
      "SubSGD iter. 300/499: loss=6.1740520913417, w0=74.90000000000015, w1=13.383435676470967\n",
      "SubSGD iter. 301/499: loss=5.865185012951109, w0=75.60000000000015, w1=12.983977904084387\n",
      "SubSGD iter. 302/499: loss=6.1412932582618724, w0=74.90000000000015, w1=12.142787735859745\n",
      "SubSGD iter. 303/499: loss=6.219158050947468, w0=74.20000000000014, w1=11.913666043572986\n",
      "SubSGD iter. 304/499: loss=6.247513338802316, w0=73.50000000000014, w1=11.871339486969495\n",
      "SubSGD iter. 305/499: loss=6.246967428775023, w0=74.20000000000014, w1=12.955214883660798\n",
      "SubSGD iter. 306/499: loss=5.853457911950595, w0=73.50000000000014, w1=12.254280886226045\n",
      "SubSGD iter. 307/499: loss=6.086425279073322, w0=72.80000000000014, w1=12.143980852765253\n",
      "SubSGD iter. 308/499: loss=6.161085773681241, w0=72.10000000000014, w1=12.756779023766665\n",
      "SubSGD iter. 309/499: loss=5.9852310257920545, w0=71.40000000000013, w1=13.596806595226475\n",
      "SubSGD iter. 310/499: loss=5.848420824901012, w0=70.70000000000013, w1=14.330920918227465\n",
      "SubSGD iter. 311/499: loss=5.827064117935577, w0=70.00000000000013, w1=14.61346873731369\n",
      "SubSGD iter. 312/499: loss=6.009336261856549, w0=70.70000000000013, w1=14.2631318039453\n",
      "SubSGD iter. 313/499: loss=5.843574323132633, w0=71.40000000000013, w1=13.897211073214901\n",
      "SubSGD iter. 314/499: loss=5.756411667461551, w0=70.70000000000013, w1=13.196277075780149\n",
      "SubSGD iter. 315/499: loss=6.166142794454757, w0=70.00000000000013, w1=12.249364814037719\n",
      "SubSGD iter. 316/499: loss=6.719237646903624, w0=70.70000000000013, w1=12.4022585711523\n",
      "SubSGD iter. 317/499: loss=6.457213428534963, w0=71.40000000000013, w1=12.383679112253423\n",
      "SubSGD iter. 318/499: loss=6.277787867820861, w0=72.10000000000014, w1=12.426005668856915\n",
      "SubSGD iter. 319/499: loss=6.117455837848833, w0=72.80000000000014, w1=12.325728569616706\n",
      "SubSGD iter. 320/499: loss=6.082162712408725, w0=73.50000000000014, w1=13.688479965008453\n",
      "SubSGD iter. 321/499: loss=5.578964303246332, w0=72.80000000000014, w1=13.905736969188203\n",
      "SubSGD iter. 322/499: loss=5.537521990803961, w0=72.10000000000014, w1=14.995531992261423\n",
      "SubSGD iter. 323/499: loss=5.406687791481727, w0=72.80000000000014, w1=13.958017798447882\n",
      "SubSGD iter. 324/499: loss=5.5254098963154465, w0=72.10000000000014, w1=14.50103425981298\n",
      "SubSGD iter. 325/499: loss=5.479730965207238, w0=72.80000000000014, w1=14.644364850407497\n",
      "SubSGD iter. 326/499: loss=5.404056212728687, w0=73.50000000000014, w1=15.500586902912035\n",
      "SubSGD iter. 327/499: loss=5.36744092060756, w0=72.80000000000014, w1=16.30870064395397\n",
      "SubSGD iter. 328/499: loss=5.31799512534423, w0=72.10000000000014, w1=15.428970514121492\n",
      "SubSGD iter. 329/499: loss=5.359286687456863, w0=72.80000000000014, w1=14.575124243696223\n",
      "SubSGD iter. 330/499: loss=5.41333405696756, w0=72.10000000000014, w1=14.855053236132687\n",
      "SubSGD iter. 331/499: loss=5.425984445860185, w0=71.40000000000013, w1=15.413176939881726\n",
      "SubSGD iter. 332/499: loss=5.460647156430115, w0=72.10000000000014, w1=15.922362783827978\n",
      "SubSGD iter. 333/499: loss=5.339680049410649, w0=71.40000000000013, w1=15.880036227224487\n",
      "SubSGD iter. 334/499: loss=5.437377150856025, w0=70.70000000000013, w1=16.698694597030116\n",
      "SubSGD iter. 335/499: loss=5.633237064513132, w0=71.40000000000013, w1=16.78722211051924\n",
      "SubSGD iter. 336/499: loss=5.461600725696103, w0=72.10000000000014, w1=17.40188309164963\n",
      "SubSGD iter. 337/499: loss=5.468269381497992, w0=72.80000000000014, w1=16.047926197616402\n",
      "SubSGD iter. 338/499: loss=5.313266165728872, w0=72.10000000000014, w1=16.556427315356235\n",
      "SubSGD iter. 339/499: loss=5.356398227021895, w0=71.40000000000013, w1=16.30614619889418\n",
      "SubSGD iter. 340/499: loss=5.4382032938140785, w0=72.10000000000014, w1=15.362639715357059\n",
      "SubSGD iter. 341/499: loss=5.364224304611044, w0=72.80000000000014, w1=15.979026664194308\n",
      "SubSGD iter. 342/499: loss=5.312966814523399, w0=72.10000000000014, w1=16.335752182550145\n",
      "SubSGD iter. 343/499: loss=5.345380342185083, w0=72.80000000000014, w1=16.48864593966473\n",
      "SubSGD iter. 344/499: loss=5.328830052025701, w0=73.50000000000014, w1=16.68516602244323\n",
      "SubSGD iter. 345/499: loss=5.410842155143258, w0=72.80000000000014, w1=17.21212305821208\n",
      "SubSGD iter. 346/499: loss=5.428309835045562, w0=73.50000000000014, w1=17.456435781921215\n",
      "SubSGD iter. 347/499: loss=5.532409914363479, w0=74.20000000000014, w1=18.07992390420739\n",
      "SubSGD iter. 348/499: loss=5.787638748976511, w0=73.50000000000014, w1=17.475391798353233\n",
      "SubSGD iter. 349/499: loss=5.536016712317324, w0=72.80000000000014, w1=16.84422645835838\n",
      "SubSGD iter. 350/499: loss=5.373152333014366, w0=73.50000000000014, w1=17.56238978238957\n",
      "SubSGD iter. 351/499: loss=5.552569987206929, w0=72.80000000000014, w1=16.61547752064714\n",
      "SubSGD iter. 352/499: loss=5.342660493779803, w0=72.10000000000014, w1=16.640775286035982\n",
      "SubSGD iter. 353/499: loss=5.361840138546099, w0=72.80000000000014, w1=16.98448790721937\n",
      "SubSGD iter. 354/499: loss=5.393898562707202, w0=72.10000000000014, w1=17.416280485502792\n",
      "SubSGD iter. 355/499: loss=5.470930660842681, w0=71.40000000000013, w1=17.90596401889938\n",
      "SubSGD iter. 356/499: loss=5.671961846266316, w0=72.10000000000014, w1=17.474953334150765\n",
      "SubSGD iter. 357/499: loss=5.481835287685512, w0=72.80000000000014, w1=16.87118726418425\n",
      "SubSGD iter. 358/499: loss=5.377035043910745, w0=72.10000000000014, w1=15.81478603280536\n",
      "SubSGD iter. 359/499: loss=5.342215955032304, w0=72.80000000000014, w1=15.78009517346389\n",
      "SubSGD iter. 360/499: loss=5.3142333350166755, w0=72.10000000000014, w1=16.86989019653711\n",
      "SubSGD iter. 361/499: loss=5.385860011720961, w0=72.80000000000014, w1=16.958417710026236\n",
      "SubSGD iter. 362/499: loss=5.390018308821461, w0=72.10000000000014, w1=15.41835537163905\n",
      "SubSGD iter. 363/499: loss=5.360034827318924, w0=72.80000000000014, w1=14.62398602714827\n",
      "SubSGD iter. 364/499: loss=5.406719621367768, w0=73.50000000000014, w1=15.276042924590724\n",
      "SubSGD iter. 365/499: loss=5.376742122212164, w0=72.80000000000014, w1=16.010157247591714\n",
      "SubSGD iter. 366/499: loss=5.313012855186229, w0=73.50000000000014, w1=15.210326513529004\n",
      "SubSGD iter. 367/499: loss=5.379776208436932, w0=74.20000000000014, w1=16.222764851395425\n",
      "SubSGD iter. 368/499: loss=5.489319024184869, w0=74.90000000000015, w1=16.87482174883788\n",
      "SubSGD iter. 369/499: loss=5.7260445927392185, w0=74.20000000000014, w1=15.706490948320413\n",
      "SubSGD iter. 370/499: loss=5.464952257488849, w0=73.50000000000014, w1=14.960505294733016\n",
      "SubSGD iter. 371/499: loss=5.392682237269262, w0=72.80000000000014, w1=15.24567978928231\n",
      "SubSGD iter. 372/499: loss=5.342282762675155, w0=73.50000000000014, w1=15.798885705358423\n",
      "SubSGD iter. 373/499: loss=5.362464348628779, w0=72.80000000000014, w1=15.538173483976559\n",
      "SubSGD iter. 374/499: loss=5.326096521216771, w0=72.10000000000014, w1=16.37820105543637\n",
      "SubSGD iter. 375/499: loss=5.3473849519468475, w0=71.40000000000013, w1=15.015449660044624\n",
      "SubSGD iter. 376/499: loss=5.501536426160375, w0=70.70000000000013, w1=15.520467391868946\n",
      "SubSGD iter. 377/499: loss=5.630491570792113, w0=70.00000000000013, w1=16.361885901594892\n",
      "SubSGD iter. 378/499: loss=5.878901081292928, w0=70.70000000000013, w1=15.78887581858027\n",
      "SubSGD iter. 379/499: loss=5.617371257201919, w0=71.40000000000013, w1=16.584045543697616\n",
      "SubSGD iter. 380/499: loss=5.449808201012503, w0=72.10000000000014, w1=16.621332855315487\n",
      "SubSGD iter. 381/499: loss=5.360502009060366, w0=71.40000000000013, w1=17.032408039857714\n",
      "SubSGD iter. 382/499: loss=5.484030184694593, w0=72.10000000000014, w1=17.17573863045223\n",
      "SubSGD iter. 383/499: loss=5.428222282818056, w0=72.80000000000014, w1=17.328632387566813\n",
      "SubSGD iter. 384/499: loss=5.446490038009967, w0=73.50000000000014, w1=17.85281293901853\n",
      "SubSGD iter. 385/499: loss=5.610898393495743, w0=72.80000000000014, w1=18.399975241252402\n",
      "SubSGD iter. 386/499: loss=5.686680176008509, w0=73.50000000000014, w1=18.953181157328515\n",
      "SubSGD iter. 387/499: loss=5.9020709561097355, w0=72.80000000000014, w1=19.500343459562387\n",
      "SubSGD iter. 388/499: loss=6.054938029394798, w0=73.50000000000014, w1=19.070011871101652\n",
      "SubSGD iter. 389/499: loss=5.941546256142824, w0=74.20000000000014, w1=20.08269021245442\n",
      "SubSGD iter. 390/499: loss=6.475638968336466, w0=74.90000000000015, w1=19.425809244701455\n",
      "SubSGD iter. 391/499: loss=6.409293145366914, w0=74.20000000000014, w1=19.24745712332164\n",
      "SubSGD iter. 392/499: loss=6.137670510612562, w0=73.50000000000014, w1=18.997858660634463\n",
      "SubSGD iter. 393/499: loss=5.917166796841791, w0=72.80000000000014, w1=18.654146039451074\n",
      "SubSGD iter. 394/499: loss=5.761323162722185, w0=72.10000000000014, w1=17.919870295959274\n",
      "SubSGD iter. 395/499: loss=5.581094379146833, w0=71.40000000000013, w1=16.554500843295664\n",
      "SubSGD iter. 396/499: loss=5.44831938668086, w0=70.70000000000013, w1=16.834429835732127\n",
      "SubSGD iter. 397/499: loss=5.647406173926827, w0=71.40000000000013, w1=16.94825016254644\n",
      "SubSGD iter. 398/499: loss=5.474917023388393, w0=70.70000000000013, w1=16.973547927935282\n",
      "SubSGD iter. 399/499: loss=5.664944594293563, w0=71.40000000000013, w1=16.637184970259206\n",
      "SubSGD iter. 400/499: loss=5.452581711120799, w0=72.10000000000014, w1=17.432354695376553\n",
      "SubSGD iter. 401/499: loss=5.473901890438507, w0=71.40000000000013, w1=17.855594120149068\n",
      "SubSGD iter. 402/499: loss=5.658489351183878, w0=72.10000000000014, w1=16.87879664120715\n",
      "SubSGD iter. 403/499: loss=5.386978629493431, w0=71.40000000000013, w1=15.82088133437959\n",
      "SubSGD iter. 404/499: loss=5.438434274485391, w0=72.10000000000014, w1=15.201740178965208\n",
      "SubSGD iter. 405/499: loss=5.379384846282922, w0=72.80000000000014, w1=14.674551540217982\n",
      "SubSGD iter. 406/499: loss=5.400110965772875, w0=72.10000000000014, w1=15.287349711219393\n",
      "SubSGD iter. 407/499: loss=5.370367261611106, w0=71.40000000000013, w1=14.119018910701925\n",
      "SubSGD iter. 408/499: loss=5.693334798660325, w0=72.10000000000014, w1=14.397145879503613\n",
      "SubSGD iter. 409/499: loss=5.497599217248837, w0=72.80000000000014, w1=14.925201695014263\n",
      "SubSGD iter. 410/499: loss=5.3690246725353905, w0=72.10000000000014, w1=14.501660441960247\n",
      "SubSGD iter. 411/499: loss=5.479635580792596, w0=71.40000000000013, w1=14.927446589250987\n",
      "SubSGD iter. 412/499: loss=5.511783768298188, w0=72.10000000000014, w1=14.373339515254406\n",
      "SubSGD iter. 413/499: loss=5.502187676801244, w0=72.80000000000014, w1=14.989726464091655\n",
      "SubSGD iter. 414/499: loss=5.3618703770924405, w0=73.50000000000014, w1=14.462537825344429\n",
      "SubSGD iter. 415/499: loss=5.4380577657049045, w0=74.20000000000014, w1=15.318759877848967\n",
      "SubSGD iter. 416/499: loss=5.472538902170223, w0=74.90000000000015, w1=15.334067544561103\n",
      "SubSGD iter. 417/499: loss=5.620096287162974, w0=74.20000000000014, w1=15.69079306291694\n",
      "SubSGD iter. 418/499: loss=5.4651312734611395, w0=73.50000000000014, w1=14.632877756089382\n",
      "SubSGD iter. 419/499: loss=5.420337348035543, w0=74.20000000000014, w1=14.97734600295985\n",
      "SubSGD iter. 420/499: loss=5.485240716450486, w0=74.90000000000015, w1=15.640490320002897\n",
      "SubSGD iter. 421/499: loss=5.623233580582998, w0=74.20000000000014, w1=16.34399523839376\n",
      "SubSGD iter. 422/499: loss=5.498213729138169, w0=73.50000000000014, w1=15.510657655834184\n",
      "SubSGD iter. 423/499: loss=5.36708911286892, w0=72.80000000000014, w1=15.504229774955837\n",
      "SubSGD iter. 424/499: loss=5.327951539690192, w0=73.50000000000014, w1=16.028410326407556\n",
      "SubSGD iter. 425/499: loss=5.35989703923652, w0=72.80000000000014, w1=16.212571104725875\n",
      "SubSGD iter. 426/499: loss=5.315937334212406, w0=72.10000000000014, w1=16.623646289268102\n",
      "SubSGD iter. 427/499: loss=5.360661231650885, w0=71.40000000000013, w1=15.567245057889211\n",
      "SubSGD iter. 428/499: loss=5.449138266778155, w0=72.10000000000014, w1=15.383779278838793\n",
      "SubSGD iter. 429/499: loss=5.362549295612858, w0=72.80000000000014, w1=15.580299361617294\n",
      "SubSGD iter. 430/499: loss=5.3237943484876515, w0=72.10000000000014, w1=14.949134021622442\n",
      "SubSGD iter. 431/499: loss=5.4130611793729315, w0=71.40000000000013, w1=13.754395184518016\n",
      "SubSGD iter. 432/499: loss=5.799366389181704, w0=72.10000000000014, w1=13.769702851230152\n",
      "SubSGD iter. 433/499: loss=5.650610257657938, w0=72.80000000000014, w1=14.894832811360459\n",
      "SubSGD iter. 434/499: loss=5.372605134425347, w0=73.50000000000014, w1=15.164971261650129\n",
      "SubSGD iter. 435/499: loss=5.381870232482425, w0=74.20000000000014, w1=15.130280402308658\n",
      "SubSGD iter. 436/499: loss=5.478487218012704, w0=73.50000000000014, w1=15.073970787263354\n",
      "SubSGD iter. 437/499: loss=5.38624062547723, w0=74.20000000000014, w1=15.501487872480773\n",
      "SubSGD iter. 438/499: loss=5.467591553094186, w0=73.50000000000014, w1=16.122539446051366\n",
      "SubSGD iter. 439/499: loss=5.361777231680282, w0=74.20000000000014, w1=16.288345705618863\n",
      "SubSGD iter. 440/499: loss=5.494130708477445, w0=73.50000000000014, w1=15.082329415848415\n",
      "SubSGD iter. 441/499: loss=5.38579208793858, w0=72.80000000000014, w1=15.918368273121231\n",
      "SubSGD iter. 442/499: loss=5.31287710362735, w0=72.10000000000014, w1=15.30445385974365\n",
      "SubSGD iter. 443/499: loss=5.368834704054895, w0=71.40000000000013, w1=14.712135898475472\n",
      "SubSGD iter. 444/499: loss=5.5457792760459474, w0=72.10000000000014, w1=14.914572788516471\n",
      "SubSGD iter. 445/499: loss=5.4178086315039, w0=72.80000000000014, w1=14.709739268641249\n",
      "SubSGD iter. 446/499: loss=5.395512108484599, w0=73.50000000000014, w1=13.73294178969933\n",
      "SubSGD iter. 447/499: loss=5.567353545468511, w0=72.80000000000014, w1=14.436446708090193\n",
      "SubSGD iter. 448/499: loss=5.434333202675647, w0=73.50000000000014, w1=14.546746741550985\n",
      "SubSGD iter. 449/499: loss=5.428797842884359, w0=74.20000000000014, w1=15.665056962162467\n",
      "SubSGD iter. 450/499: loss=5.465424763506525, w0=74.90000000000015, w1=16.521279014667005\n",
      "SubSGD iter. 451/499: loss=5.68266124219041, w0=74.20000000000014, w1=17.30551174270633\n",
      "SubSGD iter. 452/499: loss=5.616548982442033, w0=74.90000000000015, w1=17.858717658782442\n",
      "SubSGD iter. 453/499: loss=5.912084164607101, w0=74.20000000000014, w1=17.09736070816337\n",
      "SubSGD iter. 454/499: loss=5.581637356206678, w0=74.90000000000015, w1=17.829325301671005\n",
      "SubSGD iter. 455/499: loss=5.904132466949788, w0=75.60000000000015, w1=18.492469618714054\n",
      "SubSGD iter. 456/499: loss=6.354696910253036, w0=74.90000000000015, w1=18.932664873421025\n",
      "SubSGD iter. 457/499: loss=6.2445233458985925, w0=74.20000000000014, w1=18.20764468334022\n",
      "SubSGD iter. 458/499: loss=5.818700012463059, w0=73.50000000000014, w1=18.288458988828932\n",
      "SubSGD iter. 459/499: loss=5.707963210058432, w0=74.20000000000014, w1=17.8924827456071\n",
      "SubSGD iter. 460/499: loss=5.743396233404586, w0=73.50000000000014, w1=17.99275984484731\n",
      "SubSGD iter. 461/499: loss=5.640341178060829, w0=72.80000000000014, w1=17.340702947404854\n",
      "SubSGD iter. 462/499: loss=5.44837353720239, w0=73.50000000000014, w1=16.569879881336668\n",
      "SubSGD iter. 463/499: loss=5.398146312845878, w0=74.20000000000014, w1=17.3018444748443\n",
      "SubSGD iter. 464/499: loss=5.615914661146546, w0=73.50000000000014, w1=16.095828185073856\n",
      "SubSGD iter. 465/499: loss=5.360611890177474, w0=74.20000000000014, w1=15.854848270407208\n",
      "SubSGD iter. 466/499: loss=5.469492585546534, w0=74.90000000000015, w1=16.469509251537595\n",
      "SubSGD iter. 467/499: loss=5.677295092891122, w0=75.60000000000015, w1=17.65031395223749\n",
      "SubSGD iter. 468/499: loss=6.129924860666604, w0=74.90000000000015, w1=17.51799042588365\n",
      "SubSGD iter. 469/499: loss=5.832309124741691, w0=75.60000000000015, w1=16.831295790377514\n",
      "SubSGD iter. 470/499: loss=5.972966659630615, w0=74.90000000000015, w1=17.19721652110791\n",
      "SubSGD iter. 471/499: loss=5.775493994677465, w0=74.20000000000014, w1=16.318044208877104\n",
      "SubSGD iter. 472/499: loss=5.496309695368251, w0=73.50000000000014, w1=15.617110211442352\n",
      "SubSGD iter. 473/499: loss=5.364497568118177, w0=72.80000000000014, w1=14.9161762140076\n",
      "SubSGD iter. 474/499: loss=5.370088767980955, w0=72.10000000000014, w1=15.10033699232592\n",
      "SubSGD iter. 475/499: loss=5.392291409287644, w0=71.40000000000013, w1=15.590020525722508\n",
      "SubSGD iter. 476/499: loss=5.447968616100129, w0=72.10000000000014, w1=12.81972082883352\n",
      "SubSGD iter. 477/499: loss=5.962910010814458, w0=72.80000000000014, w1=13.069319291520697\n",
      "SubSGD iter. 478/499: loss=5.783565663805163, w0=73.50000000000014, w1=13.692807413806875\n",
      "SubSGD iter. 479/499: loss=5.577823255271739, w0=72.80000000000014, w1=13.442526297344818\n",
      "SubSGD iter. 480/499: loss=5.659838527716293, w0=72.10000000000014, w1=12.785343594149833\n",
      "SubSGD iter. 481/499: loss=5.975025751333203, w0=71.40000000000013, w1=12.799098790125322\n",
      "SubSGD iter. 482/499: loss=6.119805862511716, w0=72.10000000000014, w1=13.352304706201435\n",
      "SubSGD iter. 483/499: loss=5.779237492339475, w0=71.40000000000013, w1=13.792499960908406\n",
      "SubSGD iter. 484/499: loss=5.787905619088177, w0=70.70000000000013, w1=14.415286367728699\n",
      "SubSGD iter. 485/499: loss=5.807107414211814, w0=71.40000000000013, w1=15.256476535953341\n",
      "SubSGD iter. 486/499: loss=5.475081731180871, w0=72.10000000000014, w1=14.517143736509396\n",
      "SubSGD iter. 487/499: loss=5.477277057807289, w0=72.80000000000014, w1=14.795270705311085\n",
      "SubSGD iter. 488/499: loss=5.384405358395734, w0=72.10000000000014, w1=15.529385028312074\n",
      "SubSGD iter. 489/499: loss=5.352209617985602, w0=72.80000000000014, w1=16.143299441689656\n",
      "SubSGD iter. 490/499: loss=5.314454474572934, w0=73.50000000000014, w1=16.487012062873045\n",
      "SubSGD iter. 491/499: loss=5.3890205259590624, w0=72.80000000000014, w1=16.912798210163785\n",
      "SubSGD iter. 492/499: loss=5.3832283624203905, w0=73.50000000000014, w1=17.55572790892758\n",
      "SubSGD iter. 493/499: loss=5.551302419642949, w0=72.80000000000014, w1=17.027672093416932\n",
      "SubSGD iter. 494/499: loss=5.400326040223161, w0=73.50000000000014, w1=16.34932509744239\n",
      "SubSGD iter. 495/499: loss=5.375368839178999, w0=72.80000000000014, w1=15.29140979061483\n",
      "SubSGD iter. 496/499: loss=5.339582119077515, w0=73.50000000000014, w1=14.672268635200448\n",
      "SubSGD iter. 497/499: loss=5.416468052734709, w0=72.80000000000014, w1=15.104061213483869\n",
      "SubSGD iter. 498/499: loss=5.351995272738447, w0=72.10000000000014, w1=14.047659982104978\n",
      "SubSGD iter. 499/499: loss=5.578685039170566, w0=71.40000000000013, w1=14.458735166647203\n",
      "SubSGD: execution time=0.043 seconds\n"
     ]
    }
   ],
   "source": [
    "# Define the parameters of the algorithm.\n",
    "max_iters = 500\n",
    "gamma = 0.7\n",
    "batch_size = 1\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start SubSGD.\n",
    "start_time = datetime.datetime.now()\n",
    "subsgd_losses, subsgd_ws = stochastic_subgradient_descent(\n",
    "    y, tx, w_initial, batch_size, max_iters, gamma\n",
    ")\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"SubSGD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-26T14:05:43.621647952Z",
     "start_time": "2023-10-26T14:05:43.289677266Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "interactive(children=(IntSlider(value=1, description='n_iter', max=501, min=1), Output()), _dom_classes=('widg…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6220b975875342f68bb260d97404a3f3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<function __main__.plot_figure(n_iter)>"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        subsgd_losses,\n",
    "        subsgd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(subsgd_ws)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
