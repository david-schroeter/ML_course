{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T07:56:25.290388821Z",
     "start_time": "2023-10-05T07:56:24.938184962Z"
    }
   },
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T08:24:59.323806965Z",
     "start_time": "2023-10-05T08:24:59.250097062Z"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "from helpers import *\n",
    "\n",
    "height, weight, gender = load_data(sub_sample=False, add_outlier=False)\n",
    "x, mean_x, std_x = standardize(height)\n",
    "y, tx = build_model_data(x, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T08:08:42.454578470Z",
     "start_time": "2023-10-05T08:08:42.414169284Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "((10000,), (10000, 2))"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape, tx.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NB: throughout this laboratory the data has the following format: \n",
    "  * there are **N = 10000** data entries\n",
    "  * **y** represents the column vector containing weight information -- that which we wish to predict/the output (see also the first page of $\\texttt{exercise02.pdf}$). Its **shape** is **(N,)**.\n",
    "  * **tx** represents the matrix $\\tilde{X}$ formed by laterally concatenating a column vector of 1s to the column vector of height information -- the input data (see also the first page of $\\texttt{exercise02.pdf}$). Its **shape** is **(N,2)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Computing the Cost Function\n",
    "Fill in the `compute_loss` function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T07:56:29.705331903Z",
     "start_time": "2023-10-05T07:56:29.692428271Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_loss(y, tx, w):\n",
    "    \"\"\"Calculate the loss using either MSE or MAE.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        w: numpy array of shape=(2,). The vector of model parameters.\n",
    "\n",
    "    Returns:\n",
    "        the value of the loss (a scalar), corresponding to the input parameters w.\n",
    "    \"\"\"\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    nb_sample = y.shape[0]\n",
    "    e = y - tx @ w\n",
    "    return 1/(2*nb_sample) * e.T @ e\n",
    "    # ***************************************************x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "def compute_loss_MAE(y, tx, w):\n",
    "    nb_sample = y.shape[0]\n",
    "    e = y - tx @ w\n",
    "    return 1/nb_sample * np.sum(np.abs(e))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-05T08:06:18.942034761Z",
     "start_time": "2023-10-05T08:06:18.773445232Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in the function `grid_search()` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T07:56:31.315126303Z",
     "start_time": "2023-10-05T07:56:31.277181258Z"
    }
   },
   "outputs": [],
   "source": [
    "# from costs import *\n",
    "\n",
    "\n",
    "def grid_search(y, tx, grid_w0, grid_w1):\n",
    "    \"\"\"Algorithm for grid search.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        grid_w0: numpy array of shape=(num_grid_pts_w0, ). A 1D array containing num_grid_pts_w0 values of parameter w0 to be tested in the grid search.\n",
    "        grid_w1: numpy array of shape=(num_grid_pts_w1, ). A 1D array containing num_grid_pts_w1 values of parameter w1 to be tested in the grid search.\n",
    "\n",
    "    Returns:\n",
    "        losses: numpy array of shape=(num_grid_pts_w0, num_grid_pts_w1). A 2D array containing the loss value for each combination of w0 and w1\n",
    "    \"\"\"\n",
    "\n",
    "    losses = np.zeros((len(grid_w0), len(grid_w1)))\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    w = np.hstack((grid_w0[:, np.newaxis], grid_w1[:, np.newaxis]))\n",
    "    for i in range(len(grid_w0)):\n",
    "        for j in range(len(grid_w1)):\n",
    "            w = np.array([grid_w0[i], grid_w1[j]])\n",
    "            losses[i, j] = compute_loss(y, tx, w)\n",
    "            \n",
    "    # ***************************************************\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T07:56:31.988903755Z",
     "start_time": "2023-10-05T07:56:31.972051900Z"
    }
   },
   "outputs": [],
   "source": [
    "# This function is a bit more efficient as it doesn't contain any for loop, but it is not possible to use the function compute_loss as\n",
    "# we implemented it, because it expects to treat each (w0, w1) separately\n",
    "\n",
    "# This one uses indices\n",
    "def grid_search_v2(y, tx, grid_w0, grid_w1):\n",
    "    row, col = np.indices((len(grid_w0), len(grid_w1)))\n",
    "    big_w0, big_w1 = grid_w0[row.ravel()], grid_w1[col.ravel()]\n",
    "    w = np.column_stack((big_w0, big_w1))\n",
    "    e = (y[:, np.newaxis] - tx @ w.T)**2\n",
    "    nb_sample = y.shape[0]\n",
    "    losses = 1/(2*nb_sample) * np.sum(e, axis=0)\n",
    "    return losses.reshape((len(grid_w0), len(grid_w1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T07:56:32.310394943Z",
     "start_time": "2023-10-05T07:56:32.286161632Z"
    }
   },
   "outputs": [],
   "source": [
    "# This one uses broadcasting, the broadcasting must be explicit, as we have to stack the arrays\n",
    "def grid_search_v3(y, tx, grid_w0, grid_w1):\n",
    "    w0_size, w1_size = grid_w0.shape[0], grid_w1.shape[0]\n",
    "    w0 = np.broadcast_to(grid_w0[:, np.newaxis], (w0_size, w1_size))\n",
    "    w1 = np.broadcast_to(grid_w1[np.newaxis, :], (w0_size, w1_size))\n",
    "    w = np.column_stack((w0.ravel(), w1.ravel()))\n",
    "    e = (y[:, np.newaxis] - tx @ w.T)**2\n",
    "    nb_sample = y.shape[0]\n",
    "    losses = 1/(2*nb_sample) * np.sum(e, axis=0)\n",
    "    return losses.reshape((len(grid_w0), len(grid_w1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us play with the grid search demo now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T07:53:44.308274536Z",
     "start_time": "2023-10-05T07:53:20.292125293Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.4 s ± 2.88 s per loop (mean ± std. dev. of 3 runs, 3 loops each)\n",
      "6 s ± 164 ms per loop (mean ± std. dev. of 3 runs, 3 loops each)\n",
      "6.12 s ± 121 ms per loop (mean ± std. dev. of 3 runs, 3 loops each)\n"
     ]
    }
   ],
   "source": [
    "from grid_search import generate_w\n",
    "grid_w0_t, grid_w1_t = generate_w(num_intervals=100)\n",
    "%timeit -r 3 -n 3 -c grid_search(y, tx, grid_w0_t, grid_w1_t)\n",
    "%timeit -r 3 -n 3 -c grid_search_v2(y, tx, grid_w0_t, grid_w1_t)\n",
    "%timeit -r 3 -n 3 -c grid_search_v3(y, tx, grid_w0_t, grid_w1_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T07:56:37.836352311Z",
     "start_time": "2023-10-05T07:56:36.589774191Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search: loss*=15.558703368609557, w0*=72.72727272727272, w1*=13.636363636363626, execution time=0.697 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 1000x600 with 3 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from grid_search import generate_w, get_best_parameters\n",
    "from plots import grid_visualization\n",
    "\n",
    "# Generate the grid of parameters to be swept\n",
    "grid_w0, grid_w1 = generate_w(num_intervals=100)\n",
    "\n",
    "# Start the grid search\n",
    "start_time = datetime.datetime.now()\n",
    "grid_losses = grid_search_v3(y, tx, grid_w0, grid_w1)\n",
    "\n",
    "# Select the best combinaison\n",
    "loss_star, w0_star, w1_star = get_best_parameters(grid_w0, grid_w1, grid_losses)\n",
    "end_time = datetime.datetime.now()\n",
    "execution_time = (end_time - start_time).total_seconds()\n",
    "\n",
    "# Print the results\n",
    "print(\n",
    "    \"Grid Search: loss*={l}, w0*={w0}, w1*={w1}, execution time={t:.3f} seconds\".format(\n",
    "        l=loss_star, w0=w0_star, w1=w1_star, t=execution_time\n",
    "    )\n",
    ")\n",
    "\n",
    "# Plot the results\n",
    "fig = grid_visualization(grid_losses, grid_w0, grid_w1, mean_x, std_x, height, weight)\n",
    "fig.set_size_inches(10.0, 6.0)\n",
    "fig.savefig(\"grid_plot\")  # Optional saving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, please fill in the functions `compute_gradient` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T07:56:39.062333459Z",
     "start_time": "2023-10-05T07:56:39.051103483Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_gradient(y, tx, w):\n",
    "    \"\"\"Computes the gradient at w.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        w: numpy array of shape=(2, ). The vector of model parameters.\n",
    "\n",
    "    Returns:\n",
    "        An numpy array of shape (2, ) (same shape as w), containing the gradient of the loss at w.\n",
    "    \"\"\"\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    nb_sample = y.shape[0]\n",
    "    e = y - tx @ w\n",
    "    return -1/nb_sample * tx.T @ e\n",
    "    # ***************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please fill in the functions `gradient_descent` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T07:56:40.092268461Z",
     "start_time": "2023-10-05T07:56:40.075270738Z"
    }
   },
   "outputs": [],
   "source": [
    "def gradient_descent(y, tx, initial_w, max_iters, gamma):\n",
    "    \"\"\"The Gradient Descent (GD) algorithm.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        initial_w: numpy array of shape=(2, ). The initial guess (or the initialization) for the model parameters\n",
    "        max_iters: a scalar denoting the total number of iterations of GD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "\n",
    "    Returns:\n",
    "        losses: a list of length max_iters containing the loss value (scalar) for each iteration of GD\n",
    "        ws: a list of length max_iters containing the model parameters as numpy arrays of shape (2, ), for each iteration of GD\n",
    "    \"\"\"\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        # ***************************************************\n",
    "        # INSERT YOUR CODE HERE\n",
    "        # TODO: compute gradient and loss\n",
    "        # ***************************************************\n",
    "        loss = compute_loss(y, tx, w)\n",
    "        gradient = compute_gradient(y, tx, w)\n",
    "        # ***************************************************\n",
    "        # INSERT YOUR CODE HERE\n",
    "        w = w - gamma*gradient\n",
    "        # ***************************************************\n",
    "\n",
    "        # store w and loss\n",
    "        ws.append(w)\n",
    "        losses.append(loss)\n",
    "        print(\n",
    "            \"GD iter. {bi}/{ti}: loss={l}, w0={w0}, w1={w1}\".format(\n",
    "                bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your gradient descent function through gradient descent demo shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T08:08:51.743360695Z",
     "start_time": "2023-10-05T08:08:51.696198134Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GD iter. 0/49: loss=2792.2367127591674, w0=51.30574540147361, w1=9.43579870449228\n",
      "GD iter. 1/49: loss=265.3024621089606, w0=66.69746902191571, w1=12.266538315839998\n",
      "GD iter. 2/49: loss=37.87837955044126, w0=71.31498610804834, w1=13.115760199244328\n",
      "GD iter. 3/49: loss=17.41021212017447, w0=72.70024123388814, w1=13.37052676426563\n",
      "GD iter. 4/49: loss=15.568077051450452, w0=73.11581777164007, w1=13.446956733772023\n",
      "GD iter. 5/49: loss=15.402284895265302, w0=73.24049073296565, w1=13.469885724623941\n",
      "GD iter. 6/49: loss=15.387363601208634, w0=73.27789262136334, w1=13.476764421879516\n",
      "GD iter. 7/49: loss=15.386020684743531, w0=73.28911318788263, w1=13.478828031056189\n",
      "GD iter. 8/49: loss=15.385899822261674, w0=73.29247935783842, w1=13.47944711380919\n",
      "GD iter. 9/49: loss=15.385888944638305, w0=73.29348920882516, w1=13.47963283863509\n",
      "GD iter. 10/49: loss=15.385887965652199, w0=73.29379216412119, w1=13.479688556082861\n",
      "GD iter. 11/49: loss=15.38588787754345, w0=73.29388305071, w1=13.479705271317192\n",
      "GD iter. 12/49: loss=15.385887869613665, w0=73.29391031668663, w1=13.479710285887492\n",
      "GD iter. 13/49: loss=15.385887868899985, w0=73.29391849647962, w1=13.479711790258582\n",
      "GD iter. 14/49: loss=15.385887868835756, w0=73.29392095041752, w1=13.479712241569908\n",
      "GD iter. 15/49: loss=15.385887868829968, w0=73.29392168659889, w1=13.479712376963306\n",
      "GD iter. 16/49: loss=15.385887868829451, w0=73.2939219074533, w1=13.479712417581325\n",
      "GD iter. 17/49: loss=15.3858878688294, w0=73.29392197370962, w1=13.479712429766732\n",
      "GD iter. 18/49: loss=15.385887868829407, w0=73.29392199358652, w1=13.479712433422353\n",
      "GD iter. 19/49: loss=15.385887868829403, w0=73.2939219995496, w1=13.47971243451904\n",
      "GD iter. 20/49: loss=15.3858878688294, w0=73.29392200133852, w1=13.479712434848047\n",
      "GD iter. 21/49: loss=15.385887868829398, w0=73.29392200187519, w1=13.479712434946748\n",
      "GD iter. 22/49: loss=15.385887868829403, w0=73.29392200203618, w1=13.479712434976358\n",
      "GD iter. 23/49: loss=15.3858878688294, w0=73.29392200208449, w1=13.479712434985242\n",
      "GD iter. 24/49: loss=15.3858878688294, w0=73.29392200209898, w1=13.479712434987906\n",
      "GD iter. 25/49: loss=15.385887868829402, w0=73.29392200210333, w1=13.479712434988706\n",
      "GD iter. 26/49: loss=15.385887868829403, w0=73.29392200210464, w1=13.479712434988945\n",
      "GD iter. 27/49: loss=15.385887868829398, w0=73.29392200210502, w1=13.479712434989018\n",
      "GD iter. 28/49: loss=15.385887868829396, w0=73.29392200210513, w1=13.47971243498904\n",
      "GD iter. 29/49: loss=15.385887868829403, w0=73.29392200210518, w1=13.479712434989047\n",
      "GD iter. 30/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 31/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 32/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 33/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 34/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 35/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 36/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 37/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 38/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 39/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 40/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 41/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 42/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 43/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 44/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 45/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 46/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 47/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 48/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 49/49: loss=15.385887868829398, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD: execution time=0.010 seconds\n"
     ]
    }
   ],
   "source": [
    "# from gradient_descent import *\n",
    "from plots import gradient_descent_visualization\n",
    "\n",
    "# Define the parameters of the algorithm.\n",
    "max_iters = 50\n",
    "gamma = 0.7\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start gradient descent.\n",
    "start_time = datetime.datetime.now()\n",
    "gd_losses, gd_ws = gradient_descent(y, tx, w_initial, max_iters, gamma)\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"GD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T07:56:42.078582498Z",
     "start_time": "2023-10-05T07:56:41.665939340Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "interactive(children=(IntSlider(value=1, description='n_iter', max=51, min=1), Output()), _dom_classes=('widge…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "682ac0b475b94591989ee353396666dd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<function __main__.plot_figure(n_iter)>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time Visualization\n",
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        gd_losses,\n",
    "        gd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "    \n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(gd_ws)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 4. Stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T08:23:31.760472499Z",
     "start_time": "2023-10-05T08:23:31.731669250Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_stoch_gradient(y, tx, w):\n",
    "    \"\"\"Compute a stochastic gradient at w from just few examples n and their corresponding y_n labels.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        w: numpy array of shape=(2, ). The vector of model parameters.\n",
    "\n",
    "    Returns:\n",
    "        A numpy array of shape (2, ) (same shape as w), containing the stochastic gradient of the loss at w.\n",
    "    \"\"\"\n",
    "\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    nb_sample = y.shape[0]\n",
    "    e = y - tx @ w\n",
    "    return -1/nb_sample * tx.T @ e\n",
    "    # ***************************************************\n",
    "\n",
    "\n",
    "def stochastic_gradient_descent(y, tx, initial_w, batch_size, max_iters, gamma):\n",
    "    \"\"\"The Stochastic Gradient Descent algorithm (SGD).\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        initial_w: numpy array of shape=(2, ). The initial guess (or the initialization) for the model parameters\n",
    "        batch_size: a scalar denoting the number of data points in a mini-batch used for computing the stochastic gradient\n",
    "        max_iters: a scalar denoting the total number of iterations of SGD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "\n",
    "    Returns:\n",
    "        losses: a list of length max_iters containing the loss value (scalar) for each iteration of SGD\n",
    "        ws: a list of length max_iters containing the model parameters as numpy arrays of shape (2, ), for each iteration of SGD\n",
    "    \"\"\"\n",
    "\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "\n",
    "    for n_iter in range(max_iters):\n",
    "        # ***************************************************\n",
    "        # INSERT YOUR CODE HERE\n",
    "        # TODO: implement stochastic gradient descent.\n",
    "        # ***************************************************\n",
    "        loss = compute_loss(y, tx, w)\n",
    "        gradient = np.zeros(tx.shape[1]) # init the gradient for the upcoming batch\n",
    "        for y_batch, tx_batch in batch_iter(y,tx, batch_size):\n",
    "            gradient += compute_stoch_gradient(y_batch, tx_batch, w)\n",
    "\n",
    "        w = w - gamma * gradient/batch_size\n",
    "        # store w and loss\n",
    "        ws.append(w)\n",
    "        losses.append(loss)\n",
    "        # ***************************************************\n",
    "        print(\n",
    "            \"SGD iter. {bi}/{ti}: loss={l}, w0={w0}, w1={w1}\".format(\n",
    "                bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]\n",
    "            )\n",
    "        )\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T08:24:30.766391420Z",
     "start_time": "2023-10-05T08:24:30.642208850Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD iter. 0/49: loss=2792.2367127591674, w0=5.68321294116898, w1=-7.039907321989116\n",
      "SGD iter. 1/49: loss=2511.5172752155922, w0=14.225267620194348, w1=-1.2445104939420464\n",
      "SGD iter. 2/49: loss=1868.3402235440758, w0=22.228471410358175, w1=8.513831515048441\n",
      "SGD iter. 3/49: loss=1331.555996593422, w0=27.23331534324224, w1=8.10691154586556\n",
      "SGD iter. 4/49: loss=1090.6091254571572, w0=32.32941117889554, w1=18.667302289862995\n",
      "SGD iter. 5/49: loss=867.8870056124554, w0=36.236022769748715, w1=16.175189393581295\n",
      "SGD iter. 6/49: loss=705.6626336437237, w0=40.43322232513989, w1=11.414964289237563\n",
      "SGD iter. 7/49: loss=557.4302719513751, w0=43.238386258138036, w1=11.331147947689304\n",
      "SGD iter. 8/49: loss=469.36166697531553, w0=46.608148341794085, w1=9.92888716313055\n",
      "SGD iter. 9/49: loss=377.7553258491407, w0=48.543937082575475, w1=7.526406317061618\n",
      "SGD iter. 10/49: loss=339.3876914941795, w0=51.87464332996305, w1=6.404630919853675\n",
      "SGD iter. 11/49: loss=269.80702650917584, w0=52.917213158187714, w1=4.84717823250323\n",
      "SGD iter. 12/49: loss=260.25134290226526, w0=55.82575920603146, w1=4.708087869712989\n",
      "SGD iter. 13/49: loss=206.42494236097377, w0=57.31560530991382, w1=4.866246247232401\n",
      "SGD iter. 14/49: loss=180.13508991062344, w0=59.36494955620602, w1=7.049165906657306\n",
      "SGD iter. 15/49: loss=133.0699888946581, w0=62.642553630431514, w1=10.869851522859658\n",
      "SGD iter. 16/49: loss=75.51739895370497, w0=63.39508841586241, w1=10.911875831098227\n",
      "SGD iter. 17/49: loss=67.67623346503419, w0=64.74969998122336, w1=11.64316920169139\n",
      "SGD iter. 18/49: loss=53.574198363776105, w0=65.43257041321986, w1=11.75939275737592\n",
      "SGD iter. 19/49: loss=47.76606216745577, w0=65.83008593029274, w1=11.651531170438895\n",
      "SGD iter. 20/49: loss=44.91143569029984, w0=67.37010940215428, w1=11.449978511104929\n",
      "SGD iter. 21/49: loss=34.99157562938096, w0=67.79469103534228, w1=11.266551099051211\n",
      "SGD iter. 22/49: loss=32.95570003117652, w0=68.44315920324996, w1=11.535710106763531\n",
      "SGD iter. 23/49: loss=29.0404102602814, w0=68.37593633774148, w1=11.606510228205492\n",
      "SGD iter. 24/49: loss=29.233622620022267, w0=68.1248190451919, w1=11.70535326713369\n",
      "SGD iter. 25/49: loss=30.31987578669044, w0=68.90092219510211, w1=12.203487238721932\n",
      "SGD iter. 26/49: loss=25.849486896787454, w0=70.20938163138057, w1=12.686467657473225\n",
      "SGD iter. 27/49: loss=20.45770115667246, w0=71.13418052827662, w1=11.076032353691707\n",
      "SGD iter. 28/49: loss=20.60696845232981, w0=71.90662410661784, w1=11.39286721429898\n",
      "SGD iter. 29/49: loss=18.5256470817997, w0=72.48031916786763, w1=11.875062761897096\n",
      "SGD iter. 30/49: loss=17.004312941446145, w0=72.17190075492759, w1=11.755170602256316\n",
      "SGD iter. 31/49: loss=17.502375974810967, w0=72.62120209033658, w1=12.431902463323539\n",
      "SGD iter. 32/49: loss=16.161116777035225, w0=71.71513115565163, w1=12.874234059192393\n",
      "SGD iter. 33/49: loss=16.81548016903085, w0=71.21686393833478, w1=13.384810494725652\n",
      "SGD iter. 34/49: loss=17.54747615809911, w0=71.88449241044992, w1=13.902929661305087\n",
      "SGD iter. 35/49: loss=16.46869016607149, w0=72.0806068073534, w1=13.649089563672062\n",
      "SGD iter. 36/49: loss=16.136299055597632, w0=71.9089868193194, w1=13.759465080088733\n",
      "SGD iter. 37/49: loss=16.3840413703085, w0=72.06603448709589, w1=13.919527017950942\n",
      "SGD iter. 38/49: loss=16.23646017728023, w0=71.52199572621467, w1=12.837860041914976\n",
      "SGD iter. 39/49: loss=17.161736479672484, w0=72.82760555802501, w1=14.06182306042647\n",
      "SGD iter. 40/49: loss=15.664039771962768, w0=72.66884489562231, w1=13.969242485577166\n",
      "SGD iter. 41/49: loss=15.701068398568305, w0=72.54561417480963, w1=14.035203708817424\n",
      "SGD iter. 42/49: loss=15.820155448675038, w0=72.96363426401125, w1=13.421703282950078\n",
      "SGD iter. 43/49: loss=15.442115394657144, w0=72.91156568773759, w1=13.469515873922354\n",
      "SGD iter. 44/49: loss=15.459038029326585, w0=72.55891947383492, w1=13.21319560305184\n",
      "SGD iter. 45/49: loss=15.691517837964168, w0=72.50427433882146, w1=13.201626670035644\n",
      "SGD iter. 46/49: loss=15.736325431228988, w0=72.58184865773362, w1=13.101725961016964\n",
      "SGD iter. 47/49: loss=15.710848979964585, w0=72.95881714598505, w1=13.375672335643914\n",
      "SGD iter. 48/49: loss=15.447447672262921, w0=73.37233787328695, w1=13.748142855431874\n",
      "SGD iter. 49/49: loss=15.424989838565555, w0=73.376000208375, w1=13.752224351920578\n",
      "SGD: execution time=0.066 seconds\n"
     ]
    }
   ],
   "source": [
    "# from stochastic_gradient_descent import *\n",
    "\n",
    "# Define the parameters of the algorithm.\n",
    "max_iters = 50\n",
    "gamma = 0.1\n",
    "batch_size = 1\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start SGD.\n",
    "start_time = datetime.datetime.now()\n",
    "sgd_losses, sgd_ws = stochastic_gradient_descent(\n",
    "    y, tx, w_initial, batch_size, max_iters, gamma\n",
    ")\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"SGD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T08:22:09.852037826Z",
     "start_time": "2023-10-05T08:22:09.485488673Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "interactive(children=(IntSlider(value=1, description='n_iter', max=51, min=1), Output()), _dom_classes=('widge…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "35dbd505a2b54441b17d3c4b2edd7b12"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<function __main__.plot_figure(n_iter)>"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time Visualization\n",
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        sgd_losses,\n",
    "        sgd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(sgd_ws)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Effect of Outliers and MAE Cost Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T08:25:28.960981640Z",
     "start_time": "2023-10-05T08:25:28.903237746Z"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "from helpers import *\n",
    "\n",
    "# ***************************************************\n",
    "# INSERT YOUR CODE HERE\n",
    "# TODO: reload the data by subsampling first, then by subsampling and adding outliers\n",
    "height, weight, gender = load_data(sub_sample=True, add_outlier=True)\n",
    "x, mean_x, std_x = standardize(height)\n",
    "y, tx = build_model_data(x, weight)\n",
    "# ***************************************************\n",
    "\n",
    "x, mean_x, std_x = standardize(height)\n",
    "y, tx = build_model_data(x, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T08:09:39.920795334Z",
     "start_time": "2023-10-05T08:09:39.895305405Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "((200,), (200, 2))"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape, tx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T08:10:37.801456654Z",
     "start_time": "2023-10-05T08:10:37.781489408Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GD iter. 0/49: loss=2869.835114535854, w0=51.84746409844846, w1=7.724426406192428\n",
      "GD iter. 1/49: loss=318.2821247015954, w0=67.40170332798299, w1=10.041754328050121\n",
      "GD iter. 2/49: loss=88.6423556165127, w0=72.06797509684336, w1=10.736952704607413\n",
      "GD iter. 3/49: loss=67.9747763988552, w0=73.46785662750146, w1=10.945512217574597\n",
      "GD iter. 4/49: loss=66.11469426926604, w0=73.88782108669889, w1=11.00808007146475\n",
      "GD iter. 5/49: loss=65.94728687760302, w0=74.01381042445813, w1=11.026850427631794\n",
      "GD iter. 6/49: loss=65.93222021235334, w0=74.0516072257859, w1=11.03248153448191\n",
      "GD iter. 7/49: loss=65.93086421248088, w0=74.06294626618423, w1=11.034170866536943\n",
      "GD iter. 8/49: loss=65.93074217249236, w0=74.06634797830372, w1=11.034677666153454\n",
      "GD iter. 9/49: loss=65.93073118889338, w0=74.06736849193958, w1=11.034829706038408\n",
      "GD iter. 10/49: loss=65.93073020036948, w0=74.06767464603033, w1=11.034875318003893\n",
      "GD iter. 11/49: loss=65.93073011140234, w0=74.06776649225755, w1=11.03488900159354\n",
      "GD iter. 12/49: loss=65.93073010339528, w0=74.06779404612573, w1=11.034893106670433\n",
      "GD iter. 13/49: loss=65.93073010267466, w0=74.06780231228618, w1=11.034894338193501\n",
      "GD iter. 14/49: loss=65.93073010260979, w0=74.06780479213431, w1=11.034894707650421\n",
      "GD iter. 15/49: loss=65.93073010260395, w0=74.06780553608876, w1=11.034894818487498\n",
      "GD iter. 16/49: loss=65.93073010260343, w0=74.06780575927509, w1=11.03489485173862\n",
      "GD iter. 17/49: loss=65.93073010260338, w0=74.06780582623098, w1=11.034894861713957\n",
      "GD iter. 18/49: loss=65.93073010260338, w0=74.06780584631775, w1=11.034894864706558\n",
      "GD iter. 19/49: loss=65.93073010260338, w0=74.06780585234378, w1=11.034894865604338\n",
      "GD iter. 20/49: loss=65.93073010260338, w0=74.06780585415159, w1=11.034894865873673\n",
      "GD iter. 21/49: loss=65.93073010260339, w0=74.06780585469393, w1=11.034894865954472\n",
      "GD iter. 22/49: loss=65.93073010260338, w0=74.06780585485663, w1=11.034894865978712\n",
      "GD iter. 23/49: loss=65.93073010260338, w0=74.06780585490544, w1=11.034894865985985\n",
      "GD iter. 24/49: loss=65.93073010260338, w0=74.0678058549201, w1=11.034894865988166\n",
      "GD iter. 25/49: loss=65.93073010260338, w0=74.06780585492449, w1=11.034894865988822\n",
      "GD iter. 26/49: loss=65.93073010260338, w0=74.06780585492581, w1=11.034894865989017\n",
      "GD iter. 27/49: loss=65.93073010260338, w0=74.06780585492619, w1=11.034894865989076\n",
      "GD iter. 28/49: loss=65.93073010260338, w0=74.06780585492632, w1=11.034894865989093\n",
      "GD iter. 29/49: loss=65.93073010260338, w0=74.06780585492635, w1=11.0348948659891\n",
      "GD iter. 30/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 31/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 32/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 33/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 34/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 35/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 36/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 37/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 38/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 39/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 40/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 41/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 42/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 43/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 44/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 45/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 46/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 47/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 48/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 49/49: loss=65.93073010260338, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD: execution time=0.002 seconds\n"
     ]
    }
   ],
   "source": [
    "from plots import gradient_descent_visualization\n",
    "\n",
    "# Define the parameters of the algorithm.\n",
    "max_iters = 50\n",
    "gamma = 0.7\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start gradient descent.\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "# ***************************************************\n",
    "# INSERT YOUR CODE HERE\n",
    "# TODO: fit the model to the subsampled data / subsampled data with outliers and visualize the cloud of points\n",
    "gd_losses, gd_ws = gradient_descent(y, tx, w_initial, max_iters, gamma)\n",
    "#       and the model fit\n",
    "# ***************************************************\n",
    "\n",
    "\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"GD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T07:56:53.270899444Z",
     "start_time": "2023-10-05T07:56:52.885292788Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "interactive(children=(IntSlider(value=1, description='n_iter', max=51, min=1), Output()), _dom_classes=('widge…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "94050fda60934180afaf3a7deda6596f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<function __main__.plot_figure(n_iter)>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time Visualization\n",
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        gd_losses,\n",
    "        gd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(gd_ws)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 6. Subgradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T08:00:13.520979743Z",
     "start_time": "2023-10-05T08:00:13.503344344Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_subgradient_mae(y, tx, w):\n",
    "    \"\"\"Compute a subgradient of the MAE at w.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        w: numpy array of shape=(2, ). The vector of model parameters.\n",
    "\n",
    "    Returns:\n",
    "        A numpy array of shape (2, ) (same shape as w), containing the subgradient of the MAE at w.\n",
    "    \"\"\"\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # TODO: compute subgradient gradient vector for MAE\n",
    "\n",
    "    #return -1/nb_sample * tx.T @ e\n",
    "    nb_sample = y.shape[0]\n",
    "    e = y - tx @ w\n",
    "    return -1/nb_sample * tx.T @ np.sign(e)\n",
    "    \n",
    "    # ***************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T08:06:25.653984286Z",
     "start_time": "2023-10-05T08:06:25.591651835Z"
    }
   },
   "outputs": [],
   "source": [
    "def subgradient_descent(y, tx, initial_w, max_iters, gamma):\n",
    "    \"\"\"The SubGradient Descent (SubGD) algorithm.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        initial_w: numpy array of shape=(2, ). The initial guess (or the initialization) for the model parameters\n",
    "        max_iters: a scalar denoting the total number of iterations of GD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "\n",
    "    Returns:\n",
    "        losses: a list of length max_iters containing the loss value (scalar) for each iteration of SubGD\n",
    "        ws: a list of length max_iters containing the model parameters as numpy arrays of shape (2, ), for each iteration of SubGD\n",
    "    \"\"\"\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        # ***************************************************\n",
    "        # INSERT YOUR CODE HERE\n",
    "        # TODO: compute subgradient and loss\n",
    "        # ***************************************************\n",
    "        loss = compute_loss_MAE(y, tx, w)\n",
    "        subgradient = compute_subgradient_mae(y, tx, w)\n",
    "        # ***************************************************\n",
    "        # INSERT YOUR CODE HERE\n",
    "        # TODO: update w by subgradient\n",
    "        w = w - gamma*subgradient\n",
    "        # ***************************************************\n",
    "\n",
    "        ws.append(w)\n",
    "        losses.append(loss)\n",
    "        print(\n",
    "            \"SubGD iter. {bi}/{ti}: loss={l}, w0={w0}, w1={w1}\".format(\n",
    "                bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T08:10:46.384137784Z",
     "start_time": "2023-10-05T08:10:46.349344251Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SubGD iter. 0/499: loss=74.06780585492638, w0=0.7000000000000004, w1=7.625844400394043e-16\n",
      "SubGD iter. 1/499: loss=73.36780585492637, w0=1.4000000000000008, w1=1.5251688800788087e-15\n",
      "SubGD iter. 2/499: loss=72.66780585492637, w0=2.1000000000000014, w1=2.287753320118213e-15\n",
      "SubGD iter. 3/499: loss=71.96780585492637, w0=2.8000000000000016, w1=3.0503377601576174e-15\n",
      "SubGD iter. 4/499: loss=71.26780585492638, w0=3.5000000000000018, w1=3.812922200197022e-15\n",
      "SubGD iter. 5/499: loss=70.56780585492639, w0=4.200000000000002, w1=4.575506640236426e-15\n",
      "SubGD iter. 6/499: loss=69.86780585492637, w0=4.900000000000002, w1=5.3380910802758305e-15\n",
      "SubGD iter. 7/499: loss=69.16780585492637, w0=5.600000000000002, w1=6.100675520315235e-15\n",
      "SubGD iter. 8/499: loss=68.46780585492637, w0=6.3000000000000025, w1=6.863259960354639e-15\n",
      "SubGD iter. 9/499: loss=67.76780585492638, w0=7.000000000000003, w1=7.625844400394044e-15\n",
      "SubGD iter. 10/499: loss=67.06780585492638, w0=7.700000000000003, w1=8.388428840433449e-15\n",
      "SubGD iter. 11/499: loss=66.36780585492637, w0=8.400000000000004, w1=9.151013280472854e-15\n",
      "SubGD iter. 12/499: loss=65.66780585492639, w0=9.100000000000005, w1=9.913597720512259e-15\n",
      "SubGD iter. 13/499: loss=64.96780585492637, w0=9.800000000000006, w1=1.0676182160551664e-14\n",
      "SubGD iter. 14/499: loss=64.26780585492638, w0=10.500000000000007, w1=1.1438766600591069e-14\n",
      "SubGD iter. 15/499: loss=63.56780585492637, w0=11.200000000000008, w1=1.2201351040630474e-14\n",
      "SubGD iter. 16/499: loss=62.867805854926374, w0=11.90000000000001, w1=1.2963935480669879e-14\n",
      "SubGD iter. 17/499: loss=62.16780585492637, w0=12.60000000000001, w1=1.3726519920709284e-14\n",
      "SubGD iter. 18/499: loss=61.46780585492636, w0=13.300000000000011, w1=1.448910436074869e-14\n",
      "SubGD iter. 19/499: loss=60.76780585492637, w0=14.000000000000012, w1=1.5251688800788094e-14\n",
      "SubGD iter. 20/499: loss=60.06780585492637, w0=14.700000000000014, w1=1.60142732408275e-14\n",
      "SubGD iter. 21/499: loss=59.36780585492637, w0=15.400000000000015, w1=1.6776857680866904e-14\n",
      "SubGD iter. 22/499: loss=58.667805854926364, w0=16.100000000000016, w1=1.753944212090631e-14\n",
      "SubGD iter. 23/499: loss=57.96780585492636, w0=16.800000000000015, w1=1.8302026560945714e-14\n",
      "SubGD iter. 24/499: loss=57.267805854926365, w0=17.500000000000014, w1=1.906461100098512e-14\n",
      "SubGD iter. 25/499: loss=56.56780585492637, w0=18.200000000000014, w1=1.9827195441024524e-14\n",
      "SubGD iter. 26/499: loss=55.86780585492637, w0=18.900000000000013, w1=2.058977988106393e-14\n",
      "SubGD iter. 27/499: loss=55.16780585492637, w0=19.600000000000012, w1=2.1352364321103335e-14\n",
      "SubGD iter. 28/499: loss=54.46780585492636, w0=20.30000000000001, w1=2.211494876114274e-14\n",
      "SubGD iter. 29/499: loss=53.767805854926365, w0=21.00000000000001, w1=2.2877533201182145e-14\n",
      "SubGD iter. 30/499: loss=53.06780585492637, w0=21.70000000000001, w1=2.364011764122155e-14\n",
      "SubGD iter. 31/499: loss=52.36780585492637, w0=22.40000000000001, w1=2.4402702081260955e-14\n",
      "SubGD iter. 32/499: loss=51.66780585492637, w0=23.10000000000001, w1=2.516528652130036e-14\n",
      "SubGD iter. 33/499: loss=50.96780585492636, w0=23.800000000000008, w1=2.5927870961339765e-14\n",
      "SubGD iter. 34/499: loss=50.26780585492637, w0=24.500000000000007, w1=2.669045540137917e-14\n",
      "SubGD iter. 35/499: loss=49.56780585492638, w0=25.200000000000006, w1=2.7453039841418575e-14\n",
      "SubGD iter. 36/499: loss=48.86780585492637, w0=25.900000000000006, w1=2.821562428145798e-14\n",
      "SubGD iter. 37/499: loss=48.16780585492637, w0=26.600000000000005, w1=2.8978208721497385e-14\n",
      "SubGD iter. 38/499: loss=47.46780585492637, w0=27.300000000000004, w1=2.9740793161536787e-14\n",
      "SubGD iter. 39/499: loss=46.76780585492637, w0=28.000000000000004, w1=3.050337760157619e-14\n",
      "SubGD iter. 40/499: loss=46.06780585492638, w0=28.700000000000003, w1=3.126596204161559e-14\n",
      "SubGD iter. 41/499: loss=45.367805854926374, w0=29.400000000000002, w1=3.202854648165499e-14\n",
      "SubGD iter. 42/499: loss=44.66780585492637, w0=30.1, w1=3.2791130921694394e-14\n",
      "SubGD iter. 43/499: loss=43.96780585492637, w0=30.8, w1=3.3553715361733796e-14\n",
      "SubGD iter. 44/499: loss=43.26780585492637, w0=31.5, w1=3.43162998017732e-14\n",
      "SubGD iter. 45/499: loss=42.567805854926384, w0=32.2, w1=3.50788842418126e-14\n",
      "SubGD iter. 46/499: loss=41.867805854926374, w0=32.900000000000006, w1=3.5841468681852e-14\n",
      "SubGD iter. 47/499: loss=41.16780585492638, w0=33.60000000000001, w1=3.6604053121891404e-14\n",
      "SubGD iter. 48/499: loss=40.46780585492637, w0=34.30000000000001, w1=3.7366637561930805e-14\n",
      "SubGD iter. 49/499: loss=39.767805854926365, w0=35.000000000000014, w1=3.812922200197021e-14\n",
      "SubGD iter. 50/499: loss=39.06780585492637, w0=35.70000000000002, w1=3.889180644200961e-14\n",
      "SubGD iter. 51/499: loss=38.36780585492637, w0=36.40000000000002, w1=3.965439088204901e-14\n",
      "SubGD iter. 52/499: loss=37.667805854926364, w0=37.10000000000002, w1=4.041697532208841e-14\n",
      "SubGD iter. 53/499: loss=36.967805854926354, w0=37.800000000000026, w1=4.1179559762127815e-14\n",
      "SubGD iter. 54/499: loss=36.26780585492636, w0=38.50000000000003, w1=4.1942144202167217e-14\n",
      "SubGD iter. 55/499: loss=35.56780585492635, w0=39.20000000000003, w1=4.270472864220662e-14\n",
      "SubGD iter. 56/499: loss=34.86780585492634, w0=39.900000000000034, w1=4.346731308224602e-14\n",
      "SubGD iter. 57/499: loss=34.16780585492634, w0=40.60000000000004, w1=4.422989752228542e-14\n",
      "SubGD iter. 58/499: loss=33.46780585492633, w0=41.30000000000004, w1=4.4992481962324824e-14\n",
      "SubGD iter. 59/499: loss=32.76780585492634, w0=42.00000000000004, w1=4.5755066402364226e-14\n",
      "SubGD iter. 60/499: loss=32.067805854926334, w0=42.700000000000045, w1=4.651765084240363e-14\n",
      "SubGD iter. 61/499: loss=31.36780585492633, w0=43.40000000000005, w1=4.728023528244303e-14\n",
      "SubGD iter. 62/499: loss=30.667805854926332, w0=44.10000000000005, w1=4.804281972248243e-14\n",
      "SubGD iter. 63/499: loss=29.967805854926326, w0=44.800000000000054, w1=4.8805404162521834e-14\n",
      "SubGD iter. 64/499: loss=29.267805854926323, w0=45.50000000000006, w1=4.9567988602561235e-14\n",
      "SubGD iter. 65/499: loss=28.56780585492632, w0=46.20000000000006, w1=5.033057304260064e-14\n",
      "SubGD iter. 66/499: loss=27.867805854926317, w0=46.90000000000006, w1=5.109315748264004e-14\n",
      "SubGD iter. 67/499: loss=27.173270209668893, w0=47.59306930693076, w1=0.011147845678281268\n",
      "SubGD iter. 68/499: loss=26.490451563751183, w0=48.279207920792146, w1=0.03308574108990965\n",
      "SubGD iter. 69/499: loss=25.817212322770157, w0=48.965346534653534, w1=0.055023636501538034\n",
      "SubGD iter. 70/499: loss=25.155039434656434, w0=49.630693069307, w1=0.10538326388308852\n",
      "SubGD iter. 71/499: loss=24.524103413894757, w0=50.28910891089116, w1=0.16746568532794484\n",
      "SubGD iter. 72/499: loss=23.89929534603557, w0=50.94752475247532, w1=0.22954810677280116\n",
      "SubGD iter. 73/499: loss=23.284392925657123, w0=51.59207920792086, w1=0.31242512932748595\n",
      "SubGD iter. 74/499: loss=22.686876444181824, w0=52.22277227722779, w1=0.4119501328840099\n",
      "SubGD iter. 75/499: loss=22.10626756964053, w0=52.84653465346541, w1=0.5208167847923866\n",
      "SubGD iter. 76/499: loss=21.53781882800841, w0=53.45643564356442, w1=0.6457900912636104\n",
      "SubGD iter. 77/499: loss=20.986339874628445, w0=54.059405940594125, w1=0.7796904498577328\n",
      "SubGD iter. 78/499: loss=20.44556093662042, w0=54.655445544554524, w1=0.9197570104995809\n",
      "SubGD iter. 79/499: loss=19.91191015895782, w0=55.244554455445616, w1=1.0670920297850033\n",
      "SubGD iter. 80/499: loss=19.389644090563205, w0=55.81980198019809, w1=1.2261255948210887\n",
      "SubGD iter. 81/499: loss=18.88798906439586, w0=56.36732673267334, w1=1.4107093426222252\n",
      "SubGD iter. 82/499: loss=18.41596050185421, w0=56.900990099009974, w1=1.6058537322202813\n",
      "SubGD iter. 83/499: loss=17.95489854304036, w0=57.4277227722773, w1=1.8087628022939741\n",
      "SubGD iter. 84/499: loss=17.505757656579803, w0=57.9336633663367, w1=2.0285064197514817\n",
      "SubGD iter. 85/499: loss=17.074957426931594, w0=58.4326732673268, w1=2.24943708486729\n",
      "SubGD iter. 86/499: loss=16.65296729750988, w0=58.91089108910898, w1=2.4837982986028466\n",
      "SubGD iter. 87/499: loss=16.248540731496703, w0=59.38217821782185, w1=2.7260245553531632\n",
      "SubGD iter. 88/499: loss=15.849105212654136, w0=59.83960396039611, w1=2.9787423334691487\n",
      "SubGD iter. 89/499: loss=15.466919791231307, w0=60.26237623762383, w1=3.251528669355451\n",
      "SubGD iter. 90/499: loss=15.108294621512195, w0=60.67821782178225, w1=3.5270865794242927\n",
      "SubGD iter. 91/499: loss=14.754896345922813, w0=61.087128712871355, w1=3.8064591839518287\n",
      "SubGD iter. 92/499: loss=14.404528961620256, w0=61.49603960396046, w1=4.085831788479364\n",
      "SubGD iter. 93/499: loss=14.055787028127256, w0=61.891089108910954, w1=4.373839384328622\n",
      "SubGD iter. 94/499: loss=13.714620911605614, w0=62.27920792079214, w1=4.666037469532062\n",
      "SubGD iter. 95/499: loss=13.381236307284132, w0=62.653465346534716, w1=4.959829093241784\n",
      "SubGD iter. 96/499: loss=13.058821615166217, w0=63.020792079207986, w1=5.257057192056655\n",
      "SubGD iter. 97/499: loss=12.740251724339217, w0=63.38118811881195, w1=5.560434316352422\n",
      "SubGD iter. 98/499: loss=12.42321888875609, w0=63.74158415841591, w1=5.86381144064819\n",
      "SubGD iter. 99/499: loss=12.10756173190115, w0=64.08811881188126, w1=6.172402175278565\n",
      "SubGD iter. 100/499: loss=11.800622097398117, w0=64.42772277227729, w1=6.486369310516515\n",
      "SubGD iter. 101/499: loss=11.495041794646406, w0=64.76732673267333, w1=6.800336445754466\n",
      "SubGD iter. 102/499: loss=11.189461491894695, w0=65.10693069306936, w1=7.114303580992416\n",
      "SubGD iter. 103/499: loss=10.883881189142983, w0=65.44653465346539, w1=7.428270716230367\n",
      "SubGD iter. 104/499: loss=10.584593408313182, w0=65.76534653465352, w1=7.747893210218644\n",
      "SubGD iter. 105/499: loss=10.295816534318924, w0=66.07029702970303, w1=8.073669686866923\n",
      "SubGD iter. 106/499: loss=10.011352081221341, w0=66.37524752475254, w1=8.399446163515202\n",
      "SubGD iter. 107/499: loss=9.72808432666811, w0=66.66633663366343, w1=8.732970280417408\n",
      "SubGD iter. 108/499: loss=9.448125461122489, w0=66.95742574257433, w1=9.066494397319614\n",
      "SubGD iter. 109/499: loss=9.171041104096652, w0=67.23465346534661, w1=9.398630319470307\n",
      "SubGD iter. 110/499: loss=8.903656131158945, w0=67.51188118811889, w1=9.730766241621\n",
      "SubGD iter. 111/499: loss=8.636271158221236, w0=67.78910891089117, w1=10.062902163771692\n",
      "SubGD iter. 112/499: loss=8.376151920302355, w0=68.06633663366345, w1=10.36399928997944\n",
      "SubGD iter. 113/499: loss=8.140540838751479, w0=68.32970297029712, w1=10.66046690927363\n",
      "SubGD iter. 114/499: loss=7.918544501597256, w0=68.59306930693079, w1=10.943174379960832\n",
      "SubGD iter. 115/499: loss=7.705279728376982, w0=68.85643564356445, w1=11.225881850648033\n",
      "SubGD iter. 116/499: loss=7.4936958311786235, w0=69.11287128712881, w1=11.504395843582225\n",
      "SubGD iter. 117/499: loss=7.289992405743398, w0=69.35544554455456, w1=11.78820189306777\n",
      "SubGD iter. 118/499: loss=7.0972340357815265, w0=69.58415841584169, w1=12.06091146519099\n",
      "SubGD iter. 119/499: loss=6.919905294668907, w0=69.8059405940595, w1=12.324245668386068\n",
      "SubGD iter. 120/499: loss=6.750573527315438, w0=70.02772277227733, w1=12.587579871581145\n",
      "SubGD iter. 121/499: loss=6.584744810805648, w0=70.25643564356446, w1=12.824765405096503\n",
      "SubGD iter. 122/499: loss=6.43034327634779, w0=70.47821782178228, w1=13.065616959310168\n",
      "SubGD iter. 123/499: loss=6.278071481890337, w0=70.6930693069308, w1=13.302953389983932\n",
      "SubGD iter. 124/499: loss=6.1336633292633085, w0=70.8940594059407, w1=13.525403099312937\n",
      "SubGD iter. 125/499: loss=6.005840798343017, w0=71.08811881188129, w1=13.742945617944232\n",
      "SubGD iter. 126/499: loss=5.885021825223205, w0=71.27524752475257, w1=13.953548196006865\n",
      "SubGD iter. 127/499: loss=5.771635252269645, w0=71.46237623762386, w1=14.1641507740695\n",
      "SubGD iter. 128/499: loss=5.667162061790244, w0=71.62178217821791, w1=14.349779559473198\n",
      "SubGD iter. 129/499: loss=5.586726765993134, w0=71.75346534653474, w1=14.516890107612335\n",
      "SubGD iter. 130/499: loss=5.523847812160379, w0=71.87128712871295, w1=14.67079118532421\n",
      "SubGD iter. 131/499: loss=5.4800937085918635, w0=71.95445544554464, w1=14.780276456654546\n",
      "SubGD iter. 132/499: loss=5.4530880035020175, w0=72.03762376237633, w1=14.889761727984881\n",
      "SubGD iter. 133/499: loss=5.427392630862901, w0=72.1069306930694, w1=14.985916181776751\n",
      "SubGD iter. 134/499: loss=5.407322445682746, w0=72.17623762376247, w1=15.082070635568622\n",
      "SubGD iter. 135/499: loss=5.387252260502593, w0=72.24554455445555, w1=15.178225089360492\n",
      "SubGD iter. 136/499: loss=5.370460780338691, w0=72.30099009901001, w1=15.259723489715935\n",
      "SubGD iter. 137/499: loss=5.3574065233347365, w0=72.34950495049516, w1=15.335091856448162\n",
      "SubGD iter. 138/499: loss=5.345929264022579, w0=72.39801980198031, w1=15.41046022318039\n",
      "SubGD iter. 139/499: loss=5.33571465951747, w0=72.43267326732685, w1=15.46996178675575\n",
      "SubGD iter. 140/499: loss=5.330043910465358, w0=72.46039603960408, w1=15.518645285832834\n",
      "SubGD iter. 141/499: loss=5.325676428273224, w0=72.48811881188131, w1=15.561592159086512\n",
      "SubGD iter. 142/499: loss=5.322176726526589, w0=72.50198019801992, w1=15.59782833203255\n",
      "SubGD iter. 143/499: loss=5.32011130964311, w0=72.52277227722784, w1=15.624722856626738\n",
      "SubGD iter. 144/499: loss=5.318478284898437, w0=72.55049504950507, w1=15.642690329098025\n",
      "SubGD iter. 145/499: loss=5.317240048565144, w0=72.56435643564369, w1=15.664356578291116\n",
      "SubGD iter. 146/499: loss=5.316406547951545, w0=72.58514851485161, w1=15.677095775361309\n",
      "SubGD iter. 147/499: loss=5.315557122666142, w0=72.60594059405953, w1=15.689834972431502\n",
      "SubGD iter. 148/499: loss=5.314707697380738, w0=72.62673267326745, w1=15.702574169501695\n",
      "SubGD iter. 149/499: loss=5.313876880922166, w0=72.64059405940607, w1=15.724240418694786\n",
      "SubGD iter. 150/499: loss=5.313052246871382, w0=72.66138613861399, w1=15.736979615764978\n",
      "SubGD iter. 151/499: loss=5.312377839024388, w0=72.6683168316833, w1=15.748110294231305\n",
      "SubGD iter. 152/499: loss=5.312132229725042, w0=72.6752475247526, w1=15.759240972697631\n",
      "SubGD iter. 153/499: loss=5.311886620425697, w0=72.68217821782191, w1=15.770371651163957\n",
      "SubGD iter. 154/499: loss=5.311683566098434, w0=72.68217821782191, w1=15.774323911906711\n",
      "SubGD iter. 155/499: loss=5.311661251291322, w0=72.68217821782191, w1=15.778276172649464\n",
      "SubGD iter. 156/499: loss=5.311638936484209, w0=72.68217821782191, w1=15.782228433392218\n",
      "SubGD iter. 157/499: loss=5.311616621677096, w0=72.68217821782191, w1=15.786180694134972\n",
      "SubGD iter. 158/499: loss=5.311594306869985, w0=72.68217821782191, w1=15.790132954877725\n",
      "SubGD iter. 159/499: loss=5.311571992062872, w0=72.68217821782191, w1=15.794085215620479\n",
      "SubGD iter. 160/499: loss=5.311549677255759, w0=72.68217821782191, w1=15.798037476363232\n",
      "SubGD iter. 161/499: loss=5.311527362448647, w0=72.68217821782191, w1=15.801989737105986\n",
      "SubGD iter. 162/499: loss=5.3115050476415355, w0=72.68217821782191, w1=15.80594199784874\n",
      "SubGD iter. 163/499: loss=5.311482732834422, w0=72.68217821782191, w1=15.809894258591493\n",
      "SubGD iter. 164/499: loss=5.311460418027309, w0=72.68217821782191, w1=15.813846519334247\n",
      "SubGD iter. 165/499: loss=5.311438103220198, w0=72.68217821782191, w1=15.817798780077\n",
      "SubGD iter. 166/499: loss=5.311415788413084, w0=72.68217821782191, w1=15.821751040819754\n",
      "SubGD iter. 167/499: loss=5.311393473605972, w0=72.68217821782191, w1=15.825703301562507\n",
      "SubGD iter. 168/499: loss=5.311371158798861, w0=72.68217821782191, w1=15.82965556230526\n",
      "SubGD iter. 169/499: loss=5.311348843991747, w0=72.68217821782191, w1=15.833607823048014\n",
      "SubGD iter. 170/499: loss=5.311326529184636, w0=72.68217821782191, w1=15.837560083790768\n",
      "SubGD iter. 171/499: loss=5.3113042143775235, w0=72.68217821782191, w1=15.841512344533522\n",
      "SubGD iter. 172/499: loss=5.311281899570409, w0=72.68217821782191, w1=15.845464605276275\n",
      "SubGD iter. 173/499: loss=5.311259584763298, w0=72.68217821782191, w1=15.849416866019029\n",
      "SubGD iter. 174/499: loss=5.311237269956186, w0=72.68217821782191, w1=15.853369126761782\n",
      "SubGD iter. 175/499: loss=5.3112149551490715, w0=72.68217821782191, w1=15.857321387504536\n",
      "SubGD iter. 176/499: loss=5.31119264034196, w0=72.68217821782191, w1=15.86127364824729\n",
      "SubGD iter. 177/499: loss=5.311170325534848, w0=72.68217821782191, w1=15.865225908990043\n",
      "SubGD iter. 178/499: loss=5.311148010727736, w0=72.68217821782191, w1=15.869178169732796\n",
      "SubGD iter. 179/499: loss=5.311125695920623, w0=72.68217821782191, w1=15.87313043047555\n",
      "SubGD iter. 180/499: loss=5.3111033811135115, w0=72.68217821782191, w1=15.877082691218304\n",
      "SubGD iter. 181/499: loss=5.311081066306398, w0=72.68217821782191, w1=15.881034951961057\n",
      "SubGD iter. 182/499: loss=5.311058751499286, w0=72.68217821782191, w1=15.88498721270381\n",
      "SubGD iter. 183/499: loss=5.311036436692174, w0=72.68217821782191, w1=15.888939473446564\n",
      "SubGD iter. 184/499: loss=5.31101412188506, w0=72.68217821782191, w1=15.892891734189318\n",
      "SubGD iter. 185/499: loss=5.310991807077948, w0=72.68217821782191, w1=15.896843994932071\n",
      "SubGD iter. 186/499: loss=5.310969492270836, w0=72.68217821782191, w1=15.900796255674825\n",
      "SubGD iter. 187/499: loss=5.3109471774637225, w0=72.68217821782191, w1=15.904748516417579\n",
      "SubGD iter. 188/499: loss=5.310924862656612, w0=72.68217821782191, w1=15.908700777160332\n",
      "SubGD iter. 189/499: loss=5.310902547849499, w0=72.68217821782191, w1=15.912653037903086\n",
      "SubGD iter. 190/499: loss=5.310913706061381, w0=72.6752475247526, w1=15.910526938117348\n",
      "SubGD iter. 191/499: loss=5.31089223718627, w0=72.6752475247526, w1=15.914479198860102\n",
      "SubGD iter. 192/499: loss=5.3108699223791564, w0=72.6752475247526, w1=15.918431459602855\n",
      "SubGD iter. 193/499: loss=5.310862636053835, w0=72.6683168316833, w1=15.916305359817118\n",
      "SubGD iter. 194/499: loss=5.310859611715927, w0=72.6683168316833, w1=15.920257620559871\n",
      "SubGD iter. 195/499: loss=5.310837296908815, w0=72.6683168316833, w1=15.924209881302625\n",
      "SubGD iter. 196/499: loss=5.310814982101703, w0=72.6683168316833, w1=15.928162142045379\n",
      "SubGD iter. 197/499: loss=5.310823570190171, w0=72.66138613861399, w1=15.926036042259641\n",
      "SubGD iter. 198/499: loss=5.310804671438475, w0=72.66138613861399, w1=15.929988303002395\n",
      "SubGD iter. 199/499: loss=5.3107823566313614, w0=72.66138613861399, w1=15.933940563745148\n",
      "SubGD iter. 200/499: loss=5.310772500182622, w0=72.65445544554468, w1=15.93181446395941\n",
      "SubGD iter. 201/499: loss=5.3107720459681325, w0=72.65445544554468, w1=15.935766724702164\n",
      "SubGD iter. 202/499: loss=5.310749731161019, w0=72.65445544554468, w1=15.939718985444918\n",
      "SubGD iter. 203/499: loss=5.310727416353908, w0=72.65445544554468, w1=15.943671246187671\n",
      "SubGD iter. 204/499: loss=5.31073343431896, w0=72.64752475247538, w1=15.941545146401934\n",
      "SubGD iter. 205/499: loss=5.310717105690678, w0=72.64752475247538, w1=15.945497407144687\n",
      "SubGD iter. 206/499: loss=5.3106947908835656, w0=72.64752475247538, w1=15.949449667887441\n",
      "SubGD iter. 207/499: loss=5.310682364311412, w0=72.64059405940607, w1=15.947323568101703\n",
      "SubGD iter. 208/499: loss=5.3106844802203375, w0=72.64059405940607, w1=15.951275828844457\n",
      "SubGD iter. 209/499: loss=5.310662165413224, w0=72.64059405940607, w1=15.95522808958721\n",
      "SubGD iter. 210/499: loss=5.310639850606112, w0=72.64059405940607, w1=15.959180350329964\n",
      "SubGD iter. 211/499: loss=5.310643298447748, w0=72.63366336633676, w1=15.957054250544227\n",
      "SubGD iter. 212/499: loss=5.310629539942882, w0=72.63366336633676, w1=15.96100651128698\n",
      "SubGD iter. 213/499: loss=5.3106072251357705, w0=72.63366336633676, w1=15.964958772029734\n",
      "SubGD iter. 214/499: loss=5.3105922284402, w0=72.62673267326745, w1=15.962832672243996\n",
      "SubGD iter. 215/499: loss=5.310633183099026, w0=72.63366336633676, w1=15.9673013720514\n",
      "SubGD iter. 216/499: loss=5.3105993435850625, w0=72.62673267326745, w1=15.965175272265663\n",
      "SubGD iter. 217/499: loss=5.31061822827579, w0=72.63366336633676, w1=15.969643972073067\n",
      "SubGD iter. 218/499: loss=5.310606458729926, w0=72.62673267326745, w1=15.96751787228733\n",
      "SubGD iter. 219/499: loss=5.310603273452553, w0=72.63366336633676, w1=15.971986572094734\n",
      "SubGD iter. 220/499: loss=5.31061357387479, w0=72.62673267326745, w1=15.969860472308996\n",
      "SubGD iter. 221/499: loss=5.310588318629315, w0=72.63366336633676, w1=15.9743291721164\n",
      "SubGD iter. 222/499: loss=5.310620689019653, w0=72.62673267326745, w1=15.972203072330663\n",
      "SubGD iter. 223/499: loss=5.3105749661498844, w0=72.62673267326745, w1=15.970593411609576\n",
      "SubGD iter. 224/499: loss=5.310583639649727, w0=72.63366336633676, w1=15.97506211141698\n",
      "SubGD iter. 225/499: loss=5.310622915165494, w0=72.62673267326745, w1=15.972936011631242\n",
      "SubGD iter. 226/499: loss=5.310576651555033, w0=72.62673267326745, w1=15.971326350910156\n",
      "SubGD iter. 227/499: loss=5.31057896067014, w0=72.63366336633676, w1=15.97579505071756\n",
      "SubGD iter. 228/499: loss=5.310625141311338, w0=72.62673267326745, w1=15.973668950931822\n",
      "SubGD iter. 229/499: loss=5.31057833696018, w0=72.62673267326745, w1=15.972059290210735\n",
      "SubGD iter. 230/499: loss=5.310574635520699, w0=72.62673267326745, w1=15.970449629489648\n",
      "SubGD iter. 231/499: loss=5.310584557534202, w0=72.63366336633676, w1=15.974918329297052\n",
      "SubGD iter. 232/499: loss=5.31062247845816, w0=72.62673267326745, w1=15.972792229511315\n",
      "SubGD iter. 233/499: loss=5.310576320925845, w0=72.62673267326745, w1=15.971182568790228\n",
      "SubGD iter. 234/499: loss=5.3105798785546146, w0=72.63366336633676, w1=15.975651268597632\n",
      "SubGD iter. 235/499: loss=5.310624704604003, w0=72.62673267326745, w1=15.973525168811895\n",
      "SubGD iter. 236/499: loss=5.310578006330994, w0=72.62673267326745, w1=15.971915508090808\n",
      "SubGD iter. 237/499: loss=5.310575199575027, w0=72.63366336633676, w1=15.976384207898212\n",
      "SubGD iter. 238/499: loss=5.310626930749845, w0=72.62673267326745, w1=15.974258108112474\n",
      "SubGD iter. 239/499: loss=5.310579691736141, w0=72.62673267326745, w1=15.972648447391387\n",
      "SubGD iter. 240/499: loss=5.310575990296659, w0=72.62673267326745, w1=15.9710387866703\n",
      "SubGD iter. 241/499: loss=5.310580796439088, w0=72.63366336633676, w1=15.975507486477705\n",
      "SubGD iter. 242/499: loss=5.310624267896666, w0=72.62673267326745, w1=15.973381386691967\n",
      "SubGD iter. 243/499: loss=5.310577675701806, w0=72.62673267326745, w1=15.97177172597088\n",
      "SubGD iter. 244/499: loss=5.3105761174595, w0=72.63366336633676, w1=15.976240425778284\n",
      "SubGD iter. 245/499: loss=5.31062649404251, w0=72.62673267326745, w1=15.974114325992547\n",
      "SubGD iter. 246/499: loss=5.310579361106954, w0=72.62673267326745, w1=15.97250466527146\n",
      "SubGD iter. 247/499: loss=5.310575659667473, w0=72.62673267326745, w1=15.970895004550373\n",
      "SubGD iter. 248/499: loss=5.310581714323562, w0=72.63366336633676, w1=15.975363704357777\n",
      "SubGD iter. 249/499: loss=5.310623831189333, w0=72.62673267326745, w1=15.97323760457204\n",
      "SubGD iter. 250/499: loss=5.310577345072619, w0=72.62673267326745, w1=15.971627943850953\n",
      "SubGD iter. 251/499: loss=5.310577035343974, w0=72.63366336633676, w1=15.976096643658357\n",
      "SubGD iter. 252/499: loss=5.310626057335176, w0=72.62673267326745, w1=15.97397054387262\n",
      "SubGD iter. 253/499: loss=5.310579030477768, w0=72.62673267326745, w1=15.972360883151532\n",
      "SubGD iter. 254/499: loss=5.3105753290382856, w0=72.62673267326745, w1=15.970751222430446\n",
      "SubGD iter. 255/499: loss=5.310582632208036, w0=72.63366336633676, w1=15.97521992223785\n",
      "SubGD iter. 256/499: loss=5.310623394481998, w0=72.62673267326745, w1=15.973093822452112\n",
      "SubGD iter. 257/499: loss=5.3105770144434326, w0=72.62673267326745, w1=15.971484161731025\n",
      "SubGD iter. 258/499: loss=5.3105779532284485, w0=72.63366336633676, w1=15.97595286153843\n",
      "SubGD iter. 259/499: loss=5.3106256206278415, w0=72.62673267326745, w1=15.973826761752692\n",
      "SubGD iter. 260/499: loss=5.310578699848579, w0=72.62673267326745, w1=15.972217101031605\n",
      "SubGD iter. 261/499: loss=5.310574998409099, w0=72.62673267326745, w1=15.970607440310518\n",
      "SubGD iter. 262/499: loss=5.3105835500925105, w0=72.63366336633676, w1=15.975076140117922\n",
      "SubGD iter. 263/499: loss=5.3106229577746635, w0=72.62673267326745, w1=15.972950040332185\n",
      "SubGD iter. 264/499: loss=5.310576683814246, w0=72.62673267326745, w1=15.971340379611098\n",
      "SubGD iter. 265/499: loss=5.310578871112921, w0=72.63366336633676, w1=15.975809079418502\n",
      "SubGD iter. 266/499: loss=5.310625183920507, w0=72.62673267326745, w1=15.973682979632764\n",
      "SubGD iter. 267/499: loss=5.310578369219392, w0=72.62673267326745, w1=15.972073318911677\n",
      "SubGD iter. 268/499: loss=5.310574667779911, w0=72.62673267326745, w1=15.97046365819059\n",
      "SubGD iter. 269/499: loss=5.310584467976983, w0=72.63366336633676, w1=15.974932357997995\n",
      "SubGD iter. 270/499: loss=5.310622521067329, w0=72.62673267326745, w1=15.972806258212257\n",
      "SubGD iter. 271/499: loss=5.310576353185058, w0=72.62673267326745, w1=15.97119659749117\n",
      "SubGD iter. 272/499: loss=5.310579788997397, w0=72.63366336633676, w1=15.975665297298574\n",
      "SubGD iter. 273/499: loss=5.310624747213173, w0=72.62673267326745, w1=15.973539197512837\n",
      "SubGD iter. 274/499: loss=5.310578038590206, w0=72.62673267326745, w1=15.97192953679175\n",
      "SubGD iter. 275/499: loss=5.310575110017809, w0=72.63366336633676, w1=15.976398236599154\n",
      "SubGD iter. 276/499: loss=5.310626973359014, w0=72.62673267326745, w1=15.974272136813417\n",
      "SubGD iter. 277/499: loss=5.310579723995353, w0=72.62673267326745, w1=15.97266247609233\n",
      "SubGD iter. 278/499: loss=5.310576022555871, w0=72.62673267326745, w1=15.971052815371243\n",
      "SubGD iter. 279/499: loss=5.310580706881869, w0=72.63366336633676, w1=15.975521515178647\n",
      "SubGD iter. 280/499: loss=5.310624310505837, w0=72.62673267326745, w1=15.97339541539291\n",
      "SubGD iter. 281/499: loss=5.310577707961018, w0=72.62673267326745, w1=15.971785754671822\n",
      "SubGD iter. 282/499: loss=5.310576027902282, w0=72.63366336633676, w1=15.976254454479227\n",
      "SubGD iter. 283/499: loss=5.31062653665168, w0=72.62673267326745, w1=15.97412835469349\n",
      "SubGD iter. 284/499: loss=5.310579393366166, w0=72.62673267326745, w1=15.972518693972402\n",
      "SubGD iter. 285/499: loss=5.310575691926685, w0=72.62673267326745, w1=15.970909033251315\n",
      "SubGD iter. 286/499: loss=5.310581624766343, w0=72.63366336633676, w1=15.97537773305872\n",
      "SubGD iter. 287/499: loss=5.310623873798502, w0=72.62673267326745, w1=15.973251633272982\n",
      "SubGD iter. 288/499: loss=5.310577377331833, w0=72.62673267326745, w1=15.971641972551895\n",
      "SubGD iter. 289/499: loss=5.310576945786757, w0=72.63366336633676, w1=15.9761106723593\n",
      "SubGD iter. 290/499: loss=5.310626099944345, w0=72.62673267326745, w1=15.973984572573562\n",
      "SubGD iter. 291/499: loss=5.310579062736979, w0=72.62673267326745, w1=15.972374911852475\n",
      "SubGD iter. 292/499: loss=5.310575361297499, w0=72.62673267326745, w1=15.970765251131388\n",
      "SubGD iter. 293/499: loss=5.310582542650818, w0=72.63366336633676, w1=15.975233950938792\n",
      "SubGD iter. 294/499: loss=5.310623437091167, w0=72.62673267326745, w1=15.973107851153054\n",
      "SubGD iter. 295/499: loss=5.310577046702646, w0=72.62673267326745, w1=15.971498190431968\n",
      "SubGD iter. 296/499: loss=5.310577863671229, w0=72.63366336633676, w1=15.975966890239372\n",
      "SubGD iter. 297/499: loss=5.310625663237011, w0=72.62673267326745, w1=15.973840790453634\n",
      "SubGD iter. 298/499: loss=5.310578732107793, w0=72.62673267326745, w1=15.972231129732547\n",
      "SubGD iter. 299/499: loss=5.310575030668311, w0=72.62673267326745, w1=15.97062146901146\n",
      "SubGD iter. 300/499: loss=5.310583460535291, w0=72.63366336633676, w1=15.975090168818864\n",
      "SubGD iter. 301/499: loss=5.310623000383833, w0=72.62673267326745, w1=15.972964069033127\n",
      "SubGD iter. 302/499: loss=5.3105767160734585, w0=72.62673267326745, w1=15.97135440831204\n",
      "SubGD iter. 303/499: loss=5.310578781555704, w0=72.63366336633676, w1=15.975823108119444\n",
      "SubGD iter. 304/499: loss=5.310625226529674, w0=72.62673267326745, w1=15.973697008333707\n",
      "SubGD iter. 305/499: loss=5.3105784014786055, w0=72.62673267326745, w1=15.97208734761262\n",
      "SubGD iter. 306/499: loss=5.3105747000391235, w0=72.62673267326745, w1=15.970477686891533\n",
      "SubGD iter. 307/499: loss=5.3105843784197635, w0=72.63366336633676, w1=15.974946386698937\n",
      "SubGD iter. 308/499: loss=5.310622563676499, w0=72.62673267326745, w1=15.9728202869132\n",
      "SubGD iter. 309/499: loss=5.310576385444271, w0=72.62673267326745, w1=15.971210626192113\n",
      "SubGD iter. 310/499: loss=5.310579699440177, w0=72.63366336633676, w1=15.975679325999517\n",
      "SubGD iter. 311/499: loss=5.310624789822341, w0=72.62673267326745, w1=15.97355322621378\n",
      "SubGD iter. 312/499: loss=5.3105780708494175, w0=72.62673267326745, w1=15.971943565492692\n",
      "SubGD iter. 313/499: loss=5.310575020460588, w0=72.63366336633676, w1=15.976412265300096\n",
      "SubGD iter. 314/499: loss=5.310627015968183, w0=72.62673267326745, w1=15.974286165514359\n",
      "SubGD iter. 315/499: loss=5.310579756254565, w0=72.62673267326745, w1=15.972676504793272\n",
      "SubGD iter. 316/499: loss=5.310576054815085, w0=72.62673267326745, w1=15.971066844072185\n",
      "SubGD iter. 317/499: loss=5.310580617324651, w0=72.63366336633676, w1=15.97553554387959\n",
      "SubGD iter. 318/499: loss=5.3106243531150055, w0=72.62673267326745, w1=15.973409444093852\n",
      "SubGD iter. 319/499: loss=5.310577740220231, w0=72.62673267326745, w1=15.971799783372765\n",
      "SubGD iter. 320/499: loss=5.310575938345063, w0=72.63366336633676, w1=15.976268483180169\n",
      "SubGD iter. 321/499: loss=5.310626579260849, w0=72.62673267326745, w1=15.974142383394431\n",
      "SubGD iter. 322/499: loss=5.310579425625379, w0=72.62673267326745, w1=15.972532722673344\n",
      "SubGD iter. 323/499: loss=5.310575724185898, w0=72.62673267326745, w1=15.970923061952258\n",
      "SubGD iter. 324/499: loss=5.310581535209124, w0=72.63366336633676, w1=15.975391761759662\n",
      "SubGD iter. 325/499: loss=5.310623916407671, w0=72.62673267326745, w1=15.973265661973924\n",
      "SubGD iter. 326/499: loss=5.310577409591045, w0=72.62673267326745, w1=15.971656001252837\n",
      "SubGD iter. 327/499: loss=5.310576856229537, w0=72.63366336633676, w1=15.976124701060241\n",
      "SubGD iter. 328/499: loss=5.310626142553515, w0=72.62673267326745, w1=15.973998601274504\n",
      "SubGD iter. 329/499: loss=5.310579094996193, w0=72.62673267326745, w1=15.972388940553417\n",
      "SubGD iter. 330/499: loss=5.310575393556711, w0=72.62673267326745, w1=15.97077927983233\n",
      "SubGD iter. 331/499: loss=5.310582453093599, w0=72.63366336633676, w1=15.975247979639734\n",
      "SubGD iter. 332/499: loss=5.310623479700335, w0=72.62673267326745, w1=15.973121879853997\n",
      "SubGD iter. 333/499: loss=5.310577078961858, w0=72.62673267326745, w1=15.97151221913291\n",
      "SubGD iter. 334/499: loss=5.3105777741140106, w0=72.63366336633676, w1=15.975980918940314\n",
      "SubGD iter. 335/499: loss=5.310625705846178, w0=72.62673267326745, w1=15.973854819154576\n",
      "SubGD iter. 336/499: loss=5.310578764367006, w0=72.62673267326745, w1=15.97224515843349\n",
      "SubGD iter. 337/499: loss=5.310575062927523, w0=72.62673267326745, w1=15.970635497712403\n",
      "SubGD iter. 338/499: loss=5.3105833709780725, w0=72.63366336633676, w1=15.975104197519807\n",
      "SubGD iter. 339/499: loss=5.310623042993001, w0=72.62673267326745, w1=15.97297809773407\n",
      "SubGD iter. 340/499: loss=5.31057674833267, w0=72.62673267326745, w1=15.971368437012982\n",
      "SubGD iter. 341/499: loss=5.310578691998485, w0=72.63366336633676, w1=15.975837136820386\n",
      "SubGD iter. 342/499: loss=5.310625269138844, w0=72.62673267326745, w1=15.973711037034649\n",
      "SubGD iter. 343/499: loss=5.310578433737818, w0=72.62673267326745, w1=15.972101376313562\n",
      "SubGD iter. 344/499: loss=5.310574732298337, w0=72.62673267326745, w1=15.970491715592475\n",
      "SubGD iter. 345/499: loss=5.310584288862548, w0=72.63366336633676, w1=15.97496041539988\n",
      "SubGD iter. 346/499: loss=5.310622606285666, w0=72.62673267326745, w1=15.972834315614142\n",
      "SubGD iter. 347/499: loss=5.3105764177034835, w0=72.62673267326745, w1=15.971224654893055\n",
      "SubGD iter. 348/499: loss=5.310579609882959, w0=72.63366336633676, w1=15.975693354700459\n",
      "SubGD iter. 349/499: loss=5.310624832431509, w0=72.62673267326745, w1=15.973567254914721\n",
      "SubGD iter. 350/499: loss=5.310578103108631, w0=72.62673267326745, w1=15.971957594193634\n",
      "SubGD iter. 351/499: loss=5.310574930903369, w0=72.63366336633676, w1=15.976426294001039\n",
      "SubGD iter. 352/499: loss=5.310627058577351, w0=72.62673267326745, w1=15.974300194215301\n",
      "SubGD iter. 353/499: loss=5.310579788513779, w0=72.62673267326745, w1=15.972690533494214\n",
      "SubGD iter. 354/499: loss=5.310576087074297, w0=72.62673267326745, w1=15.971080872773127\n",
      "SubGD iter. 355/499: loss=5.310580527767432, w0=72.63366336633676, w1=15.975549572580531\n",
      "SubGD iter. 356/499: loss=5.310624395724174, w0=72.62673267326745, w1=15.973423472794794\n",
      "SubGD iter. 357/499: loss=5.310577772479444, w0=72.62673267326745, w1=15.971813812073707\n",
      "SubGD iter. 358/499: loss=5.3105758487878445, w0=72.63366336633676, w1=15.976282511881111\n",
      "SubGD iter. 359/499: loss=5.310626621870017, w0=72.62673267326745, w1=15.974156412095374\n",
      "SubGD iter. 360/499: loss=5.310579457884592, w0=72.62673267326745, w1=15.972546751374287\n",
      "SubGD iter. 361/499: loss=5.310575756445111, w0=72.62673267326745, w1=15.9709370906532\n",
      "SubGD iter. 362/499: loss=5.310581445651906, w0=72.63366336633676, w1=15.975405790460604\n",
      "SubGD iter. 363/499: loss=5.310623959016838, w0=72.62673267326745, w1=15.973279690674866\n",
      "SubGD iter. 364/499: loss=5.310577441850257, w0=72.62673267326745, w1=15.97167002995378\n",
      "SubGD iter. 365/499: loss=5.310576766672318, w0=72.63366336633676, w1=15.976138729761184\n",
      "SubGD iter. 366/499: loss=5.310626185162682, w0=72.62673267326745, w1=15.974012629975446\n",
      "SubGD iter. 367/499: loss=5.310579127255404, w0=72.62673267326745, w1=15.97240296925436\n",
      "SubGD iter. 368/499: loss=5.310575425815922, w0=72.62673267326745, w1=15.970793308533272\n",
      "SubGD iter. 369/499: loss=5.310582363536379, w0=72.63366336633676, w1=15.975262008340676\n",
      "SubGD iter. 370/499: loss=5.310623522309504, w0=72.62673267326745, w1=15.973135908554939\n",
      "SubGD iter. 371/499: loss=5.31057711122107, w0=72.62673267326745, w1=15.971526247833852\n",
      "SubGD iter. 372/499: loss=5.310577684556793, w0=72.63366336633676, w1=15.975994947641256\n",
      "SubGD iter. 373/499: loss=5.310625748455347, w0=72.62673267326745, w1=15.973868847855519\n",
      "SubGD iter. 374/499: loss=5.310578796626218, w0=72.62673267326745, w1=15.972259187134432\n",
      "SubGD iter. 375/499: loss=5.310575095186736, w0=72.62673267326745, w1=15.970649526413345\n",
      "SubGD iter. 376/499: loss=5.310583281420853, w0=72.63366336633676, w1=15.975118226220749\n",
      "SubGD iter. 377/499: loss=5.3106230856021694, w0=72.62673267326745, w1=15.972992126435011\n",
      "SubGD iter. 378/499: loss=5.310576780591883, w0=72.62673267326745, w1=15.971382465713925\n",
      "SubGD iter. 379/499: loss=5.310578602441265, w0=72.63366336633676, w1=15.975851165521329\n",
      "SubGD iter. 380/499: loss=5.310625311748013, w0=72.62673267326745, w1=15.973725065735591\n",
      "SubGD iter. 381/499: loss=5.310578465997032, w0=72.62673267326745, w1=15.972115405014504\n",
      "SubGD iter. 382/499: loss=5.310574764557549, w0=72.62673267326745, w1=15.970505744293417\n",
      "SubGD iter. 383/499: loss=5.310584199305326, w0=72.63366336633676, w1=15.974974444100821\n",
      "SubGD iter. 384/499: loss=5.310622648894835, w0=72.62673267326745, w1=15.972848344315084\n",
      "SubGD iter. 385/499: loss=5.310576449962697, w0=72.62673267326745, w1=15.971238683593997\n",
      "SubGD iter. 386/499: loss=5.310579520325739, w0=72.63366336633676, w1=15.975707383401401\n",
      "SubGD iter. 387/499: loss=5.310624875040678, w0=72.62673267326745, w1=15.973581283615664\n",
      "SubGD iter. 388/499: loss=5.3105781353678445, w0=72.62673267326745, w1=15.971971622894577\n",
      "SubGD iter. 389/499: loss=5.310574841346151, w0=72.63366336633676, w1=15.976440322701981\n",
      "SubGD iter. 390/499: loss=5.31062710118652, w0=72.62673267326745, w1=15.974314222916243\n",
      "SubGD iter. 391/499: loss=5.3105798207729915, w0=72.62673267326745, w1=15.972704562195156\n",
      "SubGD iter. 392/499: loss=5.3105761193335095, w0=72.62673267326745, w1=15.97109490147407\n",
      "SubGD iter. 393/499: loss=5.310580438210213, w0=72.63366336633676, w1=15.975563601281474\n",
      "SubGD iter. 394/499: loss=5.310624438333342, w0=72.62673267326745, w1=15.973437501495736\n",
      "SubGD iter. 395/499: loss=5.3105778047386565, w0=72.62673267326745, w1=15.97182784077465\n",
      "SubGD iter. 396/499: loss=5.310575759230625, w0=72.63366336633676, w1=15.976296540582053\n",
      "SubGD iter. 397/499: loss=5.3106266644791855, w0=72.62673267326745, w1=15.974170440796316\n",
      "SubGD iter. 398/499: loss=5.310579490143805, w0=72.62673267326745, w1=15.972560780075229\n",
      "SubGD iter. 399/499: loss=5.310575788704322, w0=72.62673267326745, w1=15.970951119354142\n",
      "SubGD iter. 400/499: loss=5.310581356094687, w0=72.63366336633676, w1=15.975419819161546\n",
      "SubGD iter. 401/499: loss=5.310624001626008, w0=72.62673267326745, w1=15.973293719375809\n",
      "SubGD iter. 402/499: loss=5.31057747410947, w0=72.62673267326745, w1=15.971684058654722\n",
      "SubGD iter. 403/499: loss=5.310576677115099, w0=72.63366336633676, w1=15.976152758462126\n",
      "SubGD iter. 404/499: loss=5.310626227771851, w0=72.62673267326745, w1=15.974026658676388\n",
      "SubGD iter. 405/499: loss=5.310579159514617, w0=72.62673267326745, w1=15.972416997955301\n",
      "SubGD iter. 406/499: loss=5.310575458075135, w0=72.62673267326745, w1=15.970807337234215\n",
      "SubGD iter. 407/499: loss=5.31058227397916, w0=72.63366336633676, w1=15.975276037041619\n",
      "SubGD iter. 408/499: loss=5.310623564918673, w0=72.62673267326745, w1=15.973149937255881\n",
      "SubGD iter. 409/499: loss=5.310577143480284, w0=72.62673267326745, w1=15.971540276534794\n",
      "SubGD iter. 410/499: loss=5.3105775949995735, w0=72.63366336633676, w1=15.976008976342198\n",
      "SubGD iter. 411/499: loss=5.310625791064516, w0=72.62673267326745, w1=15.97388287655646\n",
      "SubGD iter. 412/499: loss=5.310578828885431, w0=72.62673267326745, w1=15.972273215835374\n",
      "SubGD iter. 413/499: loss=5.310575127445949, w0=72.62673267326745, w1=15.970663555114287\n",
      "SubGD iter. 414/499: loss=5.310583191863635, w0=72.63366336633676, w1=15.975132254921691\n",
      "SubGD iter. 415/499: loss=5.310623128211339, w0=72.62673267326745, w1=15.973006155135954\n",
      "SubGD iter. 416/499: loss=5.310576812851097, w0=72.62673267326745, w1=15.971396494414867\n",
      "SubGD iter. 417/499: loss=5.310578512884047, w0=72.63366336633676, w1=15.975865194222271\n",
      "SubGD iter. 418/499: loss=5.31062535435718, w0=72.62673267326745, w1=15.973739094436533\n",
      "SubGD iter. 419/499: loss=5.310578498256244, w0=72.62673267326745, w1=15.972129433715446\n",
      "SubGD iter. 420/499: loss=5.310574796816762, w0=72.62673267326745, w1=15.97051977299436\n",
      "SubGD iter. 421/499: loss=5.310584109748107, w0=72.63366336633676, w1=15.974988472801764\n",
      "SubGD iter. 422/499: loss=5.310622691504004, w0=72.62673267326745, w1=15.972862373016026\n",
      "SubGD iter. 423/499: loss=5.310576482221909, w0=72.62673267326745, w1=15.97125271229494\n",
      "SubGD iter. 424/499: loss=5.310579430768521, w0=72.63366336633676, w1=15.975721412102343\n",
      "SubGD iter. 425/499: loss=5.310624917649846, w0=72.62673267326745, w1=15.973595312316606\n",
      "SubGD iter. 426/499: loss=5.310578167627056, w0=72.62673267326745, w1=15.971985651595519\n",
      "SubGD iter. 427/499: loss=5.310574751788933, w0=72.63366336633676, w1=15.976454351402923\n",
      "SubGD iter. 428/499: loss=5.310627143795689, w0=72.62673267326745, w1=15.974328251617186\n",
      "SubGD iter. 429/499: loss=5.310579853032204, w0=72.62673267326745, w1=15.972718590896099\n",
      "SubGD iter. 430/499: loss=5.310576151592722, w0=72.62673267326745, w1=15.971108930175012\n",
      "SubGD iter. 431/499: loss=5.310580348652993, w0=72.63366336633676, w1=15.975577629982416\n",
      "SubGD iter. 432/499: loss=5.310624480942511, w0=72.62673267326745, w1=15.973451530196678\n",
      "SubGD iter. 433/499: loss=5.310577836997871, w0=72.62673267326745, w1=15.971841869475591\n",
      "SubGD iter. 434/499: loss=5.310575669673406, w0=72.63366336633676, w1=15.976310569282996\n",
      "SubGD iter. 435/499: loss=5.310626707088354, w0=72.62673267326745, w1=15.974184469497258\n",
      "SubGD iter. 436/499: loss=5.3105795224030174, w0=72.62673267326745, w1=15.972574808776171\n",
      "SubGD iter. 437/499: loss=5.310575820963535, w0=72.62673267326745, w1=15.970965148055084\n",
      "SubGD iter. 438/499: loss=5.310581266537468, w0=72.63366336633676, w1=15.975433847862488\n",
      "SubGD iter. 439/499: loss=5.310624044235177, w0=72.62673267326745, w1=15.973307748076751\n",
      "SubGD iter. 440/499: loss=5.310577506368683, w0=72.62673267326745, w1=15.971698087355664\n",
      "SubGD iter. 441/499: loss=5.310576587557881, w0=72.63366336633676, w1=15.976166787163068\n",
      "SubGD iter. 442/499: loss=5.31062627038102, w0=72.62673267326745, w1=15.97404068737733\n",
      "SubGD iter. 443/499: loss=5.310579191773829, w0=72.62673267326745, w1=15.972431026656244\n",
      "SubGD iter. 444/499: loss=5.310575490334348, w0=72.62673267326745, w1=15.970821365935157\n",
      "SubGD iter. 445/499: loss=5.310582184421942, w0=72.63366336633676, w1=15.975290065742561\n",
      "SubGD iter. 446/499: loss=5.310623607527843, w0=72.62673267326745, w1=15.973163965956823\n",
      "SubGD iter. 447/499: loss=5.310577175739496, w0=72.62673267326745, w1=15.971554305235736\n",
      "SubGD iter. 448/499: loss=5.310577505442354, w0=72.63366336633676, w1=15.97602300504314\n",
      "SubGD iter. 449/499: loss=5.310625833673684, w0=72.62673267326745, w1=15.973896905257403\n",
      "SubGD iter. 450/499: loss=5.310578861144643, w0=72.62673267326745, w1=15.972287244536316\n",
      "SubGD iter. 451/499: loss=5.310575159705161, w0=72.62673267326745, w1=15.97067758381523\n",
      "SubGD iter. 452/499: loss=5.310583102306416, w0=72.63366336633676, w1=15.975146283622633\n",
      "SubGD iter. 453/499: loss=5.310623170820507, w0=72.62673267326745, w1=15.973020183836896\n",
      "SubGD iter. 454/499: loss=5.310576845110308, w0=72.62673267326745, w1=15.971410523115809\n",
      "SubGD iter. 455/499: loss=5.310578423326828, w0=72.63366336633676, w1=15.975879222923213\n",
      "SubGD iter. 456/499: loss=5.3106253969663495, w0=72.62673267326745, w1=15.973753123137476\n",
      "SubGD iter. 457/499: loss=5.310578530515456, w0=72.62673267326745, w1=15.972143462416389\n",
      "SubGD iter. 458/499: loss=5.310574829075974, w0=72.62673267326745, w1=15.970533801695302\n",
      "SubGD iter. 459/499: loss=5.3105840201908885, w0=72.63366336633676, w1=15.975002501502706\n",
      "SubGD iter. 460/499: loss=5.310622734113172, w0=72.62673267326745, w1=15.972876401716968\n",
      "SubGD iter. 461/499: loss=5.310576514481122, w0=72.62673267326745, w1=15.971266740995882\n",
      "SubGD iter. 462/499: loss=5.3105793412113025, w0=72.63366336633676, w1=15.975735440803286\n",
      "SubGD iter. 463/499: loss=5.310624960259015, w0=72.62673267326745, w1=15.973609341017548\n",
      "SubGD iter. 464/499: loss=5.310578199886271, w0=72.62673267326745, w1=15.971999680296461\n",
      "SubGD iter. 465/499: loss=5.310574662231715, w0=72.63366336633676, w1=15.976468380103865\n",
      "SubGD iter. 466/499: loss=5.310627186404856, w0=72.62673267326745, w1=15.974342280318128\n",
      "SubGD iter. 467/499: loss=5.310579885291417, w0=72.62673267326745, w1=15.972732619597041\n",
      "SubGD iter. 468/499: loss=5.310576183851936, w0=72.62673267326745, w1=15.971122958875954\n",
      "SubGD iter. 469/499: loss=5.310580259095775, w0=72.63366336633676, w1=15.975591658683358\n",
      "SubGD iter. 470/499: loss=5.31062452355168, w0=72.62673267326745, w1=15.97346555889762\n",
      "SubGD iter. 471/499: loss=5.310577869257083, w0=72.62673267326745, w1=15.971855898176534\n",
      "SubGD iter. 472/499: loss=5.310575580116187, w0=72.63366336633676, w1=15.976324597983938\n",
      "SubGD iter. 473/499: loss=5.310626749697522, w0=72.62673267326745, w1=15.9741984981982\n",
      "SubGD iter. 474/499: loss=5.3105795546622305, w0=72.62673267326745, w1=15.972588837477113\n",
      "SubGD iter. 475/499: loss=5.310575853222749, w0=72.62673267326745, w1=15.970979176756027\n",
      "SubGD iter. 476/499: loss=5.310581176980248, w0=72.63366336633676, w1=15.97544787656343\n",
      "SubGD iter. 477/499: loss=5.310624086844346, w0=72.62673267326745, w1=15.973321776777693\n",
      "SubGD iter. 478/499: loss=5.3105775386278955, w0=72.62673267326745, w1=15.971712116056606\n",
      "SubGD iter. 479/499: loss=5.310576498000661, w0=72.63366336633676, w1=15.97618081586401\n",
      "SubGD iter. 480/499: loss=5.310626312990188, w0=72.62673267326745, w1=15.974054716078273\n",
      "SubGD iter. 481/499: loss=5.3105792240330425, w0=72.62673267326745, w1=15.972445055357186\n",
      "SubGD iter. 482/499: loss=5.310575522593562, w0=72.62673267326745, w1=15.970835394636099\n",
      "SubGD iter. 483/499: loss=5.310582094864723, w0=72.63366336633676, w1=15.975304094443503\n",
      "SubGD iter. 484/499: loss=5.3106236501370105, w0=72.62673267326745, w1=15.973177994657766\n",
      "SubGD iter. 485/499: loss=5.310577207998708, w0=72.62673267326745, w1=15.971568333936679\n",
      "SubGD iter. 486/499: loss=5.3105774158851355, w0=72.63366336633676, w1=15.976037033744083\n",
      "SubGD iter. 487/499: loss=5.310625876282853, w0=72.62673267326745, w1=15.973910933958345\n",
      "SubGD iter. 488/499: loss=5.310578893403856, w0=72.62673267326745, w1=15.972301273237258\n",
      "SubGD iter. 489/499: loss=5.310575191964373, w0=72.62673267326745, w1=15.970691612516172\n",
      "SubGD iter. 490/499: loss=5.310583012749197, w0=72.63366336633676, w1=15.975160312323576\n",
      "SubGD iter. 491/499: loss=5.310623213429675, w0=72.62673267326745, w1=15.973034212537838\n",
      "SubGD iter. 492/499: loss=5.310576877369523, w0=72.62673267326745, w1=15.971424551816751\n",
      "SubGD iter. 493/499: loss=5.310578333769609, w0=72.63366336633676, w1=15.975893251624155\n",
      "SubGD iter. 494/499: loss=5.310625439575519, w0=72.62673267326745, w1=15.973767151838418\n",
      "SubGD iter. 495/499: loss=5.310578562774669, w0=72.62673267326745, w1=15.972157491117331\n",
      "SubGD iter. 496/499: loss=5.310574861335188, w0=72.62673267326745, w1=15.970547830396244\n",
      "SubGD iter. 497/499: loss=5.310583930633669, w0=72.63366336633676, w1=15.975016530203648\n",
      "SubGD iter. 498/499: loss=5.310622776722341, w0=72.62673267326745, w1=15.97289043041791\n",
      "SubGD iter. 499/499: loss=5.310576546740334, w0=72.62673267326745, w1=15.971280769696824\n",
      "SubGD: execution time=0.015 seconds\n"
     ]
    }
   ],
   "source": [
    "# Define the parameters of the algorithm.\n",
    "max_iters = 500\n",
    "gamma = 0.7\n",
    "batch_size = 1\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start SubSGD.\n",
    "start_time = datetime.datetime.now()\n",
    "subgd_losses, subgd_ws = subgradient_descent(y, tx, w_initial, max_iters, gamma)\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"SubGD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T08:06:52.681157202Z",
     "start_time": "2023-10-05T08:06:52.338496954Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "interactive(children=(IntSlider(value=1, description='n_iter', max=501, min=1), Output()), _dom_classes=('widg…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dd088b34faab4e09a81bcc048e9b376c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<function __main__.plot_figure(n_iter)>"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        subgd_losses,\n",
    "        subgd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(subgd_ws)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Subgradient Descent\n",
    "\n",
    "**NB** for the computation of the subgradient you can reuse the `compute_subgradient` method that you implemented above, just making sure that you pass in a minibatch as opposed to the full data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T08:18:20.125999874Z",
     "start_time": "2023-10-05T08:18:20.082362821Z"
    }
   },
   "outputs": [],
   "source": [
    "def stochastic_subgradient_descent(y, tx, initial_w, batch_size, max_iters, gamma):\n",
    "    \"\"\"The Stochastic SubGradient Descent algorithm (SubSGD).\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        initial_w: numpy array of shape=(2, ). The initial guess (or the initialization) for the model parameters\n",
    "        batch_size: a scalar denoting the number of data points in a mini-batch used for computing the stochastic subgradient\n",
    "        max_iters: a scalar denoting the total number of iterations of SubSGD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "\n",
    "    Returns:\n",
    "        losses: a list of length max_iters containing the loss value (scalar) for each iteration of SubSGD\n",
    "        ws: a list of length max_iters containing the model parameters as numpy arrays of shape (2, ), for each iteration of SubSGD\n",
    "    \"\"\"\n",
    "\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "\n",
    "    for n_iter in range(max_iters):\n",
    "        # ***************************************************\n",
    "        # INSERT YOUR CODE HERE\n",
    "        loss = compute_loss_MAE(y, tx, w)\n",
    "        gradient = np.zeros(tx.shape[1]) # init the gradient for the upcomming batch\n",
    "        for y_batch, tx_batch in batch_iter(y,tx, batch_size):\n",
    "            gradient += compute_subgradient_mae(y_batch, tx_batch, w)\n",
    "\n",
    "        w = w - gamma * gradient/batch_size    \n",
    "        # store w and loss\n",
    "        ws.append(w)\n",
    "        losses.append(loss)\n",
    "        # ***************************************************\n",
    "\n",
    "        print(\n",
    "            \"SubSGD iter. {bi}/{ti}: loss={l}, w0={w0}, w1={w1}\".format(\n",
    "                bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]\n",
    "            )\n",
    "        )\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T08:25:35.884109144Z",
     "start_time": "2023-10-05T08:25:35.840860105Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SubSGD iter. 0/499: loss=74.06780585492638, w0=0.7, w1=-0.9016322644127577\n",
      "SubSGD iter. 1/499: loss=73.36780585492637, w0=1.4, w1=-1.1868067589620521\n",
      "SubSGD iter. 2/499: loss=72.66780585492639, w0=2.0999999999999996, w1=-0.6911804984932197\n",
      "SubSGD iter. 3/499: loss=71.96780585492638, w0=2.8, w1=-0.9626606804757989\n",
      "SubSGD iter. 4/499: loss=71.26780585492638, w0=3.5, w1=-1.3285814112061962\n",
      "SubSGD iter. 5/499: loss=70.56780585492639, w0=4.2, w1=-1.664944368882273\n",
      "SubSGD iter. 6/499: loss=69.86780585492637, w0=4.9, w1=-2.1919014046511207\n",
      "SubSGD iter. 7/499: loss=69.16780585492639, w0=5.6000000000000005, w1=-3.0935336690638784\n",
      "SubSGD iter. 8/499: loss=68.46780585492638, w0=6.300000000000001, w1=-3.2983671889391015\n",
      "SubSGD iter. 9/499: loss=67.76780585492638, w0=7.000000000000001, w1=-3.6642879196694986\n",
      "SubSGD iter. 10/499: loss=67.06780585492639, w0=7.700000000000001, w1=-2.7591128164824354\n",
      "SubSGD iter. 11/499: loss=66.36780585492637, w0=8.4, w1=-1.6339828563521284\n",
      "SubSGD iter. 12/499: loss=65.66780585492639, w0=9.1, w1=-2.330567607592891\n",
      "SubSGD iter. 13/499: loss=64.96780585492638, w0=9.799999999999999, w1=-1.4972300250333141\n",
      "SubSGD iter. 14/499: loss=64.26780585492638, w0=10.499999999999998, w1=-1.232444915842546\n",
      "SubSGD iter. 15/499: loss=63.567805854926384, w0=11.199999999999998, w1=-0.3991073332829691\n",
      "SubSGD iter. 16/499: loss=62.867805854926374, w0=11.899999999999997, w1=0.21388516390059065\n",
      "SubSGD iter. 17/499: loss=62.167805854926385, w0=12.599999999999996, w1=0.20012996792510002\n",
      "SubSGD iter. 18/499: loss=61.46780585492638, w0=13.299999999999995, w1=0.8147909490554868\n",
      "SubSGD iter. 19/499: loss=60.76780585492637, w0=13.999999999999995, w1=1.1592591959259542\n",
      "SubSGD iter. 20/499: loss=60.067805854926384, w0=14.699999999999994, w1=1.7904245359208066\n",
      "SubSGD iter. 21/499: loss=59.36780585492639, w0=15.399999999999993, w1=2.433354234684602\n",
      "SubSGD iter. 22/499: loss=58.667805854926385, w0=16.099999999999994, w1=3.0256721959527804\n",
      "SubSGD iter. 23/499: loss=57.96780585492638, w0=16.799999999999994, w1=4.143982416564262\n",
      "SubSGD iter. 24/499: loss=57.26780585492638, w0=17.499999999999993, w1=4.2325099300533875\n",
      "SubSGD iter. 25/499: loss=56.567805854926384, w0=18.199999999999992, w1=4.656051183107403\n",
      "SubSGD iter. 26/499: loss=55.867805854926374, w0=18.89999999999999, w1=4.921534885331633\n",
      "SubSGD iter. 27/499: loss=55.16780585492638, w0=19.59999999999999, w1=4.489742307048213\n",
      "SubSGD iter. 28/499: loss=54.46780585492638, w0=20.29999999999999, w1=5.108875702992879\n",
      "SubSGD iter. 29/499: loss=53.767805854926394, w0=20.99999999999999, w1=4.772512745316803\n",
      "SubSGD iter. 30/499: loss=53.067805854926384, w0=21.69999999999999, w1=2.0022130484278136\n",
      "SubSGD iter. 31/499: loss=52.367805854926395, w0=22.399999999999988, w1=3.1273430085581206\n",
      "SubSGD iter. 32/499: loss=51.667805854926385, w0=23.099999999999987, w1=3.576002047342831\n",
      "SubSGD iter. 33/499: loss=50.96780585492639, w0=23.799999999999986, w1=3.56224685136734\n",
      "SubSGD iter. 34/499: loss=50.267805854926394, w0=24.499999999999986, w1=3.442355037879009\n",
      "SubSGD iter. 35/499: loss=49.567805854926384, w0=25.199999999999985, w1=3.418389198075918\n",
      "SubSGD iter. 36/499: loss=48.867805854926395, w0=25.899999999999984, w1=4.164374851663315\n",
      "SubSGD iter. 37/499: loss=48.167805854926385, w0=26.599999999999984, w1=3.9595413317880914\n",
      "SubSGD iter. 38/499: loss=47.4678058549264, w0=27.299999999999983, w1=4.161978221829091\n",
      "SubSGD iter. 39/499: loss=46.767805854926394, w0=27.999999999999982, w1=5.356717058933516\n",
      "SubSGD iter. 40/499: loss=46.06780585492639, w0=28.69999999999998, w1=4.538058689127888\n",
      "SubSGD iter. 41/499: loss=45.367805854926395, w0=29.39999999999998, w1=5.394280741632426\n",
      "SubSGD iter. 42/499: loss=44.667805854926385, w0=30.09999999999998, w1=4.586167000590493\n",
      "SubSGD iter. 43/499: loss=43.96780585492639, w0=30.79999999999998, w1=3.77805325954856\n",
      "SubSGD iter. 44/499: loss=43.267805854926394, w0=31.49999999999998, w1=4.3919676729261425\n",
      "SubSGD iter. 45/499: loss=42.567805854926405, w0=32.19999999999998, w1=4.7356802941095335\n",
      "SubSGD iter. 46/499: loss=41.867805854926395, w0=32.899999999999984, w1=5.231306554578366\n",
      "SubSGD iter. 47/499: loss=41.167805854926385, w0=33.59999999999999, w1=6.323931068904161\n",
      "SubSGD iter. 48/499: loss=40.46780585492638, w0=34.29999999999999, w1=6.790513194870735\n",
      "SubSGD iter. 49/499: loss=39.76780585492638, w0=34.99999999999999, w1=6.217503111856112\n",
      "SubSGD iter. 50/499: loss=39.06780585492638, w0=35.699999999999996, w1=5.315870847443354\n",
      "SubSGD iter. 51/499: loss=38.367805854926374, w0=36.4, w1=4.87618244235817\n",
      "SubSGD iter. 52/499: loss=37.66780585492638, w0=37.1, w1=5.429388358434283\n",
      "SubSGD iter. 53/499: loss=36.96780585492637, w0=37.800000000000004, w1=5.631825248475281\n",
      "SubSGD iter. 54/499: loss=36.267805854926365, w0=38.50000000000001, w1=6.15988106398593\n",
      "SubSGD iter. 55/499: loss=35.56780585492636, w0=39.20000000000001, w1=5.918901149319281\n",
      "SubSGD iter. 56/499: loss=34.86780585492637, w0=39.90000000000001, w1=5.240554153344738\n",
      "SubSGD iter. 57/499: loss=34.167805854926364, w0=40.600000000000016, w1=5.8328721146129165\n",
      "SubSGD iter. 58/499: loss=33.46780585492636, w0=41.30000000000002, w1=3.0625724177239273\n",
      "SubSGD iter. 59/499: loss=32.76780585492636, w0=42.00000000000002, w1=3.037274652335086\n",
      "SubSGD iter. 60/499: loss=32.067805854926355, w0=42.700000000000024, w1=3.0048456445677263\n",
      "SubSGD iter. 61/499: loss=31.36780585492635, w0=43.40000000000003, w1=2.787588640387976\n",
      "SubSGD iter. 62/499: loss=30.667805854926346, w0=44.10000000000003, w1=2.2520689575617707\n",
      "SubSGD iter. 63/499: loss=29.967805854926343, w0=44.80000000000003, w1=2.417875217129268\n",
      "SubSGD iter. 64/499: loss=29.26780585492634, w0=45.500000000000036, w1=1.8597515133802287\n",
      "SubSGD iter. 65/499: loss=28.567805854926338, w0=46.20000000000004, w1=3.0280823138976976\n",
      "SubSGD iter. 66/499: loss=27.867805854926335, w0=46.90000000000004, w1=2.2887495144537535\n",
      "SubSGD iter. 67/499: loss=27.167805854926332, w0=47.600000000000044, w1=1.8629633671630144\n",
      "SubSGD iter. 68/499: loss=26.467805854926336, w0=48.30000000000005, w1=2.0920850594497726\n",
      "SubSGD iter. 69/499: loss=25.767805854926333, w0=49.00000000000005, w1=1.2032532352832792\n",
      "SubSGD iter. 70/499: loss=25.07489988690716, w0=49.70000000000005, w1=1.5469658564666697\n",
      "SubSGD iter. 71/499: loss=24.377109963556112, w0=50.400000000000055, w1=1.6607861832809825\n",
      "SubSGD iter. 72/499: loss=23.69066060210616, w0=51.10000000000006, w1=0.9740915477748459\n",
      "SubSGD iter. 73/499: loss=23.065037023736313, w0=51.80000000000006, w1=2.1424223482923144\n",
      "SubSGD iter. 74/499: loss=22.31781707697547, w0=52.500000000000064, w1=3.2262977449836163\n",
      "SubSGD iter. 75/499: loss=21.588903419630263, w0=53.20000000000007, w1=3.263585056601486\n",
      "SubSGD iter. 76/499: loss=20.91407465858182, w0=53.90000000000007, w1=2.9068595382456492\n",
      "SubSGD iter. 77/499: loss=20.261200856724923, w0=54.60000000000007, w1=2.3030934682791355\n",
      "SubSGD iter. 78/499: loss=19.693918553825615, w0=55.300000000000075, w1=3.0982631933964826\n",
      "SubSGD iter. 79/499: loss=18.950692829412553, w0=56.00000000000008, w1=2.5401394896474434\n",
      "SubSGD iter. 80/499: loss=18.44091671261355, w0=55.300000000000075, w1=3.348253230689376\n",
      "SubSGD iter. 81/499: loss=18.919433104639037, w0=56.00000000000008, w1=3.228361417201045\n",
      "SubSGD iter. 82/499: loss=18.308726611102696, w0=55.300000000000075, w1=4.0644002744738605\n",
      "SubSGD iter. 83/499: loss=18.85496666610315, w0=56.00000000000008, w1=3.4416138676535684\n",
      "SubSGD iter. 84/499: loss=18.271418239005456, w0=56.70000000000008, w1=4.056274848783955\n",
      "SubSGD iter. 85/499: loss=17.558001335863505, w0=57.400000000000084, w1=4.7744381728151435\n",
      "SubSGD iter. 86/499: loss=16.832570277566283, w0=58.10000000000009, w1=4.220331098818563\n",
      "SubSGD iter. 87/499: loss=16.335648559643836, w0=58.80000000000009, w1=4.38613735838606\n",
      "SubSGD iter. 88/499: loss=15.75125102258712, w0=59.50000000000009, w1=4.392565239264407\n",
      "SubSGD iter. 89/499: loss=15.22740720187413, w0=60.200000000000095, w1=4.603729633830611\n",
      "SubSGD iter. 90/499: loss=14.672231683156934, w0=60.9000000000001, w1=5.218390614960997\n",
      "SubSGD iter. 91/499: loss=13.998048755922099, w0=61.6000000000001, w1=4.787379930212383\n",
      "SubSGD iter. 92/499: loss=13.713441763403488, w0=62.300000000000104, w1=5.237559676418677\n",
      "SubSGD iter. 93/499: loss=13.131092225225874, w0=61.6000000000001, w1=6.421561876812568\n",
      "SubSGD iter. 94/499: loss=13.148659187479634, w0=62.300000000000104, w1=6.765274497995959\n",
      "SubSGD iter. 95/499: loss=12.570221489114179, w0=63.00000000000011, w1=7.100502553299214\n",
      "SubSGD iter. 96/499: loss=12.01759179354221, w0=63.70000000000011, w1=6.443621585546251\n",
      "SubSGD iter. 97/499: loss=11.879614506008746, w0=64.4000000000001, w1=7.401756676448058\n",
      "SubSGD iter. 98/499: loss=11.108579731070371, w0=65.10000000000011, w1=7.929812491958707\n",
      "SubSGD iter. 99/499: loss=10.526794582955635, w0=65.80000000000011, w1=8.357329577176126\n",
      "SubSGD iter. 100/499: loss=10.00097750992393, w0=66.50000000000011, w1=7.7730170396302345\n",
      "SubSGD iter. 101/499: loss=9.974677374512842, w0=65.80000000000011, w1=8.05556485871646\n",
      "SubSGD iter. 102/499: loss=10.138686331413167, w0=66.50000000000011, w1=8.66855735590002\n",
      "SubSGD iter. 103/499: loss=9.547985527178266, w0=67.20000000000012, w1=8.710883912503512\n",
      "SubSGD iter. 104/499: loss=9.243702114541687, w0=67.90000000000012, w1=8.763044258033222\n",
      "SubSGD iter. 105/499: loss=8.951397029615784, w0=68.60000000000012, w1=9.01332537449528\n",
      "SubSGD iter. 106/499: loss=8.596884428649574, w0=67.90000000000012, w1=9.383593465024076\n",
      "SubSGD iter. 107/499: loss=8.649671794170054, w0=67.20000000000012, w1=9.926609926389174\n",
      "SubSGD iter. 108/499: loss=8.67602100133592, w0=67.90000000000012, w1=9.556341835860378\n",
      "SubSGD iter. 109/499: loss=8.568733269824053, w0=68.60000000000012, w1=10.751080672964804\n",
      "SubSGD iter. 110/499: loss=7.780252606656656, w0=67.90000000000012, w1=11.550911407027513\n",
      "SubSGD iter. 111/499: loss=7.7667615250296755, w0=68.60000000000012, w1=13.090973745414699\n",
      "SubSGD iter. 112/499: loss=6.997889534327171, w0=69.30000000000013, w1=13.722139085409552\n",
      "SubSGD iter. 113/499: loss=6.5202238643491475, w0=70.00000000000013, w1=13.689710077642191\n",
      "SubSGD iter. 114/499: loss=6.2368102026790115, w0=70.70000000000013, w1=12.889879343579482\n",
      "SubSGD iter. 115/499: loss=6.272851940264793, w0=71.40000000000013, w1=14.070684044279378\n",
      "SubSGD iter. 116/499: loss=5.706609888759956, w0=72.10000000000014, w1=14.097056694904198\n",
      "SubSGD iter. 117/499: loss=5.565902962490395, w0=72.80000000000014, w1=10.723913017314521\n",
      "SubSGD iter. 118/499: loss=6.823195220496666, w0=73.50000000000014, w1=12.089282469978132\n",
      "SubSGD iter. 119/499: loss=6.154126937599422, w0=72.80000000000014, w1=12.86010553604632\n",
      "SubSGD iter. 120/499: loss=5.860213861380681, w0=72.10000000000014, w1=13.349789069442908\n",
      "SubSGD iter. 121/499: loss=5.7800846261901135, w0=71.40000000000013, w1=13.593815894152058\n",
      "SubSGD iter. 122/499: loss=5.849354171658731, w0=72.10000000000014, w1=13.790160487669286\n",
      "SubSGD iter. 123/499: loss=5.6453165637491365, w0=71.40000000000013, w1=13.78373260679094\n",
      "SubSGD iter. 124/499: loss=5.790542575380464, w0=72.10000000000014, w1=14.578902331908287\n",
      "SubSGD iter. 125/499: loss=5.467869559530605, w0=71.40000000000013, w1=14.779651868957538\n",
      "SubSGD iter. 126/499: loss=5.532133778773355, w0=72.10000000000014, w1=16.01896816993554\n",
      "SubSGD iter. 127/499: loss=5.338084696807315, w0=72.80000000000014, w1=16.45889261281972\n",
      "SubSGD iter. 128/499: loss=5.325585578916297, w0=72.10000000000014, w1=17.347724436986216\n",
      "SubSGD iter. 129/499: loss=5.458258451015577, w0=72.80000000000014, w1=16.553355092495437\n",
      "SubSGD iter. 130/499: loss=5.335886308537291, w0=72.10000000000014, w1=17.06185621023527\n",
      "SubSGD iter. 131/499: loss=5.410833620592303, w0=72.80000000000014, w1=17.793820803742904\n",
      "SubSGD iter. 132/499: loss=5.534017965864255, w0=73.50000000000014, w1=18.439968037130125\n",
      "SubSGD iter. 133/499: loss=5.748421237922946, w0=74.20000000000014, w1=19.56509799726043\n",
      "SubSGD iter. 134/499: loss=6.2612038313992056, w0=73.50000000000014, w1=19.36266110721943\n",
      "SubSGD iter. 135/499: loss=6.049565890899443, w0=72.80000000000014, w1=19.101948885837565\n",
      "SubSGD iter. 136/499: loss=5.907954316470591, w0=73.50000000000014, w1=19.069519878070206\n",
      "SubSGD iter. 137/499: loss=5.941380019269801, w0=72.80000000000014, w1=19.414696965795205\n",
      "SubSGD iter. 138/499: loss=6.022437805135842, w0=72.10000000000014, w1=19.846489544078626\n",
      "SubSGD iter. 139/499: loss=6.219924949817132, w0=72.80000000000014, w1=19.0622568160393\n",
      "SubSGD iter. 140/499: loss=5.893999997212215, w0=73.50000000000014, w1=19.02756595669783\n",
      "SubSGD iter. 141/499: loss=5.927204434954234, w0=72.80000000000014, w1=19.58568966044687\n",
      "SubSGD iter. 142/499: loss=6.087670168327007, w0=73.50000000000014, w1=18.731843390021602\n",
      "SubSGD iter. 143/499: loss=5.831516921170553, w0=72.80000000000014, w1=18.675533774976298\n",
      "SubSGD iter. 144/499: loss=5.76773600281164, w0=72.10000000000014, w1=17.61761846814874\n",
      "SubSGD iter. 145/499: loss=5.510918603256378, w0=71.40000000000013, w1=16.422879631044317\n",
      "SubSGD iter. 146/499: loss=5.44249216279004, w0=72.10000000000014, w1=16.026903387822486\n",
      "SubSGD iter. 147/499: loss=5.338146328542394, w0=72.80000000000014, w1=15.242670659783162\n",
      "SubSGD iter. 148/499: loss=5.342469686221607, w0=73.50000000000014, w1=14.65835812223727\n",
      "SubSGD iter. 149/499: loss=5.417834457436895, w0=74.20000000000014, w1=14.085348039222648\n",
      "SubSGD iter. 150/499: loss=5.584301262665584, w0=73.50000000000014, w1=14.103927498121525\n",
      "SubSGD iter. 151/499: loss=5.489586677822963, w0=74.20000000000014, w1=14.74685719688532\n",
      "SubSGD iter. 152/499: loss=5.503070864298278, w0=73.50000000000014, w1=15.09203428461032\n",
      "SubSGD iter. 153/499: loss=5.385271308973099, w0=74.20000000000014, w1=14.742096353130002\n",
      "SubSGD iter. 154/499: loss=5.503492186166603, w0=73.50000000000014, w1=15.092433286498393\n",
      "SubSGD iter. 155/499: loss=5.385249897885984, w0=72.80000000000014, w1=15.336460111207543\n",
      "SubSGD iter. 156/499: loss=5.337120125991197, w0=72.10000000000014, w1=15.417274416696255\n",
      "SubSGD iter. 157/499: loss=5.360111011457115, w0=72.80000000000014, w1=16.258464584920898\n",
      "SubSGD iter. 158/499: loss=5.316919750203497, w0=72.10000000000014, w1=15.524188841429098\n",
      "SubSGD iter. 159/499: loss=5.352575837708446, w0=71.40000000000013, w1=16.076160273366778\n",
      "SubSGD iter. 160/499: loss=5.434219440062823, w0=70.70000000000013, w1=16.515848678451963\n",
      "SubSGD iter. 161/499: loss=5.61743774491585, w0=71.40000000000013, w1=16.16551174508357\n",
      "SubSGD iter. 162/499: loss=5.43451158892767, w0=72.10000000000014, w1=15.795243654554774\n",
      "SubSGD iter. 163/499: loss=5.342676627309493, w0=71.40000000000013, w1=15.506746389997359\n",
      "SubSGD iter. 164/499: loss=5.453306792497246, w0=72.10000000000014, w1=15.301912870122136\n",
      "SubSGD iter. 165/499: loss=5.36903604125299, w0=72.80000000000014, w1=14.682771714707753\n",
      "SubSGD iter. 166/499: loss=5.3990366307402615, w0=73.50000000000014, w1=14.582494615467544\n",
      "SubSGD iter. 167/499: loss=5.425286393440182, w0=72.80000000000014, w1=15.205281022287837\n",
      "SubSGD iter. 168/499: loss=5.344792286044307, w0=73.50000000000014, w1=16.217959363640603\n",
      "SubSGD iter. 169/499: loss=5.366330177621691, w0=72.80000000000014, w1=15.60404495026302\n",
      "SubSGD iter. 170/499: loss=5.322496655723045, w0=73.50000000000014, w1=16.483217262493827\n",
      "SubSGD iter. 171/499: loss=5.3886026250153565, w0=74.20000000000014, w1=16.7533557127835\n",
      "SubSGD iter. 172/499: loss=5.537364317662443, w0=74.90000000000015, w1=16.997668436492635\n",
      "SubSGD iter. 173/499: loss=5.744061497812501, w0=74.20000000000014, w1=15.791652146722187\n",
      "SubSGD iter. 174/499: loss=5.4666165885684315, w0=73.50000000000014, w1=14.83351705582038\n",
      "SubSGD iter. 175/499: loss=5.402518928844442, w0=74.20000000000014, w1=14.483579124340062\n",
      "SubSGD iter. 176/499: loss=5.530768323445897, w0=73.50000000000014, w1=14.833916057708453\n",
      "SubSGD iter. 177/499: loss=5.402488021584491, w0=74.20000000000014, w1=14.947736384522766\n",
      "SubSGD iter. 178/499: loss=5.4870734860392, w0=73.50000000000014, w1=15.499707816460445\n",
      "SubSGD iter. 179/499: loss=5.367471630269388, w0=72.80000000000014, w1=15.93939622154563\n",
      "SubSGD iter. 180/499: loss=5.312908202970109, w0=72.10000000000014, w1=16.324680361873757\n",
      "SubSGD iter. 181/499: loss=5.344894700555266, w0=72.80000000000014, w1=16.47757411898834\n",
      "SubSGD iter. 182/499: loss=5.32762271730835, w0=73.50000000000014, w1=16.905091204205757\n",
      "SubSGD iter. 183/499: loss=5.436411917313559, w0=72.80000000000014, w1=16.48154995115174\n",
      "SubSGD iter. 184/499: loss=5.328056264810748, w0=72.10000000000014, w1=15.877017845297582\n",
      "SubSGD iter. 185/499: loss=5.340748965170233, w0=72.80000000000014, w1=16.224984891687996\n",
      "SubSGD iter. 186/499: loss=5.316203069187609, w0=73.50000000000014, w1=15.198052694095463\n",
      "SubSGD iter. 187/499: loss=5.380342883120882, w0=72.80000000000014, w1=14.592649542651477\n",
      "SubSGD iter. 188/499: loss=5.410890117065636, w0=73.50000000000014, w1=15.831965843629478\n",
      "SubSGD iter. 189/499: loss=5.362094336255849, w0=72.80000000000014, w1=14.77405053680192\n",
      "SubSGD iter. 190/499: loss=5.387106952552358, w0=73.50000000000014, w1=15.426107434244374\n",
      "SubSGD iter. 191/499: loss=5.370042757198094, w0=74.20000000000014, w1=15.979313350320487\n",
      "SubSGD iter. 192/499: loss=5.475156875899117, w0=74.90000000000015, w1=15.795847571270068\n",
      "SubSGD iter. 193/499: loss=5.627572656348719, w0=75.60000000000015, w1=15.822220221894888\n",
      "SubSGD iter. 194/499: loss=5.864109110759474, w0=74.90000000000015, w1=16.02296975894414\n",
      "SubSGD iter. 195/499: loss=5.640034983604356, w0=74.20000000000014, w1=16.817339103434918\n",
      "SubSGD iter. 196/499: loss=5.5436946781394525, w0=73.50000000000014, w1=17.243125250725658\n",
      "SubSGD iter. 197/499: loss=5.493759666256311, w0=72.80000000000014, w1=17.186815635680354\n",
      "SubSGD iter. 198/499: loss=5.424360845890094, w0=73.50000000000014, w1=18.311945595810663\n",
      "SubSGD iter. 199/499: loss=5.71400517176712, w0=72.80000000000014, w1=18.924743766812075\n",
      "SubSGD iter. 200/499: loss=5.8472571709275405, w0=72.10000000000014, w1=18.129574041694728\n",
      "SubSGD iter. 201/499: loss=5.637025103479791, w0=71.40000000000013, w1=18.619257575091314\n",
      "SubSGD iter. 202/499: loss=5.877860902639996, w0=70.70000000000013, w1=18.070863071333502\n",
      "SubSGD iter. 203/499: loss=5.880014409058357, w0=71.40000000000013, w1=18.49838015655092\n",
      "SubSGD iter. 204/499: loss=5.841175901493498, w0=72.10000000000014, w1=18.776507125352605\n",
      "SubSGD iter. 205/499: loss=5.834281268590072, w0=71.40000000000013, w1=18.897011676831646\n",
      "SubSGD iter. 206/499: loss=5.96429688324697, w0=72.10000000000014, w1=18.54389592526433\n",
      "SubSGD iter. 207/499: loss=5.759228882236594, w0=71.40000000000013, w1=17.924762529319665\n",
      "SubSGD iter. 208/499: loss=5.677034863213327, w0=70.70000000000013, w1=17.178776875732268\n",
      "SubSGD iter. 209/499: loss=5.69607688173424, w0=70.00000000000013, w1=17.668460409128855\n",
      "SubSGD iter. 210/499: loss=6.032478319773878, w0=70.70000000000013, w1=18.283121390259243\n",
      "SubSGD iter. 211/499: loss=5.937861912466468, w0=71.40000000000013, w1=17.658305290448297\n",
      "SubSGD iter. 212/499: loss=5.608791056162712, w0=72.10000000000014, w1=16.863935945957518\n",
      "SubSGD iter. 213/499: loss=5.385112179026004, w0=71.40000000000013, w1=16.440394692903503\n",
      "SubSGD iter. 214/499: loss=5.443167491088153, w0=70.70000000000013, w1=15.944768432434671\n",
      "SubSGD iter. 215/499: loss=5.6136445367150465, w0=70.00000000000013, w1=16.786186942160615\n",
      "SubSGD iter. 216/499: loss=5.917175586737202, w0=69.30000000000013, w1=15.906456812328138\n",
      "SubSGD iter. 217/499: loss=6.190312104103589, w0=70.00000000000013, w1=16.049787402922654\n",
      "SubSGD iter. 218/499: loss=5.857082269320715, w0=70.70000000000013, w1=16.315271105146884\n",
      "SubSGD iter. 219/499: loss=5.6115489395598335, w0=71.40000000000013, w1=15.189338691645712\n",
      "SubSGD iter. 220/499: loss=5.4821385565495735, w0=72.10000000000014, w1=15.299638725106504\n",
      "SubSGD iter. 221/499: loss=5.369216234820735, w0=72.80000000000014, w1=15.577765693908193\n",
      "SubSGD iter. 222/499: loss=5.323932813037976, w0=72.10000000000014, w1=14.920582990713207\n",
      "SubSGD iter. 223/499: loss=5.4169830490618915, w0=71.40000000000013, w1=15.040474804201539\n",
      "SubSGD iter. 224/499: loss=5.498622423138534, w0=72.10000000000014, w1=12.27017510731255\n",
      "SubSGD iter. 225/499: loss=6.183168044975659, w0=72.80000000000014, w1=12.558672371869966\n",
      "SubSGD iter. 226/499: loss=5.982065760667145, w0=72.10000000000014, w1=13.116796075619005\n",
      "SubSGD iter. 227/499: loss=5.858659169318276, w0=72.80000000000014, w1=13.973018128123543\n",
      "SubSGD iter. 228/499: loss=5.521934714055271, w0=72.10000000000014, w1=14.508537810949749\n",
      "SubSGD iter. 229/499: loss=5.478587972172305, w0=72.80000000000014, w1=14.484571971146657\n",
      "SubSGD iter. 230/499: loss=5.426458461659519, w0=73.50000000000014, w1=13.787987219905894\n",
      "SubSGD iter. 231/499: loss=5.553900348602138, w0=72.80000000000014, w1=14.877782242979114\n",
      "SubSGD iter. 232/499: loss=5.3746153798788, w0=72.10000000000014, w1=15.303568390269854\n",
      "SubSGD iter. 233/499: loss=5.3689048648856765, w0=71.40000000000013, w1=15.735360968553275\n",
      "SubSGD iter. 234/499: loss=5.441688194079302, w0=72.10000000000014, w1=17.27542330694046\n",
      "SubSGD iter. 235/499: loss=5.4448939833938015, w0=71.40000000000013, w1=17.219113691895156\n",
      "SubSGD iter. 236/499: loss=5.513218577684424, w0=70.70000000000013, w1=16.33938356206268\n",
      "SubSGD iter. 237/499: loss=5.611810624835824, w0=70.00000000000013, w1=16.724667702390807\n",
      "SubSGD iter. 238/499: loss=5.911547181828736, w0=70.70000000000013, w1=16.700701862587717\n",
      "SubSGD iter. 239/499: loss=5.633415438286971, w0=71.40000000000013, w1=16.270370274126982\n",
      "SubSGD iter. 240/499: loss=5.437209146555095, w0=72.10000000000014, w1=15.293572795185064\n",
      "SubSGD iter. 241/499: loss=5.369716273675667, w0=72.80000000000014, w1=15.733497238069246\n",
      "SubSGD iter. 242/499: loss=5.316253072618252, w0=72.10000000000014, w1=14.64087272374345\n",
      "SubSGD iter. 243/499: loss=5.458429798949438, w0=72.80000000000014, w1=15.653551065096218\n",
      "SubSGD iter. 244/499: loss=5.319802280058896, w0=73.50000000000014, w1=15.12891814038448\n",
      "SubSGD iter. 245/499: loss=5.383534782886575, w0=72.80000000000014, w1=15.122490259506133\n",
      "SubSGD iter. 246/499: loss=5.35056567287205, w0=72.10000000000014, w1=15.469574245126124\n",
      "SubSGD iter. 247/499: loss=5.356424995325714, w0=71.40000000000013, w1=14.812391541931138\n",
      "SubSGD iter. 248/499: loss=5.526483310314909, w0=70.70000000000013, w1=13.85425645102933\n",
      "SubSGD iter. 249/499: loss=5.957746388389568, w0=71.40000000000013, w1=14.124394901319\n",
      "SubSGD iter. 250/499: loss=5.691909172076627, w0=70.70000000000013, w1=13.06799366994011\n",
      "SubSGD iter. 251/499: loss=6.209902205598326, w0=71.40000000000013, w1=13.074421550818457\n",
      "SubSGD iter. 252/499: loss=6.0232464152011875, w0=72.10000000000014, w1=13.501938636035876\n",
      "SubSGD iter. 253/499: loss=5.729712277116749, w0=72.80000000000014, w1=14.707954925806323\n",
      "SubSGD iter. 254/499: loss=5.3957453130254684, w0=73.50000000000014, w1=13.937131859738136\n",
      "SubSGD iter. 255/499: loss=5.5210049676160295, w0=74.20000000000014, w1=14.580061558501932\n",
      "SubSGD iter. 256/499: loss=5.519384293206503, w0=73.50000000000014, w1=14.955647396788502\n",
      "SubSGD iter. 257/499: loss=5.393058537028932, w0=74.20000000000014, w1=15.496604448759644\n",
      "SubSGD iter. 258/499: loss=5.467672517863539, w0=73.50000000000014, w1=15.208107184202229\n",
      "SubSGD iter. 259/499: loss=5.379878673505092, w0=72.80000000000014, w1=14.659712680444418\n",
      "SubSGD iter. 260/499: loss=5.402050329337309, w0=72.10000000000014, w1=14.653284799566071\n",
      "SubSGD iter. 261/499: loss=5.456539105335744, w0=71.40000000000013, w1=13.596883568187181\n",
      "SubSGD iter. 262/499: loss=5.848396802953811, w0=72.10000000000014, w1=12.569951370594648\n",
      "SubSGD iter. 263/499: loss=6.0586138383168375, w0=71.40000000000013, w1=13.096908406363497\n",
      "SubSGD iter. 264/499: loss=6.015376470974585, w0=72.10000000000014, w1=13.475448189720229\n",
      "SubSGD iter. 265/499: loss=5.738178266839873, w0=72.80000000000014, w1=14.600578149850536\n",
      "SubSGD iter. 266/499: loss=5.4097844560695005, w0=72.10000000000014, w1=15.170538274386521\n",
      "SubSGD iter. 267/499: loss=5.382884009200009, w0=71.40000000000013, w1=16.011956784112467\n",
      "SubSGD iter. 268/499: loss=5.4350873699377305, w0=70.70000000000013, w1=15.588415531058452\n",
      "SubSGD iter. 269/499: loss=5.626708298200303, w0=70.00000000000013, w1=14.393676693954026\n",
      "SubSGD iter. 270/499: loss=6.061034364773573, w0=70.70000000000013, w1=15.11869688403483\n",
      "SubSGD iter. 271/499: loss=5.666425791181739, w0=70.00000000000013, w1=15.5588921387418\n",
      "SubSGD iter. 272/499: loss=5.866438311695199, w0=70.70000000000013, w1=15.61105248427151\n",
      "SubSGD iter. 273/499: loss=5.625447899230226, w0=71.40000000000013, w1=16.73618244440182\n",
      "SubSGD iter. 274/499: loss=5.458261581253735, w0=72.10000000000014, w1=17.014309413203506\n",
      "SubSGD iter. 275/499: loss=5.404505680247996, w0=71.40000000000013, w1=17.561471715437378\n",
      "SubSGD iter. 276/499: loss=5.585091632401382, w0=70.70000000000013, w1=17.80549854014653\n",
      "SubSGD iter. 277/499: loss=5.815290841427666, w0=70.00000000000013, w1=17.381957287092515\n",
      "SubSGD iter. 278/499: loss=5.986763701760681, w0=70.70000000000013, w1=17.91165826115463\n",
      "SubSGD iter. 279/499: loss=5.840063287158402, w0=71.40000000000013, w1=18.535146383440807\n",
      "SubSGD iter. 280/499: loss=5.852334057350021, w0=70.70000000000013, w1=17.340407546336383\n",
      "SubSGD iter. 281/499: loss=5.721891145054557, w0=70.00000000000013, w1=17.28409793129108\n",
      "SubSGD iter. 282/499: loss=5.971732480020812, w0=70.70000000000013, w1=16.853087246542465\n",
      "SubSGD iter. 283/499: loss=5.649622195227777, w0=71.40000000000013, w1=16.502750313174072\n",
      "SubSGD iter. 284/499: loss=5.445724805044802, w0=72.10000000000014, w1=16.149634561606756\n",
      "SubSGD iter. 285/499: loss=5.339446632867946, w0=71.40000000000013, w1=16.58932296669194\n",
      "SubSGD iter. 286/499: loss=5.450082668961132, w0=72.10000000000014, w1=16.462308521463918\n",
      "SubSGD iter. 287/499: loss=5.351460635459926, w0=71.40000000000013, w1=15.405907290085027\n",
      "SubSGD iter. 288/499: loss=5.461234943656404, w0=72.10000000000014, w1=14.606076556022318\n",
      "SubSGD iter. 289/499: loss=5.463730192939254, w0=72.80000000000014, w1=15.11526239996857\n",
      "SubSGD iter. 290/499: loss=5.351126360984541, w0=73.50000000000014, w1=15.359575123677704\n",
      "SubSGD iter. 291/499: loss=5.372885492026798, w0=72.80000000000014, w1=14.829874149615588\n",
      "SubSGD iter. 292/499: loss=5.380271660612448, w0=72.10000000000014, w1=15.186599667971425\n",
      "SubSGD iter. 293/499: loss=5.381014040793368, w0=72.80000000000014, w1=14.820678937241027\n",
      "SubSGD iter. 294/499: loss=5.381370112797586, w0=72.10000000000014, w1=15.251689621989641\n",
      "SubSGD iter. 295/499: loss=5.374123477368471, w0=71.40000000000013, w1=14.045673332219193\n",
      "SubSGD iter. 296/499: loss=5.7137573215900135, w0=70.70000000000013, w1=14.535356865615782\n",
      "SubSGD iter. 297/499: loss=5.780122266740143, w0=71.40000000000013, w1=14.823854130173197\n",
      "SubSGD iter. 298/499: loss=5.5248104100929485, w0=70.70000000000013, w1=15.33235524791303\n",
      "SubSGD iter. 299/499: loss=5.642170726056655, w0=70.00000000000013, w1=14.997127192609776\n",
      "SubSGD iter. 300/499: loss=5.941824035024771, w0=70.70000000000013, w1=15.643274425996996\n",
      "SubSGD iter. 301/499: loss=5.623653819356385, w0=71.40000000000013, w1=14.431851538070816\n",
      "SubSGD iter. 302/499: loss=5.610659641449401, w0=72.10000000000014, w1=14.871775980954999\n",
      "SubSGD iter. 303/499: loss=5.423687351011199, w0=71.40000000000013, w1=14.693423859575184\n",
      "SubSGD iter. 304/499: loss=5.549763162765806, w0=72.10000000000014, w1=15.33635355833898\n",
      "SubSGD iter. 305/499: loss=5.366307107766888, w0=72.80000000000014, w1=14.782246484342398\n",
      "SubSGD iter. 306/499: loss=5.386035783858902, w0=73.50000000000014, w1=14.9787665671209\n",
      "SubSGD iter. 307/499: loss=5.391349438021915, w0=72.80000000000014, w1=14.728485450658843\n",
      "SubSGD iter. 308/499: loss=5.393062077759059, w0=72.10000000000014, w1=14.23285919019001\n",
      "SubSGD iter. 309/499: loss=5.532088814843073, w0=72.80000000000014, w1=14.248166856902147\n",
      "SubSGD iter. 310/499: loss=5.467111756515227, w0=73.50000000000014, w1=14.22958739800327\n",
      "SubSGD iter. 311/499: loss=5.469383860756109, w0=74.20000000000014, w1=12.875630503970042\n",
      "SubSGD iter. 312/499: loss=5.87952917569767, w0=73.50000000000014, w1=12.869202623091695\n",
      "SubSGD iter. 313/499: loss=5.8418222231844625, w0=72.80000000000014, w1=13.053363401410015\n",
      "SubSGD iter. 314/499: loss=5.789237112116618, w0=73.50000000000014, w1=12.469050863864124\n",
      "SubSGD iter. 315/499: loss=5.998819026543939, w0=74.20000000000014, w1=13.56167537818992\n",
      "SubSGD iter. 316/499: loss=5.684242410631372, w0=74.90000000000015, w1=14.175589791567502\n",
      "SubSGD iter. 317/499: loss=5.733806505000596, w0=74.20000000000014, w1=14.06528975810671\n",
      "SubSGD iter. 318/499: loss=5.587512504456809, w0=73.50000000000014, w1=13.472971796838532\n",
      "SubSGD iter. 319/499: loss=5.640353111197149, w0=74.20000000000014, w1=13.817440043709\n",
      "SubSGD iter. 320/499: loss=5.630674338123372, w0=73.50000000000014, w1=14.430238214710412\n",
      "SubSGD iter. 321/499: loss=5.441771415131762, w0=74.20000000000014, w1=14.077122463143098\n",
      "SubSGD iter. 322/499: loss=5.585618140892133, w0=73.50000000000014, w1=14.913161320415915\n",
      "SubSGD iter. 323/499: loss=5.3963495695930135, w0=72.80000000000014, w1=15.3528497255011\n",
      "SubSGD iter. 324/499: loss=5.336224436092717, w0=73.50000000000014, w1=15.334270266602223\n",
      "SubSGD iter. 325/499: loss=5.374053801693014, w0=74.20000000000014, w1=15.536707156643223\n",
      "SubSGD iter. 326/499: loss=5.467007634642332, w0=73.50000000000014, w1=14.330690866872775\n",
      "SubSGD iter. 327/499: loss=5.454712647522107, w0=72.80000000000014, w1=15.17210937659872\n",
      "SubSGD iter. 328/499: loss=5.346852869231447, w0=73.50000000000014, w1=15.713066428569862\n",
      "SubSGD iter. 329/499: loss=5.363424265845195, w0=74.20000000000014, w1=14.859220158144593\n",
      "SubSGD iter. 330/499: loss=5.493828190082492, w0=73.50000000000014, w1=15.402236619509692\n",
      "SubSGD iter. 331/499: loss=5.37091583703894, w0=74.20000000000014, w1=16.942298957896877\n",
      "SubSGD iter. 332/499: loss=5.558838283241571, w0=74.90000000000015, w1=16.6059360002208\n",
      "SubSGD iter. 333/499: loss=5.691540219114767, w0=75.60000000000015, w1=15.909351248980037\n",
      "SubSGD iter. 334/499: loss=5.870587424638375, w0=76.30000000000015, w1=16.522343746163596\n",
      "SubSGD iter. 335/499: loss=6.244153214006355, w0=77.00000000000016, w1=15.997710821451857\n",
      "SubSGD iter. 336/499: loss=6.544044777046754, w0=76.30000000000015, w1=15.20254109633451\n",
      "SubSGD iter. 337/499: loss=6.1377294131711215, w0=77.00000000000016, w1=15.217848763046646\n",
      "SubSGD iter. 338/499: loss=6.472820093867578, w0=76.30000000000015, w1=14.957136541664783\n",
      "SubSGD iter. 339/499: loss=6.134846443249018, w0=77.00000000000016, w1=11.583992864075105\n",
      "SubSGD iter. 340/499: loss=7.006628284445396, w0=76.30000000000015, w1=12.111181502822332\n",
      "SubSGD iter. 341/499: loss=6.5949558568516125, w0=75.60000000000015, w1=12.714947572788844\n",
      "SubSGD iter. 342/499: loss=6.201254335406835, w0=74.90000000000015, w1=12.083782232793991\n",
      "SubSGD iter. 343/499: loss=6.241598317760277, w0=75.60000000000015, w1=13.167657629485294\n",
      "SubSGD iter. 344/499: loss=6.103478178806043, w0=76.30000000000015, w1=14.180095967351715\n",
      "SubSGD iter. 345/499: loss=6.192640546150462, w0=77.00000000000016, w1=14.345548759284341\n",
      "SubSGD iter. 346/499: loss=6.478051863865858, w0=76.30000000000015, w1=14.89752019122202\n",
      "SubSGD iter. 347/499: loss=6.135970709205131, w0=75.60000000000015, w1=15.375568393648143\n",
      "SubSGD iter. 348/499: loss=5.8498393340115085, w0=74.90000000000015, w1=15.456382699136855\n",
      "SubSGD iter. 349/499: loss=5.619038738167157, w0=74.20000000000014, w1=14.509470437394425\n",
      "SubSGD iter. 350/499: loss=5.527707693329279, w0=73.50000000000014, w1=15.452976920931546\n",
      "SubSGD iter. 351/499: loss=5.369104109072884, w0=72.80000000000014, w1=14.752042923496793\n",
      "SubSGD iter. 352/499: loss=5.389983235773268, w0=72.10000000000014, w1=13.557304086392367\n",
      "SubSGD iter. 353/499: loss=5.712091380107087, w0=72.80000000000014, w1=13.722756878324994\n",
      "SubSGD iter. 354/499: loss=5.580417244141224, w0=73.50000000000014, w1=13.481776963658346\n",
      "SubSGD iter. 355/499: loss=5.637730318404346, w0=72.80000000000014, w1=13.283016097839822\n",
      "SubSGD iter. 356/499: loss=5.709649563066045, w0=73.50000000000014, w1=14.078185822957169\n",
      "SubSGD iter. 357/499: loss=5.49409423017733, w0=74.20000000000014, w1=12.86676293503099\n",
      "SubSGD iter. 358/499: loss=5.8824866765728325, w0=73.50000000000014, w1=13.306451340116174\n",
      "SubSGD iter. 359/499: loss=5.68997460021562, w0=74.20000000000014, w1=12.876119751655438\n",
      "SubSGD iter. 360/499: loss=5.8793660024009435, w0=74.90000000000015, w1=13.029013508770019\n",
      "SubSGD iter. 361/499: loss=5.941980558426747, w0=74.20000000000014, w1=12.605472255716004\n",
      "SubSGD iter. 362/499: loss=5.973887292132446, w0=73.50000000000014, w1=12.619227451691494\n",
      "SubSGD iter. 363/499: loss=5.939407302328674, w0=72.80000000000014, w1=12.354442342500725\n",
      "SubSGD iter. 364/499: loss=6.069693896316014, w0=72.10000000000014, w1=13.480374756001897\n",
      "SubSGD iter. 365/499: loss=5.736592871896921, w0=71.40000000000013, w1=14.050334880537882\n",
      "SubSGD iter. 366/499: loss=5.712424921106274, w0=70.70000000000013, w1=14.675150980348828\n",
      "SubSGD iter. 367/499: loss=5.751035090446968, w0=70.00000000000013, w1=14.79504279383716\n",
      "SubSGD iter. 368/499: loss=5.973539425767033, w0=70.70000000000013, w1=14.960849053404656\n",
      "SubSGD iter. 369/499: loss=5.6954950379155616, w0=71.40000000000013, w1=15.126655312972153\n",
      "SubSGD iter. 370/499: loss=5.488727175254587, w0=72.10000000000014, w1=15.40478228177384\n",
      "SubSGD iter. 371/499: loss=5.360991439026804, w0=71.40000000000013, w1=16.108287200164703\n",
      "SubSGD iter. 372/499: loss=5.43415830593896, w0=70.70000000000013, w1=16.997119024331198\n",
      "SubSGD iter. 373/499: loss=5.6685051082178, w0=71.40000000000013, w1=16.614993039780863\n",
      "SubSGD iter. 374/499: loss=5.451417716826242, w0=70.70000000000013, w1=16.894922032217327\n",
      "SubSGD iter. 375/499: loss=5.654767796523831, w0=70.00000000000013, w1=16.302604070949148\n",
      "SubSGD iter. 376/499: loss=5.8739912075284915, w0=69.30000000000013, w1=16.713679255491375\n",
      "SubSGD iter. 377/499: loss=6.218177626777028, w0=70.00000000000013, w1=16.681250247724016\n",
      "SubSGD iter. 378/499: loss=5.907574912082327, w0=69.30000000000013, w1=15.980316250289263\n",
      "SubSGD iter. 379/499: loss=6.189447518701643, w0=70.00000000000013, w1=15.540627845204078\n",
      "SubSGD iter. 380/499: loss=5.8682655322957, w0=69.30000000000013, w1=15.341866979385554\n",
      "SubSGD iter. 381/499: loss=6.21488735999857, w0=70.00000000000013, w1=15.96100037533022\n",
      "SubSGD iter. 382/499: loss=5.853758510376351, w0=70.70000000000013, w1=15.264415624089457\n",
      "SubSGD iter. 383/499: loss=5.647970634685723, w0=71.40000000000013, w1=14.92805266641338\n",
      "SubSGD iter. 384/499: loss=5.511713194851273, w0=72.10000000000014, w1=14.400864027666154\n",
      "SubSGD iter. 385/499: loss=5.49688257810667, w0=71.40000000000013, w1=13.206125190561728\n",
      "SubSGD iter. 386/499: loss=5.977152807442467, w0=72.10000000000014, w1=12.950693309460158\n",
      "SubSGD iter. 387/499: loss=5.9168887155646965, w0=71.40000000000013, w1=13.684807632461148\n",
      "SubSGD iter. 388/499: loss=5.820957203250096, w0=70.70000000000013, w1=14.18982536428547\n",
      "SubSGD iter. 389/499: loss=5.862526159788844, w0=71.40000000000013, w1=13.8142395259989\n",
      "SubSGD iter. 390/499: loss=5.781367012093536, w0=70.70000000000013, w1=14.655658035724844\n",
      "SubSGD iter. 391/499: loss=5.754980864297703, w0=71.40000000000013, w1=14.450824515849622\n",
      "SubSGD iter. 392/499: loss=5.60581178705545, w0=72.10000000000014, w1=14.720962966139291\n",
      "SubSGD iter. 393/499: loss=5.446229896855622, w0=72.80000000000014, w1=14.986446668363522\n",
      "SubSGD iter. 394/499: loss=5.362180934336403, w0=72.10000000000014, w1=15.011744433752364\n",
      "SubSGD iter. 395/499: loss=5.404460793687164, w0=72.80000000000014, w1=15.806914158869711\n",
      "SubSGD iter. 396/499: loss=5.313275586367142, w0=72.10000000000014, w1=16.419712329871125\n",
      "SubSGD iter. 397/499: loss=5.349345284466822, w0=71.40000000000013, w1=15.578522161646482\n",
      "SubSGD iter. 398/499: loss=5.44849725411247, w0=70.70000000000013, w1=14.372505871876035\n",
      "SubSGD iter. 399/499: loss=5.816936000388705, w0=71.40000000000013, w1=13.518659601450766\n",
      "SubSGD iter. 400/499: loss=5.873219723679413, w0=72.10000000000014, w1=14.042840152902484\n",
      "SubSGD iter. 401/499: loss=5.579932236057979, w0=72.80000000000014, w1=13.46983006988786\n",
      "SubSGD iter. 402/499: loss=5.65186263746724, w0=73.50000000000014, w1=14.112759768651657\n",
      "SubSGD iter. 403/499: loss=5.488061852723814, w0=72.80000000000014, w1=13.411825771216904\n",
      "SubSGD iter. 404/499: loss=5.668812617342623, w0=73.50000000000014, w1=13.57727856314953\n",
      "SubSGD iter. 405/499: loss=5.609342783745288, w0=72.80000000000014, w1=12.984960601881353\n",
      "SubSGD iter. 406/499: loss=5.813550574994242, w0=73.50000000000014, w1=11.947446408067812\n",
      "SubSGD iter. 407/499: loss=6.2138957469819776, w0=74.20000000000014, w1=11.36313387052192\n",
      "SubSGD iter. 408/499: loss=6.487289068717426, w0=73.50000000000014, w1=12.203161441981731\n",
      "SubSGD iter. 409/499: loss=6.107317101870397, w0=74.20000000000014, w1=11.94772956088016\n",
      "SubSGD iter. 410/499: loss=6.2332743330128295, w0=74.90000000000015, w1=12.15016645092116\n",
      "SubSGD iter. 411/499: loss=6.216407758793553, w0=74.20000000000014, w1=12.774982550732107\n",
      "SubSGD iter. 412/499: loss=5.914011972125177, w0=73.50000000000014, w1=11.8168474598303\n",
      "SubSGD iter. 413/499: loss=6.2706465233409086, w0=74.20000000000014, w1=12.161315706700767\n",
      "SubSGD iter. 414/499: loss=6.145557753576234, w0=73.50000000000014, w1=11.826087651397513\n",
      "SubSGD iter. 415/499: loss=6.266631268607074, w0=74.20000000000014, w1=12.037252045963717\n",
      "SubSGD iter. 416/499: loss=6.195852737001498, w0=74.90000000000015, w1=12.6511664593413\n",
      "SubSGD iter. 417/499: loss=6.047218756929562, w0=74.20000000000014, w1=13.469824829146928\n",
      "SubSGD iter. 418/499: loss=5.704329555219266, w0=73.50000000000014, w1=13.816908814766919\n",
      "SubSGD iter. 419/499: loss=5.546894268588602, w0=72.80000000000014, w1=12.869996553024489\n",
      "SubSGD iter. 420/499: loss=5.856410859142077, w0=72.10000000000014, w1=13.706035410297305\n",
      "SubSGD iter. 421/499: loss=5.667085080898538, w0=71.40000000000013, w1=13.825927223785637\n",
      "SubSGD iter. 422/499: loss=5.77785170430419, w0=72.10000000000014, w1=13.472811472218323\n",
      "SubSGD iter. 423/499: loss=5.7390267764009995, w0=72.80000000000014, w1=13.675248362259323\n",
      "SubSGD iter. 424/499: loss=5.593359925019468, w0=73.50000000000014, w1=12.935915562815378\n",
      "SubSGD iter. 425/499: loss=5.816897940225006, w0=74.20000000000014, w1=13.363432648032797\n",
      "SubSGD iter. 426/499: loss=5.729514220975513, w0=74.90000000000015, w1=13.979819596870046\n",
      "SubSGD iter. 427/499: loss=5.761646504771684, w0=74.20000000000014, w1=13.801467475490231\n",
      "SubSGD iter. 428/499: loss=5.633722064701314, w0=74.90000000000015, w1=13.062134676046288\n",
      "SubSGD iter. 429/499: loss=5.934250969864141, w0=74.20000000000014, w1=12.883782554666473\n",
      "SubSGD iter. 430/499: loss=5.8768286296174574, w0=74.90000000000015, w1=12.48780631144464\n",
      "SubSGD iter. 431/499: loss=6.097477768114454, w0=74.20000000000014, w1=12.50156150742013\n",
      "SubSGD iter. 432/499: loss=6.012759846246715, w0=73.50000000000014, w1=12.520140966319007\n",
      "SubSGD iter. 433/499: loss=5.978104766069556, w0=74.20000000000014, w1=13.163070665082802\n",
      "SubSGD iter. 434/499: loss=5.786809399067725, w0=74.90000000000015, w1=12.309224394657534\n",
      "SubSGD iter. 435/499: loss=6.159043190919207, w0=75.60000000000015, w1=12.83892536871965\n",
      "SubSGD iter. 436/499: loss=6.1734574923337995, w0=76.30000000000015, w1=13.035445451498152\n",
      "SubSGD iter. 437/499: loss=6.38073495192968, w0=75.60000000000015, w1=13.605405576034137\n",
      "SubSGD iter. 438/499: loss=6.025021670921174, w0=74.90000000000015, w1=13.406644710215613\n",
      "SubSGD iter. 439/499: loss=5.860670145599653, w0=74.20000000000014, w1=13.588508553790781\n",
      "SubSGD iter. 440/499: loss=5.678481317811231, w0=74.90000000000015, w1=13.967048337147514\n",
      "SubSGD iter. 441/499: loss=5.763489607510873, w0=74.20000000000014, w1=12.909133030319955\n",
      "SubSGD iter. 442/499: loss=5.868534642601225, w0=74.90000000000015, w1=12.668153115653308\n",
      "SubSGD iter. 443/499: loss=6.04204488749908, w0=74.20000000000014, w1=13.852155316047199\n",
      "SubSGD iter. 444/499: loss=5.6241886580421605, w0=73.50000000000014, w1=14.291843721132384\n",
      "SubSGD iter. 445/499: loss=5.460349790985753, w0=74.20000000000014, w1=13.90971773658205\n",
      "SubSGD iter. 446/499: loss=5.613593841752706, w0=74.90000000000015, w1=13.877288728814689\n",
      "SubSGD iter. 447/499: loss=5.776443394653336, w0=74.20000000000014, w1=14.573873480055452\n",
      "SubSGD iter. 448/499: loss=5.520094564881278, w0=73.50000000000014, w1=14.949459318342022\n",
      "SubSGD iter. 449/499: loss=5.393537874482875, w0=72.80000000000014, w1=13.754720481237596\n",
      "SubSGD iter. 450/499: loss=5.572508543184299, w0=73.50000000000014, w1=13.99903320494673\n",
      "SubSGD iter. 451/499: loss=5.508805508237287, w0=74.20000000000014, w1=15.124163165077038\n",
      "SubSGD iter. 452/499: loss=5.4787047991199795, w0=73.50000000000014, w1=15.519599957020043\n",
      "SubSGD iter. 453/499: loss=5.366776726021308, w0=74.20000000000014, w1=15.169662025539726\n",
      "SubSGD iter. 454/499: loss=5.477086471750229, w0=74.90000000000015, w1=15.964831750657073\n",
      "SubSGD iter. 455/499: loss=5.63578036671025, w0=74.20000000000014, w1=16.469849482481393\n",
      "SubSGD iter. 456/499: loss=5.509314903321969, w0=73.50000000000014, w1=16.900860167230007\n",
      "SubSGD iter. 457/499: loss=5.435742863941937, w0=74.20000000000014, w1=17.54700740061723\n",
      "SubSGD iter. 458/499: loss=5.66604267642554, w0=73.50000000000014, w1=16.998612896859417\n",
      "SubSGD iter. 459/499: loss=5.451202165013557, w0=74.20000000000014, w1=17.343081143729883\n",
      "SubSGD iter. 460/499: loss=5.623642569490391, w0=73.50000000000014, w1=17.851582261469716\n",
      "SubSGD iter. 461/499: loss=5.610641548234672, w0=72.80000000000014, w1=17.150648264034963\n",
      "SubSGD iter. 462/499: loss=5.418717262145823, w0=72.10000000000014, w1=17.394675088744115\n",
      "SubSGD iter. 463/499: loss=5.4669370216664435, w0=71.40000000000013, w1=17.16555339645736\n",
      "SubSGD iter. 464/499: loss=5.503479409238428, w0=70.70000000000013, w1=16.90076828726659\n",
      "SubSGD iter. 465/499: loss=5.655511480752914, w0=70.00000000000013, w1=16.702007421448066\n",
      "SubSGD iter. 466/499: loss=5.909473989166367, w0=70.70000000000013, w1=16.27167583298733\n",
      "SubSGD iter. 467/499: loss=5.611075813122873, w0=71.40000000000013, w1=16.381975866448123\n",
      "SubSGD iter. 468/499: loss=5.440915036203033, w0=72.10000000000014, w1=16.54742865838075\n",
      "SubSGD iter. 469/499: loss=5.35592614603877, w0=72.80000000000014, w1=17.279393251888383\n",
      "SubSGD iter. 470/499: loss=5.438806726421242, w0=72.10000000000014, w1=15.916641856496636\n",
      "SubSGD iter. 471/499: loss=5.339814908770529, w0=72.80000000000014, w1=15.520665613274803\n",
      "SubSGD iter. 472/499: loss=5.3270533236558375, w0=73.50000000000014, w1=14.993476974527576\n",
      "SubSGD iter. 473/499: loss=5.390560053751089, w0=74.20000000000014, w1=15.639624207914796\n",
      "SubSGD iter. 474/499: loss=5.465714794240769, w0=73.50000000000014, w1=14.583222976535906\n",
      "SubSGD iter. 475/499: loss=5.425214847840725, w0=74.20000000000014, w1=14.779743059314407\n",
      "SubSGD iter. 476/499: loss=5.5001605539179925, w0=74.90000000000015, w1=15.422672758078203\n",
      "SubSGD iter. 477/499: loss=5.618539466838028, w0=74.20000000000014, w1=14.581482589853561\n",
      "SubSGD iter. 478/499: loss=5.519223409536056, w0=73.50000000000014, w1=14.96676673018169\n",
      "SubSGD iter. 479/499: loss=5.392197217476453, w0=72.80000000000014, w1=13.79843592966422\n",
      "SubSGD iter. 480/499: loss=5.5623808223839815, w0=73.50000000000014, w1=13.24432885566764\n",
      "SubSGD iter. 481/499: loss=5.7092172522010385, w0=72.80000000000014, w1=13.59141284128763\n",
      "SubSGD iter. 482/499: loss=5.616734172551415, w0=72.10000000000014, w1=14.126932524113835\n",
      "SubSGD iter. 483/499: loss=5.558172182076052, w0=71.40000000000013, w1=14.53800770865606\n",
      "SubSGD iter. 484/499: loss=5.584759475708863, w0=72.10000000000014, w1=14.816134677457748\n",
      "SubSGD iter. 485/499: loss=5.431732680647341, w0=71.40000000000013, w1=15.321152409282071\n",
      "SubSGD iter. 486/499: loss=5.4685075473791915, w0=70.70000000000013, w1=14.415977306095007\n",
      "SubSGD iter. 487/499: loss=5.8069494584955, w0=70.00000000000013, w1=15.09657648375109\n",
      "SubSGD iter. 488/499: loss=5.927593393787764, w0=70.70000000000013, w1=14.700600240529257\n",
      "SubSGD iter. 489/499: loss=5.745883635534562, w0=71.40000000000013, w1=14.91176463509546\n",
      "SubSGD iter. 490/499: loss=5.513609822186671, w0=72.10000000000014, w1=14.338754552080838\n",
      "SubSGD iter. 491/499: loss=5.509047161860014, w0=71.40000000000013, w1=14.36405231746968\n",
      "SubSGD iter. 492/499: loss=5.628355864829427, w0=72.10000000000014, w1=15.197389900029258\n",
      "SubSGD iter. 493/499: loss=5.37984307806644, w0=71.40000000000013, w1=15.582674040357386\n",
      "SubSGD iter. 494/499: loss=5.448306371227331, w0=70.70000000000013, w1=16.20546044717768\n",
      "SubSGD iter. 495/499: loss=5.610947071359188, w0=70.00000000000013, w1=16.75743187911536\n",
      "SubSGD iter. 496/499: loss=5.914544781503055, w0=69.30000000000013, w1=16.87732369260369\n",
      "SubSGD iter. 497/499: loss=6.233805903245483, w0=70.00000000000013, w1=17.520253391367483\n",
      "SubSGD iter. 498/499: loss=6.0083047655871695, w0=69.30000000000013, w1=17.943492816139997\n",
      "SubSGD iter. 499/499: loss=6.3902209789806745, w0=70.00000000000013, w1=18.562626212084663\n",
      "SubSGD: execution time=0.030 seconds\n"
     ]
    }
   ],
   "source": [
    "# Define the parameters of the algorithm.\n",
    "max_iters = 500\n",
    "gamma = 0.7\n",
    "batch_size = 1\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start SubSGD.\n",
    "start_time = datetime.datetime.now()\n",
    "subsgd_losses, subsgd_ws = stochastic_subgradient_descent(\n",
    "    y, tx, w_initial, batch_size, max_iters, gamma\n",
    ")\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"SubSGD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T08:19:49.910445605Z",
     "start_time": "2023-10-05T08:19:49.579528262Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "interactive(children=(IntSlider(value=1, description='n_iter', max=501, min=1), Output()), _dom_classes=('widg…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ccf5ed1e99c9405c9adca5b737ee7b83"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<function __main__.plot_figure(n_iter)>"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        subsgd_losses,\n",
    "        subsgd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(subsgd_ws)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
